# MasterThesis
Abstract:
The work is devoted to the issue of semi-supervised learning for the tasks of text classification. One of the aims is to test the semi-supervised learning algorithm called FixMatch in the NLP domain. This method is considered to be state-of-the-art for problems of image classification with very few training labeled examples. In order to test FixMatch for text classification, it is necessary to create realistic augmentations, which will be proposed in the following work. In order to evaluate the FixMatch properly, two other popular SSL methods (VAT, Pseudo-Label) and supervised model, will be trained as comparative baselines. Another goal of the work is to check how the result on the test set are affected by training process and selection of hyperparameters using different ratio of the training and validation set sizes. The last goal will be to examine the quality of the chosen hyperparameter on small validation sets, also by checking the results of the SLL methods used with more labelled and unlabeled data. 


 Results of conducted experiments for the FixMatch algorithm indicate that it was not possible to repeat in the text domain state-of-the-art scores from the computer vision domain. After observing the results of successful experiments with different SSL methods, a conclusion appears that the number of examples in the validation set should be slightly less or equal to the number of examples in the training set. For used SSL methods, the error on the test set is decreasing with training on an additional number of labeled data, while in the case of unlabeled data, there is no such relation.
