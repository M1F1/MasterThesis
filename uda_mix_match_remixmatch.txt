\subsubsection{UDA}
    	In this work, we investigate the role of noise injection in consistency training and observe that
    	advanced data augmentation methods, specifically those work best in supervised learning (Simard
    	et al., 1998; Krizhevsky et al., 2012; Cubuk et al., 2018; Yu et al., 2018), also perform well in semisupervised
    	learning. There is indeed a strong correlation between the performance of data augmentation
    	operations in supervised learning and their performance in consistency training. We, hence,
    	propose to substitute the traditional noise injection methods with high quality data augmentation
    	methods in order to improve consistency training. To emphasize the use of better data augmentation
    	in consistency training, we name our method Unsupervised Data Augmentation or UDA.
    	Following this idea, we propose to use a rich set of state-of-the-art data augmentations verified in
    	various supervised settings to inject noise and optimize the same consistency training objective on
    	unlabeled examples. When jointly trained with labeled examples, we utilize a weighting factor 
    	 to balance the supervised cross entropy and the unsupervised consistency training loss, which is
    	illustrated in Figure 1. Formally, the full objective can be written as follows:
    	formula
        
        	where CE denotes cross entropy, q(^x j x)  is a data augmentation transformation and ~  is a fixed  copy
        of the current parameters  indicating that the gradient is not propagated through ~ , as suggested by
        VAT (Miyato et al., 2018). We set  to 1  for most of our experiments and use different batch sizes
        for the labeled data and the unlabeled data. In practice, we use a larger batch size for the objective
        function on unlabeled data.
        Confidence-based masking. We find it to be helpful to mask out examples that the current model
        is not confident about. Specifically, in each minibatch, the consistency loss term is computed only
        on examples whose highest probability among classification categories is greater than a threshold .
        Sharpening Predictions. Since regularizing the predictions to have low entropy has been shown
        to be beneficial (Grandvalet & Bengio, 2005; Miyato et al., 2018), we sharpen predictions
        when computing the target distribution on unlabeled examples by using a low Softmax temperature
        . When combined with confidence-based masking, the loss on unlabeled examples
        ExpU(x)E^xq(^xjx)
        
        CE p~(y j x)kp(y j ^x) on a minibatch B is computed as:1 jBj X x2B I(max y0p~(y0 j x) > )CE
        
        p(sharp) ~ (y j x)kp(y j ^x)
        p(sharp) ~ (y j x) = Pexp(zy= )
        y0 exp(zy0=)
        where I() is the indicator function, zy is the logit of label y for example x. 
        Moreover, the performance difference between UDA and VAT shows the superiority of data augmentation
        based noise. The difference of UDA and VAT is essentially the noise process. While
        the noise produced by VAT often contain high-frequency artifacts that do not exist in real images,
        data augmentation mostly generates diverse and realistic images.
        TRAINING  SIGNAL  ANNEALING FOR  LOW -DATA  REGIME
         In semi-supervised learning, we often encounter a situation where there is a huge gap between the
        amount of unlabeled data and that of labeled data. Hence, the model often quickly overfits the
        limited amount of labeled data while still underfitting the unlabeled data. To tackle this difficulty,
        we introduce a new training technique, called Training Signal Annealing (TSA), which gradually
        releases the “training signals” of the labeled examples as training progresses. Intuitively, we only
        utilize a labeled example if the model’s confidence on that example is lower than a predefined threshold
        which increases according to a schedule. Specifically, at training step t , if the model’s predicted
        probability for the correct category p(y j x)  is higher than a threshold t , we remove that example
        from the loss function. Suppose K  is the number of categories, by gradually increasing t  from 1
        K
         to 1 , the threshold t  serves as a ceiling to prevent over-training on easy labeled examples.
        We consider three increasing schedules of t  with different application scenarios. 
        \cite{Uda}
         

	\subsubsection{Mixmatch}
        	In this section, we introduce MixMatch , our proposed semi-supervised learning method. MixMatch
         is a “holistic” approach which incorporates ideas and components from the dominant paradigms for
        SSL discussed in section 2. Given a batch X  of labeled examples with one-hot targets (representing
        one of L  possible labels) and an equally-sized batch U  of unlabeled examples, MixMatch  produces
        a processed batch of augmented labeled examples X0  and a batch of augmented unlabeled examples
        with “guessed” labels U0 . U0  and X0  are then used in computing separate labeled and unlabeled loss
        terms. More formally, the combined loss L  for semi-supervised learning is defined as
        
         where H(p; q)  is the cross-entropy between distributions p  and q , and T , K , , and U  are hyperparameters
        described below. The full MixMatch  algorithm is provided in algorithm 1, and a diagram
        of the label guessing process is shown in fig. 1. Next, we describe each part of MixMatch .
         3.1 Data Augmentation
        As is typical in many SSL methods, we use data augmentation both on labeled and unlabeled data.
        For each xb in the batch of labeled data X, we generate a transformed version ^xb = Augment(xb)
        (algorithm 1, line 3). For each ub in the batch of unlabeled data U, we generate K augmentations
        ^ub;k = Augment(ub); k 2 (1; : : : ;K) (algorithm 1, line 5). We use these individual augmentations
        to generate a “guessed label” qb for each ub, through a process we describe in the following subsection.
         3.2 Label Guessing
        For each unlabeled example in U, MixMatch produces a “guess” for the example’s label using the
        model’s predictions. This guess is later used in the unsupervised loss term. To do so, we compute the
        average of the model’s predicted class distributions across all the K augmentations of ub by
        qb = 1 K XK k=1
        pmodel(y j ^ub;k; ) (6)
        in algorithm 1, line 7. Using data augmentation to obtain an artificial target for an unlabeled 
        Sharpening. In generating a label guess, we perform one additional step inspired by the success
        of entropy minimization in semi-supervised learning (discussed in section 2.2). Given the average
        prediction over augmentations qb, we apply a sharpening function to reduce the entropy of the label
        distribution. In practice, for the sharpening function, we use the common approach of adjusting the
        “temperature” of this categorical distribution [16], which is defined as the operation
        Sharpen(p; T)i := p1Ti XL j=1 p1Tj (7)
        where p is some input categorical distribution (specifically in MixMatch, p is the average class
        prediction over augmentations qb, as shown in algorithm 1, line 8) and T is a hyperparameter. As
        T ! 0, the output of Sharpen(p; T) will approach a Dirac (“one-hot”) distribution. Since we will
        later use qb = Sharpen(qb; T) as a target for the model’s prediction for an augmentation of ub,
        lowering the temperature encourages the model to produce lower-entropy predictions.
        We use MixUp  for semi-supervised learning, and unlike past work for SSL we mix both labeled
        examples and unlabeled examples with label guesses (generated as described in section 3.2). To be
        compatible with our separate loss terms, we define a slightly modified version of MixUp . For a pair
        of two examples with their corresponding labels probabilities (x1; p1); (x2; p2)  we compute (x0; p0)
         by
        Beta(; )  (8)
        0 = max(; 1)  (9)
        x0 = 0x1 + (10)x2  (10)
        p0 = 0p1 + (1 0)p2  (11)
        where  is a hyperparameter. Vanilla MixUp  omits eq. (9) (i.e. it sets 0 = ). Given that labeled
        and unlabeled examples are concatenated in the same batch, we need to preserve the order of the
        batch to compute individual loss components appropriately. This is achieved by eq. (9) which ensures
        that x0  is closer to x1  than to x2 . To apply MixUp , we first collect all augmented labeled examples
        with their labels and all unlabeled examples with their guessed labels into
        X^ =(^xb; pb); b 2 (1; : : : ;B)(12)^ U =(^ub;k; qb); b 2 (1; : : : ;B); k 2 (1; : : : ;K)(13)4
        (algorithm 1, lines 10–11). Then, we combine these collections and shuffle the result to form W
         which will serve as a data source for MixUp  (algorithm 1, line 12). For each the ith  example-label
        pair in X^ , we compute MixUp(X^i;Wi)  and add the result to the collection X0  (algorithm 1, line
        13). We compute U0
        i = MixUp( ^ Ui;Wi+jX^j)  for i 2 (1; : : : ; j ^ Uj) , intentionally using the remainder
        of W  that was not used in the construction of X0  (algorithm 1, line 14). To summarize, MixMatch
         transforms X  into X0 , a collection of labeled examples which have had data augmentation and
        MixUp  (potentially mixed with an unlabeled example) applied. Similarly, U  is transformed into U0 ,
        a collection of multiple augmentations of each unlabeled example with corresponding label guesses.
        pseudocode of algorithm
          \cite{MixMatch}

	\subsubsection{ReMixMatch}
        	We improve the recently-proposed “MixMatch” semi-supervised learning algorithm
        by introducing two new techniques: distribution alignment and augmentation
        anchoring. Distribution alignment  encourages the marginal distribution of
        predictions on unlabeled data to be close to the marginal distribution of groundtruth
        labels. Augmentation anchoring  feeds multiple strongly augmented versions
        of an input into the model and encourages each output to be close to the prediction
        for a weakly-augmented version of the same input. To produce strong augmentations,
        we propose a variant of AutoAugment which learns the augmentation
        policy while the model is being trained. Our new algorithm, dubbed ReMix-
        Match, is significantly more data-efficient than prior work, requiring between
        5  and 16  less data to reach the same accuracy.
        distributional annealing 
        First, we introduce “distribution alignment”, which encourages the distribution of a model’s aggregated
        class predictions to match the marginal distribution of ground-truth class labels. 
        To address these issues, we incorporate a form of fairness we call “distribution alignment” which
        proceeds as follows: over the course of training, we maintain a running average of the model’s
        predictions on unlabeled data, which we refer to as ~p(y) . Given the model’s prediction q =
        pmodel(yju; )  on an unlabeled example u , we scale q  by the ratio p(y)=~p(y)  and then renormalize
        the result to form a valid probability distribution: ~q = Normalize(q p(y)=~p(y))  where
         Normalize(x )i  = xi=
        P
        j xj . We then use  ~q as the label guess for u, and proceed as usual with
        sharpening and other processing. In practice, we compute  ~p (y ) as the moving average of the model’s
        predictions on unlabeled examples over the last  128 batches. We also estimate the marginal class
        distribution p (y ) based on the labeled examples seen during training. Note that a better estimate for
        p (y ) could be used if it is known a priori; in this work we do not explore this directly.
        Second, we introduce “augmentation anchoring”, which replaces the consistency regularization
        component of MixMatch. For each given unlabeled input, augmentation anchoring first generates a
        weakly augmented version (e.g. using only a flip and a crop) and then generates multiple strongly
        augmented versions. The model’s prediction for the weakly-augmented input is treated as the basis of the guessed label for all of the strongly augmented versions. To generate strong augmentations,
        we introduce a variant of AutoAugment (Cubuk et al., 2018) based on control theory which we dub
        “CTAugment”. Unlike AutoAugment, CTAugment learns an augmentation policy alongside model
        training, making it particularly convenient in SSL settings.
         We hypothesize the reason MixMatch with AutoAugment is unstable is that MixMatch averages the
        prediction across K  augmentations. Stronger augmentation can result in disparate predictions, so
        their average may not be a meaningful target. Instead, given an unlabeled input we first generate an
        “anchor” by applying weak augmentation to it. Then, we generate K  strongly-augmented versions
        of the same unlabeled input using CTAugment (described below). We use the guessed label (after
        applying distribution alignment and sharpening) as the target for all of the K  strongly-augmented
        versions of the image. This process is visualized in fig. 2.
        While experimenting with Augmentation Anchoring, we found it enabled us to replace MixMatch’s
        unlabeled-data mean squared error loss with a standard cross-entropy loss. This maintained stability
        while also simplifying the implementation. While MixMatch achieved its best performance at only
        K = 2 , we found that augmentation anchoring benefited from a larger value of K = 8 . We compare
        different values of K  in section 4 to measure the gain achieved from additional augmentations.
        
        ROTATION LOSS
         Rotation loss Recent result have shown that applying ideas from self-supervised learning to SSL
        can produce strong performance (Gidaris et al., 2018; Zhai et al., 2019). We integrate this idea
        by rotating each image u 2 ^ U1 as Rotate(u; r) where we sample the rotation angle r uniformly
        from r f0; 90; 180; 270g and then ask the model to predict the rotation amount as a four-class
        classification problem.
        algorithm pseudo code
            \cite{ReMixMatch}