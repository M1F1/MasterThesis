{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemiSupervisedComposableFramework.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_DWq_Q17ENpc",
        "_9cu0GG3qjHz",
        "aHn7X8Oc2IJN",
        "AhTVU9r32eyI",
        "8blDj0ji58J4",
        "AjAj0j4L5vTG"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ccb23d2bd3664952b40ce32f63d5e311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_15db53f73b5745a09842c08dc689cbd4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0e18e37d196446d95345029358ba918",
              "IPY_MODEL_d3a6e8c21ce6414997e6e3f6dc26bea0"
            ]
          }
        },
        "15db53f73b5745a09842c08dc689cbd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "f0e18e37d196446d95345029358ba918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_77f22d80472f408cb4d4bc7678814418",
            "_dom_classes": [],
            "description": "Validation sanity check: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ff83b28b8c643cf84f562c324053f56"
          }
        },
        "d3a6e8c21ce6414997e6e3f6dc26bea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9bdfb72e1c6e4aa09996238a1d58c812",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:07&lt;00:00,  3.83s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d63aaf40920a4747b94f8e9ef9541c71"
          }
        },
        "77f22d80472f408cb4d4bc7678814418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ff83b28b8c643cf84f562c324053f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bdfb72e1c6e4aa09996238a1d58c812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d63aaf40920a4747b94f8e9ef9541c71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c209f4d221a24d3d8e30fd82191b0549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_452c2f73bbf049849ea49aff316e17b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5475fc6bbad4e57bb707b5be32b4b7c",
              "IPY_MODEL_a4e41a3ff852408f98db6fb713cfa6a1"
            ]
          }
        },
        "452c2f73bbf049849ea49aff316e17b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e5475fc6bbad4e57bb707b5be32b4b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0bac890337944a4e813bb2e752996f81",
            "_dom_classes": [],
            "description": "Epoch 20:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 62,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_699f19fda48444548c3a8ae1497dcee0"
          }
        },
        "a4e41a3ff852408f98db6fb713cfa6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c31f8c50e8684b808a60ac212d2240e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/62 [00:02&lt;?, ?it/s, loss=0.661, v_num=3lv38wyt, val_loss=0.681, val_accuracy_error=0.445, val_f1_error=0.445, val_recall_error=0.445, val_precision_error=0.445, val_max_confident=0.57, val_min_confident=0.502, val_mean_confident=0.527, val_std_confident=0.0195]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_819469515a9b4f058c8f7b5838f50d72"
          }
        },
        "0bac890337944a4e813bb2e752996f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "699f19fda48444548c3a8ae1497dcee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c31f8c50e8684b808a60ac212d2240e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "819469515a9b4f058c8f7b5838f50d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "102ba5246571456ea1fad3ba350240d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9604f46d1dc043dfbacad9dffb9fb079",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4c343c24184744b2b4797f963cf5d47d",
              "IPY_MODEL_b689fe3bea5a42039c7d48078e2147ed"
            ]
          }
        },
        "9604f46d1dc043dfbacad9dffb9fb079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "4c343c24184744b2b4797f963cf5d47d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b97a68ee35a641958ce5bc405bc8c2a9",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21693a05e55f41fe88d00478369e1491"
          }
        },
        "b689fe3bea5a42039c7d48078e2147ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a76609c8ee14f3c95e5bb77d0e56cbe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.15s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6f5eb677ce54938975342288df58e66"
          }
        },
        "b97a68ee35a641958ce5bc405bc8c2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21693a05e55f41fe88d00478369e1491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a76609c8ee14f3c95e5bb77d0e56cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6f5eb677ce54938975342288df58e66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d8b7d2266e140f9bda3d3b25cf6e1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_046459bd34244f7ea2fc4ca110045aa3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9c3cdb42b0c45f480cec65b171b8130",
              "IPY_MODEL_a069eb6ac0b94200bddea9692ed25094"
            ]
          }
        },
        "046459bd34244f7ea2fc4ca110045aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "b9c3cdb42b0c45f480cec65b171b8130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0f4820fbc24f4b0a843510ee4c5866f7",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09c1f8af23584e63b20afc2918f11ebf"
          }
        },
        "a069eb6ac0b94200bddea9692ed25094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f9915dbf25624894a875884cb9efe5db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.14s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_452816a5a1e541358a33f13bd00079db"
          }
        },
        "0f4820fbc24f4b0a843510ee4c5866f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09c1f8af23584e63b20afc2918f11ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9915dbf25624894a875884cb9efe5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "452816a5a1e541358a33f13bd00079db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcf6618e3db244e4a32efc4b5eb9c41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a68bed56f4df4dcfbb36026b7e03f8de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e310af69b8af49868004f3b492ca3d21",
              "IPY_MODEL_a0fabfd8580f4717b984556ede8a1221"
            ]
          }
        },
        "a68bed56f4df4dcfbb36026b7e03f8de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e310af69b8af49868004f3b492ca3d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89512d11c2f34e1fba7c001a82cc47b3",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_356009deb2444eb79d262fc0465c5429"
          }
        },
        "a0fabfd8580f4717b984556ede8a1221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4326cf3e2d6c4b5d8f52d15b6a3261ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e2dbe11837b473b8365fa3efba99508"
          }
        },
        "89512d11c2f34e1fba7c001a82cc47b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "356009deb2444eb79d262fc0465c5429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4326cf3e2d6c4b5d8f52d15b6a3261ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e2dbe11837b473b8365fa3efba99508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "142d18ceab09490d848d6ba07382833b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d3635d58791447fdb82303634e0c596b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d1b17a91dc7464dbaae5f6ced020c11",
              "IPY_MODEL_a9eb7b2e332f4a9aacb95777aee9bc6e"
            ]
          }
        },
        "d3635d58791447fdb82303634e0c596b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "8d1b17a91dc7464dbaae5f6ced020c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9597b48314f5437f9d2b6f4b0a1451c2",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f418f8306fba4d7686b995442c22e8d3"
          }
        },
        "a9eb7b2e332f4a9aacb95777aee9bc6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f8ab160ffa145e696aaf1890126e5a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aeae74414d7d4e8b8804f864134d0234"
          }
        },
        "9597b48314f5437f9d2b6f4b0a1451c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f418f8306fba4d7686b995442c22e8d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f8ab160ffa145e696aaf1890126e5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aeae74414d7d4e8b8804f864134d0234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f877548252504fccaca2d072f4c4237a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a02a07d529184b24b65e6b7a36ddfdc2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0722969be7fa4b29b2684979052a0f1e",
              "IPY_MODEL_284bcb9cfaf9429b93227de27a44ee49"
            ]
          }
        },
        "a02a07d529184b24b65e6b7a36ddfdc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "0722969be7fa4b29b2684979052a0f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95f91510811b491f8fd30aa8851a7f34",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe256bb1db8e460d8e6d9c758fcc773a"
          }
        },
        "284bcb9cfaf9429b93227de27a44ee49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f32c21b90ef4a70961205c7453db1ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.05it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfde523e820b4666a1ace486c6e2ac53"
          }
        },
        "95f91510811b491f8fd30aa8851a7f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe256bb1db8e460d8e6d9c758fcc773a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f32c21b90ef4a70961205c7453db1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfde523e820b4666a1ace486c6e2ac53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d462a2e459649d99737552ff0be0028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_69c8a3a30c8643ff978ced9a2e06fd54",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c7ad61836ce4ef8883f6b73aa49883b",
              "IPY_MODEL_27c55514fc244b92a06dd0f1d3d4ed64"
            ]
          }
        },
        "69c8a3a30c8643ff978ced9a2e06fd54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "0c7ad61836ce4ef8883f6b73aa49883b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d860f0d91e3541a78bf2b78bcdd3bb02",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d2483f903e642c8bfd4c494278c636c"
          }
        },
        "27c55514fc244b92a06dd0f1d3d4ed64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95a55d5996bf452bac8ceb89bbd5b308",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.15s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b237977c3fd94faa89c9dcb9eb7f4923"
          }
        },
        "d860f0d91e3541a78bf2b78bcdd3bb02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d2483f903e642c8bfd4c494278c636c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95a55d5996bf452bac8ceb89bbd5b308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b237977c3fd94faa89c9dcb9eb7f4923": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c991ccf612ce45c2a0cd0f555901f3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad42b2cc1f7a44d2ad0208bf269d2dd6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1d1b2b66f5f04b288f2ec468235a5fad",
              "IPY_MODEL_b61251b09cdd4dcd8db270235716a0f0"
            ]
          }
        },
        "ad42b2cc1f7a44d2ad0208bf269d2dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "1d1b2b66f5f04b288f2ec468235a5fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3146a9f4f0924a77810164d2835b220a",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_193e44e86cc744388aad899880e4bf1e"
          }
        },
        "b61251b09cdd4dcd8db270235716a0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c5655f54cec4d039da8e14ab7aa0bd9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_927d23a9e25f4098b69e4f06b0ca6f85"
          }
        },
        "3146a9f4f0924a77810164d2835b220a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "193e44e86cc744388aad899880e4bf1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c5655f54cec4d039da8e14ab7aa0bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "927d23a9e25f4098b69e4f06b0ca6f85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9520c8c49c9343d6a4832f2dab5809c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1fd89f5e3e074e2b8e97ebcb4318a7ee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3cf10af0fbd044d0b6e4e328a49d826f",
              "IPY_MODEL_b81b89f870de42acb39e514b05bcba61"
            ]
          }
        },
        "1fd89f5e3e074e2b8e97ebcb4318a7ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "3cf10af0fbd044d0b6e4e328a49d826f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc4be049540d41e49a7370f63185755f",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75ef56e0830e49a5afd7dd2a019ba5f2"
          }
        },
        "b81b89f870de42acb39e514b05bcba61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f17a4cab2bb4777af77e94f135cc558",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0fb4f00871cc44659835a0b2f698066a"
          }
        },
        "cc4be049540d41e49a7370f63185755f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75ef56e0830e49a5afd7dd2a019ba5f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f17a4cab2bb4777af77e94f135cc558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0fb4f00871cc44659835a0b2f698066a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6946cba2a68a421f9ec1703c17056379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_262e3d2c427e41ec9c1fad58ba7f53bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a3e140e9cb2a4df7b81f73572597960f",
              "IPY_MODEL_bd23209c736a425ebebe3f5152701c20"
            ]
          }
        },
        "262e3d2c427e41ec9c1fad58ba7f53bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "a3e140e9cb2a4df7b81f73572597960f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0fe2e60191814208914553232e495b86",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0a45a8a98d541e990130c6860ca6210"
          }
        },
        "bd23209c736a425ebebe3f5152701c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e773c5c11514094a0d71b58ef737f45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.24it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_191b502762c44738b1555fa754bb86fc"
          }
        },
        "0fe2e60191814208914553232e495b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0a45a8a98d541e990130c6860ca6210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e773c5c11514094a0d71b58ef737f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "191b502762c44738b1555fa754bb86fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47faede77945479bb9080703299e3147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6e72c33bd2a4398bc065166cb277675",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2e78bc39821f48ad992436add7480e59",
              "IPY_MODEL_52ba0a87cf494110a22c42db6b17d571"
            ]
          }
        },
        "d6e72c33bd2a4398bc065166cb277675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "2e78bc39821f48ad992436add7480e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_01ade2d865774b21a374083d6b346741",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b943ddf1dcde49ca83993c3a6834f2a3"
          }
        },
        "52ba0a87cf494110a22c42db6b17d571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b90920772a94e098af162a55bd41be4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.14s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_600e40fb36014ddcbaa516ba79c48ab9"
          }
        },
        "01ade2d865774b21a374083d6b346741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b943ddf1dcde49ca83993c3a6834f2a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b90920772a94e098af162a55bd41be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "600e40fb36014ddcbaa516ba79c48ab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3739205ae04b4e30bd309a12118ebc7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29c78beeabcf4b1e92d8e1be4399ec81",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_67d069e61cad43cebb88bfbe66829548",
              "IPY_MODEL_d51e93e261a54eae97d9ed6b63d1d7c7"
            ]
          }
        },
        "29c78beeabcf4b1e92d8e1be4399ec81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "67d069e61cad43cebb88bfbe66829548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_efbf16e0c5484b1584b2e008b6916d17",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1823dde075af45e184982f3ba852be8b"
          }
        },
        "d51e93e261a54eae97d9ed6b63d1d7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a5d2ec0ec2d34e2686e068172e64900c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7e582ae60a147d0b3776700ce96cc1e"
          }
        },
        "efbf16e0c5484b1584b2e008b6916d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1823dde075af45e184982f3ba852be8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5d2ec0ec2d34e2686e068172e64900c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7e582ae60a147d0b3776700ce96cc1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4875a1fa14c44235903da90d5476c5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a2c92d4f1b3437f9edfa17d246bd7f6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ad804deaa56543b0aea4a1637b390ad2",
              "IPY_MODEL_5bd54dd59b054f84a144aed7087f4783"
            ]
          }
        },
        "9a2c92d4f1b3437f9edfa17d246bd7f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "ad804deaa56543b0aea4a1637b390ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1c7ef8df66cd48268cc0d5c5f9e1e772",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ac3a60e85a24b53aaaade4518ca897f"
          }
        },
        "5bd54dd59b054f84a144aed7087f4783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_576bbc64bf4c46e29bf4e75facff3ef2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_506bb610461640cc9792e3f6f63069ef"
          }
        },
        "1c7ef8df66cd48268cc0d5c5f9e1e772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ac3a60e85a24b53aaaade4518ca897f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "576bbc64bf4c46e29bf4e75facff3ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "506bb610461640cc9792e3f6f63069ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ab3f70501f7463b9ce45cc8cb05ecae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe723c8a30a945c68a4e3868c50a9bdb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1286adbcf69d45249306a479c3599d4b",
              "IPY_MODEL_e3a1d4a1c5bf44ddafeb089b9dd1fb13"
            ]
          }
        },
        "fe723c8a30a945c68a4e3868c50a9bdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "1286adbcf69d45249306a479c3599d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_481202dbb6d84c388d54f60c14a6198a",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a5a7701d3dc4c3ba35849c44edbada6"
          }
        },
        "e3a1d4a1c5bf44ddafeb089b9dd1fb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7429892e32da497da4518f5a46021316",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.09s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3fe4339b94a84240babd514bb8aa3fe2"
          }
        },
        "481202dbb6d84c388d54f60c14a6198a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a5a7701d3dc4c3ba35849c44edbada6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7429892e32da497da4518f5a46021316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3fe4339b94a84240babd514bb8aa3fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3b1d1c4392843889d3e20568e242ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e180856f32da4d93a6d7c16e72d390c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a4183239b34a482e90f314e481bcb41a",
              "IPY_MODEL_a4170f571e394c36a3a06f5a401a7df9"
            ]
          }
        },
        "e180856f32da4d93a6d7c16e72d390c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "a4183239b34a482e90f314e481bcb41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc2d47376a084d44bdb8c8c1c40d38a1",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9c46420abea47679175fb1172407e7a"
          }
        },
        "a4170f571e394c36a3a06f5a401a7df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c158a90fa2e49cb931f6759c2b96c7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f19279518a4c42ab954681e1cc4247fb"
          }
        },
        "fc2d47376a084d44bdb8c8c1c40d38a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9c46420abea47679175fb1172407e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c158a90fa2e49cb931f6759c2b96c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f19279518a4c42ab954681e1cc4247fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a78e4fbd75de4ce7bd85b4a0ad42219e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_db12a09cc1224d65a2735ecad9cb5bc4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51a2ee2b50d849069102e2c19483487f",
              "IPY_MODEL_d09ba6c300b540f8b55ba75349a0e74e"
            ]
          }
        },
        "db12a09cc1224d65a2735ecad9cb5bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "51a2ee2b50d849069102e2c19483487f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b5d354a4aa6e45608b5cb62a3a6efd4c",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5dc211aa75fe43ab85802e89cbb452eb"
          }
        },
        "d09ba6c300b540f8b55ba75349a0e74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_abbe91a5479446ab87f5fcabe4c68069",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a8707dd35e547509d96365c003a113a"
          }
        },
        "b5d354a4aa6e45608b5cb62a3a6efd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5dc211aa75fe43ab85802e89cbb452eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abbe91a5479446ab87f5fcabe4c68069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a8707dd35e547509d96365c003a113a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4538294c30d4fe393c94cf4ac04c734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3e85a86402b443719ff00d3b3ae24fb9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e786fff8a20b43c0b51fae73efbe8acf",
              "IPY_MODEL_185ae6085f4c4fb59c7c9b11014bf6b2"
            ]
          }
        },
        "3e85a86402b443719ff00d3b3ae24fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e786fff8a20b43c0b51fae73efbe8acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6bf2a9a3c7540459b858b5af4506a96",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8de7cdb96d574acea2cadac03203d5b0"
          }
        },
        "185ae6085f4c4fb59c7c9b11014bf6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5f22d1af25949b99ff6f12e8e182e92",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a23dc0a026c4a8a8b35d6a542b43f78"
          }
        },
        "e6bf2a9a3c7540459b858b5af4506a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8de7cdb96d574acea2cadac03203d5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5f22d1af25949b99ff6f12e8e182e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a23dc0a026c4a8a8b35d6a542b43f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "589bc446802648d0b4dd357cb313cf8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_38d8548fbe154c26ab1df93d7cb38c03",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_47a68c1dc5c54276b82ba85c933914e5",
              "IPY_MODEL_2b59c7597e544938adb357571aa62ded"
            ]
          }
        },
        "38d8548fbe154c26ab1df93d7cb38c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "47a68c1dc5c54276b82ba85c933914e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4325f9011a1d4609ba8e7d2d01a4c400",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6de36b99e6964d95ae9e7d4764560b74"
          }
        },
        "2b59c7597e544938adb357571aa62ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b0ab178ce1ce482184111edc5ad53f9b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.29it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43f0a71dbf344a42bf130926490e76bc"
          }
        },
        "4325f9011a1d4609ba8e7d2d01a4c400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6de36b99e6964d95ae9e7d4764560b74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0ab178ce1ce482184111edc5ad53f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43f0a71dbf344a42bf130926490e76bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "157352ae341942688234a2f1d4ec8a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b47ed1a9a3d44370833fd9ce5ab89769",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bae239a27d0b49ada102e5b60078049f",
              "IPY_MODEL_abaab506a88242e8bfbea044705ae0dc"
            ]
          }
        },
        "b47ed1a9a3d44370833fd9ce5ab89769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "bae239a27d0b49ada102e5b60078049f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_09266302e4bf4a5d93e8d2c4ad3b02ec",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa8dbd0636e04bb69c374991f0a6657a"
          }
        },
        "abaab506a88242e8bfbea044705ae0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c04996d0eb1407c9e976e326ba237cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d7db01e77774d5380bc3a63239b68d5"
          }
        },
        "09266302e4bf4a5d93e8d2c4ad3b02ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa8dbd0636e04bb69c374991f0a6657a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c04996d0eb1407c9e976e326ba237cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d7db01e77774d5380bc3a63239b68d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c233cc569cd44d328d7e9e5c036c2506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95b86536fdd24ab09ef05fbf45ba5a06",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5360a12f0e9d4f7c9202d592dbee1fe3",
              "IPY_MODEL_aab5b732ef2c487f91e0e836478023f7"
            ]
          }
        },
        "95b86536fdd24ab09ef05fbf45ba5a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "5360a12f0e9d4f7c9202d592dbee1fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa22bd175b1343a8b67799f78f1ee039",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f51869fc4740430dbd22d33f2400ec8b"
          }
        },
        "aab5b732ef2c487f91e0e836478023f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ddf80480661148fe8e26c285334d164c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:07&lt;00:00,  1.16s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e25bbc16d5544408b98a8af6dd7d49b7"
          }
        },
        "aa22bd175b1343a8b67799f78f1ee039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f51869fc4740430dbd22d33f2400ec8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddf80480661148fe8e26c285334d164c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e25bbc16d5544408b98a8af6dd7d49b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7f3a1829cb44a20a064b4ece2ee40a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_385e92e1a9d64900ae0417ab2572b9bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9fa28873fc164f38bb8a627173157a19",
              "IPY_MODEL_8879a680c7d54d2d855d48f09626c6df"
            ]
          }
        },
        "385e92e1a9d64900ae0417ab2572b9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "9fa28873fc164f38bb8a627173157a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d7cfcbdbd5647369f6fb2cc6e1268ca",
            "_dom_classes": [],
            "description": "Testing: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_914b8549ec1e4701a31d76cad4ceb199"
          }
        },
        "8879a680c7d54d2d855d48f09626c6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_321320e563e048469cb4481fe3a93c68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3be769bb141e47c9ab3f8ce973a9a3b7"
          }
        },
        "9d7cfcbdbd5647369f6fb2cc6e1268ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "914b8549ec1e4701a31d76cad4ceb199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "321320e563e048469cb4481fe3a93c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3be769bb141e47c9ab3f8ce973a9a3b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M1F1/MasterThesis/blob/master/SemiSupervisedComposableFrameworkWithMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmIolHgLI6Yn",
        "colab_type": "text"
      },
      "source": [
        "### Setup env "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE7eYLcuXnX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "b73c8184-0b21-48ba-9c90-0807a383f8dd"
      },
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "import pkg_resources\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if importlib.util.find_spec('wandb') is None:\n",
        "  !pip install wandb\n",
        "\n",
        "!wandb login\n",
        "\n",
        "if importlib.util.find_spec('neptune') is None:\n",
        "  !pip install neptune-client\n",
        "\n",
        "\n",
        "if importlib.util.find_spec('pytorch_lightning') is None:\n",
        "  !pip install pytorch-lightning\n",
        "\n",
        "if importlib.util.find_spec('logzero') is None:\n",
        "  !pip install logzero \n",
        "\n",
        "if importlib.util.find_spec('tensorboardX') is None:\n",
        "  !pip install tensorboardX \n",
        "\n",
        "# if importlib.util.find_spec('lineflow') is None:\n",
        "!pip install lineflow\n",
        "\n",
        "if importlib.util.find_spec('optuna') is None:\n",
        "  !pip install optuna\n",
        "\n",
        "#if importlib.util.find_spec('gdown') is None:\n",
        "!pip install gdown==3.11.0\n",
        "  \n",
        "if importlib.util.find_spec('transformers') is None:\n",
        "  !pip install transformers \n",
        "  \n",
        "if importlib.util.find_spec('nlpaug') is None:\n",
        "  !pip install nlpaug \n",
        "\n",
        "if importlib.util.find_spec('torchtest') is None:\n",
        "  !pip install torchtest \n",
        "\n",
        "import gdown\n",
        "import contextlib\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "from functools import partial\n",
        "from collections import OrderedDict\n",
        "from typing import Dict\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "import pprint\n",
        "from functools import wraps\n",
        "from timeit import default_timer as timer\n",
        "from typing import List, Set, Dict, Tuple, Optional\n",
        "\n",
        "import lineflow as lf\n",
        "import lineflow.datasets as lfds\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, RandomSampler, Dataset, sampler, ConcatDataset\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.optim.lr_scheduler import _LRScheduler, LambdaLR\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "from sklearn import preprocessing\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "if pkg_resources.parse_version(pl.__version__) < pkg_resources.parse_version(\"0.7.1\"):\n",
        "  raise RuntimeError(\"PyTorch Lightning>=0.7.1 is required for this code.\")\n",
        "from pytorch_lightning import LightningModule\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning import Callback\n",
        "from pytorch_lightning.callbacks import LearningRateLogger\n",
        "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
        "\n",
        "from gensim.utils import tokenize as gensim_tokenizer\n",
        "import gensim\n",
        "from gensim.models.fasttext import FastText as FT_gensim\n",
        "\n",
        "from transformers import BertModel, BertTokenizer, RobertaTokenizer, RobertaModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup \n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import operator\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import toolz\n",
        "from toolz import partial, compose, juxt, curry\n",
        "import optuna\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.model.word_stats as nmw\n",
        "import nlpaug.flow as nafc\n",
        "from nlpaug.util import Action\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "!pip freeze > requirements.txt\n",
        "\n",
        "os.environ['PROJECT_PATH'] = str(Path()/'gdrive'/'My Drive'/'praca_magisterska'/'pytorch_lightning')\n",
        "os.environ['DATASETS_PATH'] = str(Path()/'gdrive'/'My Drive'/'praca_magisterska'/'pytorch_lightning'/'datasets')\n",
        "os.environ['REQUIREMENTS_PATH'] = str(Path()/'requirements.txt')\n",
        "os.environ['MODEL_CHECKPOINT_PATH'] = str(Path()/'model_checkpoints')\n",
        "os.environ['SPELLING_PATH'] = str(Path()/'gdrive'/'My Drive'/'praca_magisterska'/'pytorch_lightning'/'nlpaug'/'spelling_en.txt') \n",
        "os.environ['NLPAUG_PATH'] = str(Path()/'gdrive'/'My Drive'/'praca_magisterska'/'pytorch_lightning'/'nlpaug')\n",
        "artefacts_temp_dir = os.path.join(os.environ['PROJECT_PATH'], 'parametrized_nbs')\n",
        "\n",
        "neptune_api_token_key_file = str(Path()/'gdrive'/'My Drive'/'praca_magisterska'/'neptune_api_token.txt')\n",
        "with open (neptune_api_token_key_file, 'r') as f:\n",
        "  os.environ['NEPTUNE_API_TOKEN'] = f.readlines()[0]\n",
        "\n",
        "if not os.path.exists(artefacts_temp_dir):\n",
        "  os.makedirs(artefacts_temp_dir)\n",
        "\n",
        "if not os.path.exists(os.environ['MODEL_CHECKPOINT_PATH']):\n",
        "  os.makedirs(os.environ['MODEL_CHECKPOINT_PATH'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "wandb: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter: 3c9e821c5866cac1e8b131c58196f26c6e9a4349\n",
            "wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "Successfully logged in to Weights & Biases!\n",
            "Requirement already satisfied: lineflow in /usr/local/lib/python3.6/dist-packages (0.6.4)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (from lineflow) (3.11.0)\n",
            "Requirement already satisfied: arrayfiles in /usr/local/lib/python3.6/dist-packages (from lineflow) (0.0.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.6/dist-packages (from gdown->lineflow) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from gdown->lineflow) (3.0.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown->lineflow) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown->lineflow) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown->lineflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown->lineflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown->lineflow) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown->lineflow) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown->lineflow) (1.7.1)\n",
            "Requirement already satisfied: gdown==3.11.0 in /usr/local/lib/python3.6/dist-packages (3.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown==3.11.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown==3.11.0) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from gdown==3.11.0) (3.0.12)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.6/dist-packages (from gdown==3.11.0) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown==3.11.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown==3.11.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown==3.11.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown==3.11.0) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown==3.11.0) (1.7.1)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7vhKpOlrSut",
        "colab_type": "text"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgXkuwHGrTdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_global_metric(outputs, metric):\n",
        "    return sum([out[metric] for out in outputs]) / len(outputs)\n",
        "\n",
        "\n",
        "def create_metrics_dict(phase_type: str, loss, labels, labels_hat, max_probs) -> dict:\n",
        "\n",
        "    output_dict = {f'{phase_type}_loss': loss}\n",
        "    \n",
        "    metrics_keys = [\n",
        "                    f'{phase_type}_accuracy_error',\n",
        "                    f'{phase_type}_f1_error',\n",
        "                    f'{phase_type}_recall_error',\n",
        "                    f'{phase_type}_precision_error'\n",
        "                   ]\n",
        "\n",
        "    error_map = lambda x: 1-x\n",
        "\n",
        "    error_metrics_values = juxt(\n",
        "                                compose(error_map, partial(accuracy_score)),\n",
        "                                compose(error_map, partial(f1_score, **{'average':'micro'})),\n",
        "                                compose(error_map, partial(recall_score, **{'average':'micro'})),\n",
        "                                compose(error_map, partial(precision_score, **{'average':'micro'}))\n",
        "                               )(labels, labels_hat)\n",
        "\n",
        "\n",
        "    output_dict.update(dict(zip(metrics_keys, error_metrics_values)))\n",
        "\n",
        "    confident_keys = [\n",
        "                      f'{phase_type}_max_confident',\n",
        "                      f'{phase_type}_min_confident',\n",
        "                      f'{phase_type}_mean_confident',\n",
        "                      f'{phase_type}_std_confident'\n",
        "                     ]\n",
        "    confident_values = toolz.juxt(\n",
        "                                  np.max,\n",
        "                                  np.min, \n",
        "                                  np.mean,\n",
        "                                  np.std,\n",
        "                                 )(max_probs)\n",
        "\n",
        "    output_dict.update(dict(zip(confident_keys, confident_values)))\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "def tfidf_tokenizer(text, token_pattern=r\"(?u)\\b\\w\\w+\\b\"):\n",
        "    token_pattern = re.compile(token_pattern)\n",
        "    return token_pattern.findall(text)\n",
        "\n",
        "\n",
        "def create_tfidf_model(df: pd.DataFrame):  \n",
        "  train_data = df['text'] \n",
        "  train_x = train_data.values\n",
        "    \n",
        "  train_x_tokens = [tfidf_tokenizer(x) for x in train_x]\n",
        "    \n",
        "  tfidf_model = nmw.TfIdf()\n",
        "  tfidf_model.train(train_x_tokens)\n",
        "  tfidf_model.save(os.environ['NLPAUG_PATH'])\n",
        "  os.environ['TFIDF_MODEL_PATH']  = os.path.join(os.environ['NLPAUG_PATH'], 'tfidfaug_w2tfidf.txt')\n",
        "  os.listdir(os.environ['NLPAUG_PATH'])\n",
        "\n",
        "\n",
        "class MetricsCallback(Callback):\n",
        "    \"\"\"PyTorch Lightning metric callback.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.metrics = []\n",
        "\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        self.metrics.append(trainer.callback_metric)\n",
        "\n",
        "\n",
        "# credits:\n",
        "# https://github.com/galatolofederico/pytorch-balanced-batch/blob/master/sampler.py        \n",
        "#-------------------------------------------------------------------------------\n",
        "class BalancedBatchSampler(torch.utils.data.sampler.Sampler):\n",
        "    def __init__(self, dataset, labels=None):\n",
        "        self.labels = labels\n",
        "        self.dataset = dict()\n",
        "        self.balanced_max = 0\n",
        "        # Save all the indices for all the classes\n",
        "        for idx in range(0, len(dataset)):\n",
        "            label = self._get_label(dataset, idx)\n",
        "            if label not in self.dataset:\n",
        "                self.dataset[label] = list()\n",
        "            self.dataset[label].append(idx)\n",
        "            self.balanced_max = len(self.dataset[label]) \\\n",
        "                if len(self.dataset[label]) > self.balanced_max else self.balanced_max\n",
        "        \n",
        "        # Oversample the classes with fewer elements than the max\n",
        "        for label in self.dataset:\n",
        "            while len(self.dataset[label]) < self.balanced_max:\n",
        "                self.dataset[label].append(random.choice(self.dataset[label]))\n",
        "        self.keys = list(self.dataset.keys())\n",
        "        self.currentkey = 0\n",
        "        self.indices = [-1]*len(self.keys)\n",
        "\n",
        "    def __iter__(self):\n",
        "        while self.indices[self.currentkey] < self.balanced_max - 1:\n",
        "            self.indices[self.currentkey] += 1\n",
        "            yield self.dataset[self.keys[self.currentkey]][self.indices[self.currentkey]]\n",
        "            self.currentkey = (self.currentkey + 1) % len(self.keys)\n",
        "        self.indices = [-1]*len(self.keys)\n",
        "    \n",
        "    def _get_label(self, dataset, idx, labels = None):\n",
        "        if self.labels is not None:\n",
        "            return self.labels[idx].item()\n",
        "        else:\n",
        "            raise Exception(\"You should pass the tensor of labels to the constructor as second argument\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.balanced_max*len(self.keys)\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# credits:\n",
        "# https://github.com/pytorch/pytorch/issues/3223\n",
        "#-------------------------------------------------------------------------------\n",
        "def size_splits(tensor, split_sizes, dim=0):\n",
        "    \"\"\"Splits the tensor according to chunks of split_sizes.\n",
        "    \n",
        "    Arguments:\n",
        "        tensor (Tensor): tensor to split.\n",
        "        split_sizes (list(int)): sizes of chunks\n",
        "        dim (int): dimension along which to split the tensor.\n",
        "    \"\"\"\n",
        "    if dim < 0:\n",
        "        dim += tensor.dim()\n",
        "    \n",
        "    dim_size = tensor.size(dim)\n",
        "    if dim_size != torch.sum(torch.Tensor(split_sizes)):\n",
        "        raise KeyError(\"Sum of split sizes exceeds tensor dim\")\n",
        "    \n",
        "    splits = torch.cumsum(torch.Tensor([0] + split_sizes), dim=0)[:-1]\n",
        "\n",
        "    return tuple(tensor.narrow(int(dim), int(start), int(length)) \n",
        "        for start, length in zip(splits, split_sizes))\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# credits:\n",
        "# Modified StepLR from https://pytorch.org/docs/stable/optim.html\n",
        "#-------------------------------------------------------------------------------\n",
        "class StepLR(_LRScheduler):\n",
        "    \"\"\"Decays the learning rate of each parameter group by gamma every\n",
        "    step_size epochs. Notice that such decay can happen simultaneously with\n",
        "    other changes to the learning rate from outside this scheduler. When\n",
        "    last_epoch=-1, sets initial lr as lr.\n",
        "\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        step_size (int): Period of learning rate decay.\n",
        "        gamma (float): Multiplicative factor of learning rate decay.\n",
        "            Default: 0.1.\n",
        "        last_epoch (int): The index of last epoch. Default: -1.\n",
        "\n",
        "    Example:\n",
        "        >>> # Assuming optimizer uses lr = 0.05 for all groups\n",
        "        >>> # lr = 0.05     if epoch < 30\n",
        "        >>> # lr = 0.005    if 30 <= epoch < 60\n",
        "        >>> # lr = 0.0005   if 60 <= epoch < 90\n",
        "        >>> # ...\n",
        "        >>> scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "        >>> for epoch in range(100):\n",
        "        >>>     train(...)\n",
        "        >>>     validate(...)\n",
        "        >>>     scheduler.step()\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, step_size, decay_step, gamma=0.1, last_epoch=-1):\n",
        "        self.step_size = step_size\n",
        "        self.gamma = gamma\n",
        "        # adding constant initial learning rate for n decay_step\n",
        "        self.decay_step = decay_step \n",
        "        super(StepLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if not self._get_lr_called_within_step:\n",
        "            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
        "                          \"please use `get_last_lr()`.\", UserWarning)\n",
        "            \n",
        "        if (self.optimizer._step_count < self.decay_step) or (self.last_epoch == 0) or (self.last_epoch % self.step_size != 0):\n",
        "            return [group['lr'] for group in self.optimizer.param_groups]\n",
        "            \n",
        "        return [group['lr'] * self.gamma for group in self.optimizer.param_groups]\n",
        "\n",
        "    def _get_closed_form_lr(self):\n",
        "        return [base_lr * self.gamma ** (self.last_epoch // self.step_size)\n",
        "                for base_lr in self.base_lrs]        \n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# credits:\n",
        "# https://www.kaggle.com/indralin/train-uses-tpu-in-kaggle-kernel-baseline-0-82\n",
        "#-------------------------------------------------------------------------------\n",
        "def get_cosine_schedule_with_warmup(optimizer,\n",
        "                                    num_warmup_steps,\n",
        "                                    num_training_steps,\n",
        "                                    num_cycles=7./16.,\n",
        "                                    last_epoch=-1):\n",
        "    def _lr_lambda(current_step):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        no_progress = float(current_step - num_warmup_steps) / \\\n",
        "            float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0., math.cos(math.pi * num_cycles * no_progress))\n",
        "\n",
        "    return LambdaLR(optimizer, _lr_lambda, last_epoch)\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# credits:\n",
        "# https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n",
        "#-------------------------------------------------------------------------------\n",
        "def build_vocab(sentences, verbose =  True):\n",
        "    \"\"\"\n",
        "    :param sentences: list of list of words\n",
        "    :return: dictionary of words and their count\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except KeyError:\n",
        "                vocab[word] = 1\n",
        "    return vocab\n",
        "\n",
        "def check_coverage(vocab,embeddings_index):\n",
        "    a = {}\n",
        "    oov = {}\n",
        "    k = 0\n",
        "    i = 0\n",
        "    for word in tqdm(vocab):\n",
        "        try:\n",
        "            a[word] = embeddings_index[word]\n",
        "            k += vocab[word]\n",
        "        except:\n",
        "\n",
        "            oov[word] = vocab[word]\n",
        "            i += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
        "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
        "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return sorted_x\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def get_ft_vectors():\n",
        "    source ='./cc.en.300.vec' \n",
        "    my_file = Path(source)\n",
        "    if not my_file.is_file():\n",
        "      !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
        "      !gunzip -k cc.en.300.vec.gz\n",
        "\n",
        "    def get_coefs(word,*arr):\n",
        "       return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(source) if len(o)>100)\n",
        "\n",
        "    return embeddings_index\n",
        "\n",
        "def create_ft_embeder():\n",
        "  source ='./cc.en.300.bin' \n",
        "  my_file = Path(source)\n",
        "  if not my_file.is_file():\n",
        "    !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "    !gunzip -k cc.en.300.bin.gz\n",
        "\n",
        "  print('Loading fastText model into memory, it can take a while...')\n",
        "  start = time.time()\n",
        "  ft = gensim.models.FastText.load_fasttext_format(\"./cc.en.300.bin\")\n",
        "  end = time.time()\n",
        "  duration =  end - start\n",
        "  print(f'Loading took: {duration} s')\n",
        "\n",
        "  return ft\n",
        "  \n",
        "\n",
        "def create_spacy_nlp_embeder():\n",
        "\n",
        "  my_file = Path(\"./cc.en.300.vec\")\n",
        "  if not my_file.is_file():\n",
        "    !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
        "\n",
        "  my_file2 = Path(\"./en_vectors_wiki_lg\")\n",
        "  if not my_file2.is_file():\n",
        "    !python -m spacy init-model en /en_vectors_wiki_lg --vectors-loc cc.en.300.vec.gz\n",
        "    \n",
        "  print('Loading fastText vectors into spaCy model into memory, it can take a while...')\n",
        "  start = time.time()\n",
        "  nlp = spacy.load(\"/en_vectors_wiki_lg\")\n",
        "  end = time.time()\n",
        "  duration =  end - start\n",
        "  print(f'Loading took: {duration} s')\n",
        "  \n",
        "  return nlp \n",
        "\n",
        "# credits:\n",
        "# https://www.kaggle.com/gmhost/gru-capsule\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def load_fasttext(word_index):    \n",
        "    EMBEDDING_FILE = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
        "\n",
        "    def get_coefs(word,*arr):\n",
        "       return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
        "\n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    nb_words = min(max_features, len(word_index))\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features:\n",
        "           continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "           embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    return embedding_matrix\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def timing(f):\n",
        "    @wraps(f)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time()\n",
        "        result = f(*args, **kwargs)\n",
        "        end = time()\n",
        "        print('Elapsed time: {}'.format(end-start))\n",
        "        return result\n",
        "    return wrapper"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-bl-L6P_fZc",
        "colab_type": "text"
      },
      "source": [
        "## Data Manipulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5njzVxrJNbuU",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyI6rfO5o1mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct_abbrevation_and_mispelling(text: str) -> str: \n",
        "  # credits\n",
        "  # https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing\n",
        "  mispell_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}\n",
        "  mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
        "  return mispell_re.sub(lambda match: mispell_dict[match.group(0)], text)\n",
        "\n",
        "@curry \n",
        "def remove_stopwords(stopwords: [str], sentence: str) -> str:\n",
        "  words = word_tokenize(sentence)\n",
        "  return \" \".join([word for word in words if not word in stopwords])\n",
        "\n",
        "@curry\n",
        "def delete_stopwords_with_regex(stopwords: [str], text: str) -> str:\n",
        "  pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
        "  return pattern.sub('', text)\n",
        "\n",
        "def create_stopwords_set(stopwords=None, show_classification=False) -> Set[str]:\n",
        "  if stopwords == None:\n",
        "    # credits:\n",
        "    # https://gist.github.com/sebleier/554280\n",
        "    stopwords = [\"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"able\", \"about\", \"above\", \"abst\", \"ac\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\", \"ae\", \"af\", \"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\", \"ah\", \"ain\", \"ain't\", \"aj\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"ap\", \"apart\", \"apparently\", \"appear\", \"appreciate\", \"appropriate\", \"approximately\", \"ar\", \"are\", \"aren\", \"arent\", \"aren't\", \"arise\", \"around\", \"as\", \"a's\", \"aside\", \"ask\", \"asking\", \"associated\", \"at\", \"au\", \"auth\", \"av\", \"available\", \"aw\", \"away\", \"awfully\", \"ax\", \"ay\", \"az\", \"b\", \"b1\", \"b2\", \"b3\", \"ba\", \"back\", \"bc\", \"bd\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"believe\", \"below\", \"beside\", \"besides\", \"best\", \"better\", \"between\", \"beyond\", \"bi\", \"bill\", \"biol\", \"bj\", \"bk\", \"bl\", \"bn\", \"both\", \"bottom\", \"bp\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"bu\", \"but\", \"bx\", \"by\", \"c\", \"c1\", \"c2\", \"c3\", \"ca\", \"call\", \"came\", \"can\", \"cannot\", \"cant\", \"can't\", \"cause\", \"causes\", \"cc\", \"cd\", \"ce\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"changes\", \"ci\", \"cit\", \"cj\", \"cl\", \"clearly\", \"cm\", \"c'mon\", \"cn\", \"co\", \"com\", \"come\", \"comes\", \"con\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"corresponding\", \"could\", \"couldn\", \"couldnt\", \"couldn't\", \"course\", \"cp\", \"cq\", \"cr\", \"cry\", \"cs\", \"c's\", \"ct\", \"cu\", \"currently\", \"cv\", \"cx\", \"cy\", \"cz\", \"d\", \"d2\", \"da\", \"date\", \"dc\", \"dd\", \"de\", \"definitely\", \"describe\", \"described\", \"despite\", \"detail\", \"df\", \"di\", \"did\", \"didn\", \"didn't\", \"different\", \"dj\", \"dk\", \"dl\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\", \"done\", \"don't\", \"down\", \"downwards\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"due\", \"during\", \"dx\", \"dy\", \"e\", \"e2\", \"e3\", \"ea\", \"each\", \"ec\", \"ed\", \"edu\", \"ee\", \"ef\", \"effect\", \"eg\", \"ei\", \"eight\", \"eighty\", \"either\", \"ej\", \"el\", \"eleven\", \"else\", \"elsewhere\", \"em\", \"empty\", \"en\", \"end\", \"ending\", \"enough\", \"entirely\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"especially\", \"est\", \"et\", \"et-al\", \"etc\", \"eu\", \"ev\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"except\", \"ey\", \"f\", \"f2\", \"fa\", \"far\", \"fc\", \"few\", \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"fix\", \"fj\", \"fl\", \"fn\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"forty\", \"found\", \"four\", \"fr\", \"from\", \"front\", \"fs\", \"ft\", \"fu\", \"full\", \"further\", \"furthermore\", \"fy\", \"g\", \"ga\", \"gave\", \"ge\", \"get\", \"gets\", \"getting\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gj\", \"gl\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"gr\", \"greetings\", \"gs\", \"gy\", \"h\", \"h2\", \"h3\", \"had\", \"hadn\", \"hadn't\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasnt\", \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"hed\", \"he'd\", \"he'll\", \"hello\", \"help\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"here's\", \"hereupon\", \"hers\", \"herself\", \"hes\", \"he's\", \"hh\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \"hither\", \"hj\", \"ho\", \"home\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"how's\", \"hr\", \"hs\", \"http\", \"hu\", \"hundred\", \"hy\", \"i\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ibid\", \"ic\", \"id\", \"i'd\", \"ie\", \"if\", \"ig\", \"ignored\", \"ih\", \"ii\", \"ij\", \"il\", \"i'll\", \"im\", \"i'm\", \"immediate\", \"immediately\", \"importance\", \"important\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"insofar\", \"instead\", \"interest\", \"into\", \"invention\", \"inward\", \"io\", \"ip\", \"iq\", \"ir\", \"is\", \"isn\", \"isn't\", \"it\", \"itd\", \"it'd\", \"it'll\", \"its\", \"it's\", \"itself\", \"iv\", \"i've\", \"ix\", \"iy\", \"iz\", \"j\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \"just\", \"k\", \"ke\", \"keep\", \"keeps\", \"kept\", \"kg\", \"kj\", \"km\", \"know\", \"known\", \"knows\", \"ko\", \"l\", \"l2\", \"la\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"lb\", \"lc\", \"le\", \"least\", \"les\", \"less\", \"lest\", \"let\", \"lets\", \"let's\", \"lf\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"lj\", \"ll\", \"ll\", \"ln\", \"lo\", \"look\", \"looking\", \"looks\", \"los\", \"lr\", \"ls\", \"lt\", \"ltd\", \"m\", \"m2\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"mightn\", \"mightn't\", \"mill\", \"million\", \"mine\", \"miss\", \"ml\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"mr\", \"mrs\", \"ms\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"n\", \"n2\", \"na\", \"name\", \"namely\", \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needn\", \"needn't\", \"needs\", \"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nj\", \"nl\", \"nn\", \"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"novel\", \"now\", \"nowhere\", \"nr\", \"ns\", \"nt\", \"ny\", \"o\", \"oa\", \"ob\", \"obtain\", \"obtained\", \"obviously\", \"oc\", \"od\", \"of\", \"off\", \"often\", \"og\", \"oh\", \"oi\", \"oj\", \"ok\", \"okay\", \"ol\", \"old\", \"om\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"oo\", \"op\", \"oq\", \"or\", \"ord\", \"os\", \"ot\", \"other\", \"others\", \"otherwise\", \"ou\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"ow\", \"owing\", \"own\", \"ox\", \"oz\", \"p\", \"p1\", \"p2\", \"p3\", \"page\", \"pagecount\", \"pages\", \"par\", \"part\", \"particular\", \"particularly\", \"pas\", \"past\", \"pc\", \"pd\", \"pe\", \"per\", \"perhaps\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"placed\", \"please\", \"plus\", \"pm\", \"pn\", \"po\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"pq\", \"pr\", \"predominantly\", \"present\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"ps\", \"pt\", \"pu\", \"put\", \"py\", \"q\", \"qj\", \"qu\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"r2\", \"ra\", \"ran\", \"rather\", \"rc\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"research-articl\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"rf\", \"rh\", \"ri\", \"right\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"run\", \"rv\", \"ry\", \"s\", \"s2\", \"sa\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sensible\", \"sent\", \"serious\", \"seriously\", \"seven\", \"several\", \"sf\", \"shall\", \"shan\", \"shan't\", \"she\", \"shed\", \"she'd\", \"she'll\", \"shes\", \"she's\", \"should\", \"shouldn\", \"shouldn't\", \"should've\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"sincere\", \"six\", \"sixty\", \"sj\", \"sl\", \"slightly\", \"sm\", \"sn\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"sp\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sq\", \"sr\", \"ss\", \"st\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"sy\", \"system\", \"sz\", \"t\", \"t1\", \"t2\", \"t3\", \"take\", \"taken\", \"taking\", \"tb\", \"tc\", \"td\", \"te\", \"tell\", \"ten\", \"tends\", \"tf\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"that'll\", \"thats\", \"that's\", \"that've\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"there'll\", \"thereof\", \"therere\", \"theres\", \"there's\", \"thereto\", \"thereupon\", \"there've\", \"these\", \"they\", \"theyd\", \"they'd\", \"they'll\", \"theyre\", \"they're\", \"they've\", \"thickv\", \"thin\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"ti\", \"til\", \"tip\", \"tj\", \"tl\", \"tm\", \"tn\", \"to\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\", \"tp\", \"tq\", \"tr\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"t's\", \"tt\", \"tv\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tx\", \"u\", \"u201d\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"uo\", \"up\", \"upon\", \"ups\", \"ur\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"ut\", \"v\", \"va\", \"value\", \"various\", \"vd\", \"ve\", \"ve\", \"very\", \"via\", \"viz\", \"vj\", \"vo\", \"vol\", \"vols\", \"volumtype\", \"vq\", \"vs\", \"vt\", \"vu\", \"w\", \"wa\", \"want\", \"wants\", \"was\", \"wasn\", \"wasnt\", \"wasn't\", \"way\", \"we\", \"wed\", \"we'd\", \"welcome\", \"well\", \"we'll\", \"well-b\", \"went\", \"were\", \"we're\", \"weren\", \"werent\", \"weren't\", \"we've\", \"what\", \"whatever\", \"what'll\", \"whats\", \"what's\", \"when\", \"whence\", \"whenever\", \"when's\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"where's\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"who'll\", \"whom\", \"whomever\", \"whos\", \"who's\", \"whose\", \"why\", \"why's\", \"wi\", \"widely\", \"will\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"wo\", \"won\", \"wonder\", \"wont\", \"won't\", \"words\", \"world\", \"would\", \"wouldn\", \"wouldnt\", \"wouldn't\", \"www\", \"x\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y\", \"y2\", \"yes\", \"yet\", \"yj\", \"yl\", \"you\", \"youd\", \"you'd\", \"you'll\", \"your\", \"youre\", \"you're\", \"yours\", \"yourself\", \"yourselves\", \"you've\", \"yr\", \"ys\", \"yt\", \"z\", \"zero\", \"zi\", \"zz\"]\n",
        "  \n",
        "  sid = SentimentIntensityAnalyzer()\n",
        "  pos_word_list=[]\n",
        "  neu_word_list=[]\n",
        "  neg_word_list=[]\n",
        "  \n",
        "  for word in stopwords:\n",
        "      if (sid.polarity_scores(word)['compound']) >= 0.2:\n",
        "          pos_word_list.append(word)\n",
        "      elif (sid.polarity_scores(word)['compound']) <= -0.2:\n",
        "          neg_word_list.append(word)\n",
        "      else:\n",
        "          neu_word_list.append(word)                \n",
        "  if show_classification: \n",
        "    print('Positive :',pos_word_list)        \n",
        "    print('Neutral :',neu_word_list)    \n",
        "    print('Negative :',neg_word_list)  \n",
        "  \n",
        "  return set(stopwords) - set(pos_word_list + neg_word_list)\n",
        "\n",
        "    \n",
        "def create_dataset_preprocessor() -> str:\n",
        "  stopwords = create_stopwords_set()\n",
        "\n",
        "  remove_html_tags_re = re.compile(r'<.*?>')\n",
        "  remove_punctuation_re = re.compile(r'[^\\w\\s]+')\n",
        "  remove_extra_whitespaces_re = re.compile(r' +')\n",
        "  remove_numeric_re = re.compile(r'\\d+')\n",
        "  \n",
        "  remove_html_tags = curry(remove_html_tags_re.sub)('') \n",
        "  remove_punctuation = curry(remove_punctuation_re.sub)('') \n",
        "  remove_extra_whitespaces = curry(remove_extra_whitespaces_re.sub)(' ') \n",
        "  remove_numeric = curry(remove_numeric_re.sub)('') \n",
        "\n",
        "  preprocessing = compose(\n",
        "                          remove_stopwords(stopwords),\n",
        "                          remove_extra_whitespaces,\n",
        "                          remove_punctuation,\n",
        "                          remove_html_tags,\n",
        "                          correct_abbrevation_and_mispelling,\n",
        "                          remove_numeric,\n",
        "                          str.lower\n",
        "                        )\n",
        "  \n",
        "  return preprocessing\n",
        "\n",
        "def create_vocab_embeddings_preprocessor(tokenizer: keras.preprocessing.text.Tokenizer,\n",
        "                            hparams: dict) -> np.ndarray :\n",
        "\n",
        "  create_vocab_indices_sequence = tokenizer.texts_to_sequences\n",
        "  pad_seq = curry(pad_sequences)(maxlen=hparams['maxlen'])\n",
        "\n",
        "  vocab_padded_vectorization = compose(\n",
        "                                       pad_seq,\n",
        "                                       create_vocab_indices_sequence,\n",
        "                                       lambda x: [x],\n",
        "                                      )\n",
        "  \n",
        "  return vocab_padded_vectorization \n",
        "\n",
        "\n",
        "def create_embeddings_matrix(word_index, embeder, hparams):    \n",
        "  \n",
        "    emb_mean, emb_std = hparams['emb_mean'], hparams['emb_std']\n",
        "\n",
        "    nb_words = min(hparams['max_features'], len(word_index))\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, hparams['embed_size']))\n",
        "    for word, i in word_index.items():\n",
        "\n",
        "        if i >= hparams['max_features']:\n",
        "           continue\n",
        "\n",
        "        try:\n",
        "          embedding_vector = embeder[word]\n",
        "        except: \n",
        "          embedding_vector = None\n",
        "\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i - 1] = embedding_vector\n",
        "\n",
        "    return embedding_matrix"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnm0S8FesJ7_",
        "colab_type": "text"
      },
      "source": [
        "### Load texts embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE6d_BsPr5tG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c9a7c411-6b0c-4faf-f1ef-5bb417df22f3"
      },
      "source": [
        "# nlp = create_spacy_nlp_embeder()\n",
        "# embedding_matrix = load_fasttext(word_index) \n",
        "embeddings_index = create_ft_embeder()\n",
        "# embeddings_index = get_ft_vectors()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading fastText model into memory, it can take a while...\n",
            "Loading took: 217.9109447002411 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrU1NutI_1dY",
        "colab_type": "text"
      },
      "source": [
        "### Datasets EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3KMkjEDKPoE",
        "colab_type": "text"
      },
      "source": [
        "#### IMDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isBfou21d5f7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train = lfds.Imdb('train')\n",
        "# test = lfds.Imdb('test')\n",
        "# dataset = train + test\n",
        "# ds = dataset.map(lambda x: {'text': x[0], 'label':x[1], 'tokens_len': len(list(gensim_tokenizer(x[0])))})\n",
        "# df = pd.DataFrame(ds)\n",
        "# df['tokens_len'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKH958ALCaju",
        "colab_type": "text"
      },
      "source": [
        "#### MR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QwNnk0zCYTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "outputId": "263eb79f-132d-4683-ed86-25091d6b6d63"
      },
      "source": [
        "dataset_path = str(Path()/\n",
        "                        'gdrive'/\n",
        "                        'My Drive'/\n",
        "                        'praca_magisterska'/\n",
        "                        'pytorch_lightning'/\n",
        "                        'datasets'/\n",
        "                        'mr_with_bt2.csv')\n",
        "df = pd.read_csv(dataset_path, index_col=None)\n",
        "df['totalwords'] = df['text'].str.split().str.len()\n",
        "print(df['totalwords'].describe())\n",
        "\n",
        "dataset_preprocessor = create_dataset_preprocessor()\n",
        "\n",
        "start = timer()\n",
        "df['text'] = df['text'].apply(dataset_preprocessor)\n",
        "end = timer()\n",
        "print('time: ', end - start)\n",
        "\n",
        "df['totalwords'] = df['text'].str.split().str.len()\n",
        "print(df['totalwords'].describe(percentiles=[.25, .5, .75, .90, .95, .98, .99]))\n",
        "\n",
        "sentences = df[\"text\"].progress_apply(lambda x: x.split()).values\n",
        "vocab = build_vocab(sentences)\n",
        "print(len(vocab))\n",
        "oov = check_coverage(vocab, embeddings_index)\n",
        "oov"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    2000.000000\n",
            "mean      737.534500\n",
            "std       324.113972\n",
            "min        17.000000\n",
            "25%       520.750000\n",
            "50%       688.500000\n",
            "75%       893.250000\n",
            "max      2660.000000\n",
            "Name: totalwords, dtype: float64\n",
            "time:  9.156945981998433\n",
            "count    2000.000000\n",
            "mean      279.169500\n",
            "std       120.226844\n",
            "min         4.000000\n",
            "25%       199.000000\n",
            "50%       260.500000\n",
            "75%       339.250000\n",
            "90%       424.100000\n",
            "95%       504.000000\n",
            "98%       590.000000\n",
            "99%       657.000000\n",
            "max      1175.000000\n",
            "Name: totalwords, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [00:00<00:00, 25765.83it/s]\n",
            "100%|██████████| 2000/2000 [00:00<00:00, 12775.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "46232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-83013aae62eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0moov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_coverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0moov\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N99PSDrfHyFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fd0dd74-f8af-47f5-b718-6e72dab17d14"
      },
      "source": [
        "hparams = {'maxlen': 600,\n",
        "           'max_features': 120000,\n",
        "           'embed_size': 300}\n",
        "\n",
        "# split data into train and test dataset \n",
        "train_all = df['text'].values\n",
        "# use tokenizer in the same way as label_encoder in data pipelines\n",
        "\n",
        "# create tokenizer\n",
        "tokenizer = Tokenizer(num_words=hparams['max_features'],\n",
        "                      oov_token='######')\n",
        "tokenizer.fit_on_texts(list(train_all))\n",
        "\n",
        "vocab_prepro = create_vocab_embeddings_preprocessor(tokenizer, hparams)\n",
        "\n",
        "# create embeddings matrix\n",
        "embedding_matrix = create_embeddings_matrix(tokenizer.word_index,\n",
        "                                            embeder,\n",
        "                                            hparams)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ4VNXpsOVtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_Text(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(CNN_Text, self).__init__()\n",
        "      filter_sizes = [1,2,3,5]\n",
        "      num_filters = 36\n",
        "      self.embedding = nn.Embedding(max_features, embed_size)\n",
        "      self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "      self.embedding.weight.requires_grad = False\n",
        "      self.convs1 = nn.ModuleList([nn.Conv2d(1, num_filters, (K, embed_size)) for K in filter_sizes])\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      self.fc1 = nn.Linear(len(filter_sizes)*num_filters, 1)\n",
        "  \n",
        "  \n",
        "  def forward(self, x):\n",
        "      x = self.embedding(x)  \n",
        "      x = x.unsqueeze(1)  \n",
        "      x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] \n",
        "      x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
        "      x = torch.cat(x, 1)\n",
        "      x = self.dropout(x)  \n",
        "      logit = self.fc1(x)  \n",
        "      return logit\n",
        "\n",
        "# keras model \n",
        "def create_embedding_model(vocab_size, max_length):\n",
        "    model=models.Sequential()\n",
        "    model.add(layers.Embedding(vocab_size, 100, input_length=max_length))\n",
        "    model.add(layers.Conv1D(32, 8, activation=\"relu\"))\n",
        "    model.add(layers.MaxPooling1D(2))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(10, activation=\"relu\"))\n",
        "    model.add(layers.Dense(1,  activation=\"sigmoid\"))   \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCViuaUo82Ij",
        "colab_type": "text"
      },
      "source": [
        "#### NLUHD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GdQmqGu82YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# datasets_path = str(Path()/'gdrive'/'My Drive'/'praca_magisterska'/'pytorch_lightning'/'datasets')\n",
        "# NLU_HD_path = os.path.join(datasets_path,'NLU-Data-Home-Domain-Annotated-All.csv')\n",
        "# print(NLU_HD_path)\n",
        "# # df = pd.read_csv(str(NLU_HD_path), delimiter=';')[['intent', 'answer_annotation']]\n",
        "# df = pd.read_csv(str(NLU_HD_path), delimiter=';')[['intent', 'answer_annotation', 'scenario']]\n",
        "# df['intent'] = df[['scenario', 'intent']].agg('-'.join, axis=1) \n",
        "# del df['scenario']\n",
        "# df = df[df['answer_annotation'].notna()]\n",
        "# df = df.rename(columns={\"answer_annotation\": \"text\"})\n",
        "# nlp = spacy.load(\"en\", disable=['parser', 'tagger', 'ner'])\n",
        "\n",
        "# df['text'] = df['text'].apply(normalize,\n",
        "#                               lowercase=True,\n",
        "#                               remove_stopwords=False,\n",
        "#                               with_ner_tags=False,\n",
        "#                               nlp=nlp) \n",
        "# # df.to_csv(os.path.join(datasets_path,'NLU-Data-Home-Domain-preprocessed-without-ner_no-scenario.csv'))\n",
        "# df.to_csv(os.path.join(datasets_path,'NLU-Data-Home-Domain-preprocessed-without-ner.csv'))\n",
        "# df['intent'].value_counts().plot(kind=\"bar\", figsize= (21,20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La0V7D3a6il3",
        "colab_type": "text"
      },
      "source": [
        "### FixMatch Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY4LSqfiCuZu",
        "colab_type": "text"
      },
      "source": [
        "#### FixMatch Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCDNS6xvCtVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# credits: \n",
        "# https://github.com/ildoonet/pytorch-randaugment/blob/master/RandAugment/augmentations.py\n",
        "# https://github.com/google-research/fixmatch/blob/master/third_party/auto_augment/augmentations.py\n",
        "# https://github.com/google-research/fixmatch/blob/master/libml/ctaugment.py\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "import logging\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import PIL\n",
        "import PIL.ImageOps\n",
        "import PIL.ImageEnhance\n",
        "import PIL.ImageDraw\n",
        "from PIL import Image\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "PARAMETER_MAX = 10\n",
        "\n",
        "\n",
        "def AutoContrast(img, **kwarg):\n",
        "    return PIL.ImageOps.autocontrast(img)\n",
        "\n",
        "\n",
        "def Brightness(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
        "\n",
        "\n",
        "def Color(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
        "\n",
        "\n",
        "def Contrast(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
        "\n",
        "\n",
        "def Cutout(img, v, max_v, bias=0):\n",
        "    if v == 0:\n",
        "        return img\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    v = int(v * min(img.size))\n",
        "    return CutoutAbs(img, v)\n",
        "\n",
        "\n",
        "def CutoutAbs(img, v, **kwarg):\n",
        "    w, h = img.size\n",
        "    x0 = np.random.uniform(0, w)\n",
        "    y0 = np.random.uniform(0, h)\n",
        "    x0 = int(max(0, x0 - v / 2.))\n",
        "    y0 = int(max(0, y0 - v / 2.))\n",
        "    x1 = int(min(w, x0 + v))\n",
        "    y1 = int(min(h, y0 + v))\n",
        "    xy = (x0, y0, x1, y1)\n",
        "    # gray\n",
        "    # color = (127, 127, 127)\n",
        "    color = (255)\n",
        "    img = img.copy()\n",
        "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
        "    return img\n",
        "\n",
        "\n",
        "def Equalize(img, **kwarg):\n",
        "    return PIL.ImageOps.equalize(img)\n",
        "\n",
        "\n",
        "def Identity(img, **kwarg):\n",
        "    return img\n",
        "\n",
        "\n",
        "def Invert(img, **kwarg):\n",
        "    return PIL.ImageOps.invert(img)\n",
        "\n",
        "\n",
        "def Posterize(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    return PIL.ImageOps.posterize(img, v)\n",
        "\n",
        "\n",
        "def Rotate(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.rotate(v)\n",
        "\n",
        "\n",
        "def Sharpness(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
        "\n",
        "\n",
        "def ShearX(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
        "\n",
        "\n",
        "def ShearY(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
        "\n",
        "\n",
        "def Solarize(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    return PIL.ImageOps.solarize(img, 256 - v)\n",
        "\n",
        "\n",
        "def SolarizeAdd(img, v, max_v, bias=0, threshold=128):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    img_np = np.array(img).astype(np.int)\n",
        "    img_np = img_np + v\n",
        "    img_np = np.clip(img_np, 0, 255)\n",
        "    img_np = img_np.astype(np.uint8)\n",
        "    img = Image.fromarray(img_np)\n",
        "    return PIL.ImageOps.solarize(img, threshold)\n",
        "\n",
        "\n",
        "def TranslateX(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    v = int(v * img.size[0])\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
        "\n",
        "\n",
        "def TranslateY(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    v = int(v * img.size[1])\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
        "\n",
        "\n",
        "def _float_parameter(v, max_v):\n",
        "    return float(v) * max_v / PARAMETER_MAX\n",
        "\n",
        "\n",
        "def _int_parameter(v, max_v):\n",
        "    return int(v * max_v / PARAMETER_MAX)\n",
        "\n",
        "\n",
        "def fixmatch_augment_pool():\n",
        "    # FixMatch paper\n",
        "    augs = [(AutoContrast, None, None),\n",
        "            (Brightness, 0.9, 0.05),\n",
        "            (Color, 0.9, 0.05),\n",
        "            (Contrast, 0.9, 0.05),\n",
        "            (Equalize, None, None),\n",
        "            (Identity, None, None),\n",
        "            (Posterize, 4, 4),\n",
        "            (Rotate, 30, 0),\n",
        "            (Sharpness, 0.9, 0.05),\n",
        "            (ShearX, 0.3, 0),\n",
        "            (ShearY, 0.3, 0),\n",
        "            (Solarize, 256, 0),\n",
        "            (TranslateX, 0.3, 0),\n",
        "            (TranslateY, 0.3, 0)]\n",
        "            \n",
        "    return augs\n",
        "    \n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "class RandAugmentMCStrong(object):\n",
        "    def __init__(self, n, m):\n",
        "        assert n >= 1\n",
        "        assert 1 <= m <= 10\n",
        "        self.n = n\n",
        "        self.m = m\n",
        "        self.augment_pool = fixmatch_augment_pool()\n",
        "\n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_pool, k=self.n)\n",
        "        for op, max_v, bias in ops:\n",
        "            v = np.random.randint(1, self.m)\n",
        "            if random.random() < 0.5:\n",
        "                img = op(img, v=v, max_v=max_v, bias=bias)\n",
        "        img = CutoutAbs(img, 16)\n",
        "        return img\n",
        "\n",
        "class RandAugmentMCWeak(object):\n",
        "    def __init__(self, n, m):\n",
        "        assert n >= 1\n",
        "        assert 1 <= m <= 10\n",
        "        self.n = n\n",
        "        self.m = m\n",
        "        self.augment_pool = fixmatch_augment_pool()\n",
        "\n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_pool, k=self.n)\n",
        "        for op, max_v, bias in ops:\n",
        "            v = np.random.randint(1, self.m)\n",
        "            if random.random() < 0.5:\n",
        "                img = op(img, v=v, max_v=max_v, bias=bias)\n",
        "        return img\n",
        "\n",
        "        \n",
        "class TransformFixImage(object):\n",
        "    def __init__(self, mean, std, n_strong, m_strong, n_weak, m_weak):\n",
        "        self.weak = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            # transforms.RandomCrop(size=28,\n",
        "            #                       padding=int(28*0.125),\n",
        "            #                       padding_mode='reflect')\n",
        "            RandAugmentMCWeak(n=n_weak, m=m_weak)\n",
        "            ])\n",
        "        self.strong = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            # transforms.RandomCrop(size=28,\n",
        "            #                       padding=int(28*0.125),\n",
        "            #                       padding_mode='reflect'),\n",
        "            RandAugmentMCStrong(n=n_strong, m=m_strong)])\n",
        "        self.normalize = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean, std=std)])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        weak = self.weak(x)\n",
        "        strong = self.strong(x)\n",
        "        return self.normalize(weak), self.normalize(strong)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfNoF2dG1yGl",
        "colab_type": "text"
      },
      "source": [
        "#### FixMatch Text Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nIV2Bly11Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---------------------------------------------    \n",
        "# augmentations on char level \n",
        "# ---------------------------------------------    \n",
        "def print_augmentations(func, text):\n",
        "  def wrapper():\n",
        "    print(\"Augmentation function: \", func.__name__)\n",
        "    print(\"Original: \")\n",
        "    print(text)\n",
        "    augmented_text = func(text)\n",
        "    print(\"Augmention result: \")\n",
        "    print(augmented_text)\n",
        "    return augmented_text\n",
        "\n",
        "  return wrapper() \n",
        "\n",
        "def substitute_character_by_keyboard_distance(text):\n",
        "  aug = nac.KeyboardAug()\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text\n",
        "\n",
        "def insert_character_randomly(text):\n",
        "  aug = nac.RandomCharAug(action=\"insert\")\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text \n",
        "\n",
        "\n",
        "def substitute_character_randomly(text):\n",
        "  aug = nac.RandomCharAug(action=\"substitute\")\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text \n",
        "\n",
        "\n",
        "def delete_char_randomly(text):\n",
        "  aug = nac.RandomCharAug(action=\"delete\")\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text \n",
        "\n",
        "\n",
        "def swap_character_randomly(text):\n",
        "  aug = nac.RandomCharAug(action=\"swap\")\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text\n",
        "\n",
        "# ---------------------------------------------    \n",
        "# augmentations on word level \n",
        "# ---------------------------------------------    \n",
        "# models - spelling_en.txt\n",
        "# model_dir with fasttext or word2vec or glove \n",
        "# model dir with tf-idf\n",
        "\n",
        "# its consume to much RAM\n",
        "# def insert_word_randomly_by_word_embeddings_similarity(text):\n",
        "#   # model_type: word2vec, glove or fasttext\n",
        "#   aug = naw.WordEmbsAug(\n",
        "#       model_type='word2vec', model_path=os.environ('WORD2VEC_MODEL_PATH'),\n",
        "#       action=\"insert\")\n",
        "#   augmented_text = aug.augment(text)\n",
        "#   print(\"Original:\")\n",
        "#   print(text)\n",
        "#   print(\"Augmented Text:\")\n",
        "#   print(augmented_text)\n",
        "#   return augmented_text\n",
        "\n",
        "\n",
        "def insert_word_by_tf_idf_similarity(text):\n",
        "  aug = naw.TfIdfAug(\n",
        "      model_path=os.environ['NLPAUG_PATH'],\n",
        "      action=\"insert\")\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text \n",
        "\n",
        "\n",
        "\n",
        "def split_word_to_two_tokens_randomly(text):\n",
        "  aug = naw.SplitAug()\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text \n",
        "\n",
        "\n",
        "def swap_word_randomly(text):\n",
        "  aug = naw.RandomWordAug(action=\"swap\")\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text \n",
        "\n",
        "\n",
        "def substitute_word_by_antonym(text):\n",
        "  aug = naw.AntonymAug()\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text \n",
        "\n",
        "\n",
        "def substitute_word_by_spelling_mistake_words_dictionary(text):\n",
        "  aug = naw.SpellingAug(os.environ['SPELLING_PATH'])\n",
        "  augmented_text = aug.augment(text, n=1)\n",
        "  return augmented_text \n",
        "\n",
        "\n",
        "def insert_word_by_contextual_word_embeddings(text):\n",
        "  aug = naw.ContextualWordEmbsAug(\n",
        "      model_path='bert-base-uncased', action=\"insert\")\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text\n",
        "\n",
        "\n",
        "def subtitute_word_by_contextual_word_embeddings(text):\n",
        "  aug = naw.ContextualWordEmbsAug(\n",
        "           model_path='bert-base-uncased', action=\"substitute\")\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text\n",
        "\n",
        "\n",
        "def substitute_word_by_WordNets_synonym(text):\n",
        "  aug = naw.SynonymAug(aug_src='wordnet')\n",
        "  augmented_text = aug.augment(text)\n",
        "  return augmented_text\n",
        "  \n",
        "def fixmatch_weak_augment_pool():\n",
        "    augs = [\n",
        "            substitute_character_by_keyboard_distance,\n",
        "            insert_character_randomly,\n",
        "            substitute_character_randomly,\n",
        "            delete_char_randomly,\n",
        "            swap_character_randomly,\n",
        "            # insert_word_randomly_by_word_embeddings_similarity,\n",
        "            insert_word_by_tf_idf_similarity,\n",
        "            split_word_to_two_tokens_randomly,\n",
        "            swap_word_randomly,\n",
        "            substitute_word_by_antonym,\n",
        "            substitute_word_by_spelling_mistake_words_dictionary,\n",
        "            insert_word_by_contextual_word_embeddings,\n",
        "            subtitute_word_by_contextual_word_embeddings,\n",
        "            substitute_word_by_WordNets_synonym,\n",
        "           ]\n",
        "\n",
        "    return augs\n",
        "\n",
        "# def fixmatch_strong_augment_pool():\n",
        "#     augs = [\n",
        "#             insert_word_by_contextual_word_embeddings,\n",
        "#             subtitute_word_by_contextual_word_embeddings,\n",
        "#             substitute_word_by_WordNets_synonym,\n",
        "#            ]\n",
        "\n",
        "#     return augs\n",
        "\n",
        "\n",
        "class WeakRandAugment(object):\n",
        "  def __init__(self, n, show=False):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    n (int): number of operations\n",
        "\n",
        "    \"\"\"\n",
        "    assert n >= 0\n",
        "    self.n = n\n",
        "    self.augment_pool = fixmatch_weak_augment_pool()\n",
        "    self.show=show\n",
        "\n",
        "  def __call__(self, text):\n",
        "    if self.n <= 0:\n",
        "      return text\n",
        "    ops = random.choices(self.augment_pool, k=self.n)\n",
        "    for op in ops:\n",
        "        if random.random() < 1.:\n",
        "          if self.show:\n",
        "            text = print_augmentations(op, text)\n",
        "          else:\n",
        "            text = op(text)\n",
        "    return text \n",
        "\n",
        "# not necessery\n",
        "# class StrongRandAugment(object):\n",
        "#   def __init__(self, n, show=False):\n",
        "#     assert n >= 1\n",
        "#     self.n = n\n",
        "#     self.augment_pool = fixmatch_strong_augment_pool()\n",
        "#     self.show= show\n",
        "\n",
        "#   def __call__(self, text):\n",
        "#     ops = random.choices(self.augment_pool, k=self.n)\n",
        "#     for op in ops:\n",
        "#       if random.random() < 1.:\n",
        "#         if self.show:\n",
        "#           text = print_augmentations(op, text)\n",
        "#         else:\n",
        "#           text = op(text)\n",
        "#     return text \n",
        "\n",
        "\n",
        "class TransformFix(object):\n",
        "  def __init__(self, n_weak=3, show=False):\n",
        "  # def __init__(self, n_weak=3, n_strong=2, show=False):\n",
        "    self.weak = WeakRandAugment(n=n_weak, show=show) \n",
        "    # self.strong = StrongRandAugment(n=n_strong, show=show)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    weak = self.weak(x)\n",
        "    # strong = self.strong(x)\n",
        "    return weak #, strong\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKpMf7Gz3CpR",
        "colab_type": "text"
      },
      "source": [
        "### Datasets Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkdrQH7a3FKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !!!!!!!\n",
        "# TODO: change dataset name and data_dict keys        \n",
        "class SimpleTextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, x, y, transform=None):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # special dict convention for f: process_NLUHD \n",
        "        data_dict = { 'text': self.x[index], 'label': self.y[index]}\n",
        "        if self.transform is not None:\n",
        "          return self.transform(data_dict)\n",
        "        return tuple(data_dict.values()) \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "class FixMatchAugmentedTextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, x, x_paraphrases, y,\n",
        "                 model_preprocessing = None,\n",
        "                 fix_match_augmentation = None, show=False):\n",
        "        self.x = x\n",
        "        self.x_paraphrases = x_paraphrases\n",
        "        self.y = y\n",
        "        self.model_preprocessing = model_preprocessing\n",
        "        self.fix_match_augmentation = fix_match_augmentation\n",
        "        self.show = show\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # special dict convention for f: process_NLUHD \n",
        "        if self.fix_match_augmentation is not None:\n",
        "          weak_augmented, strong_augmented = \\\n",
        "           self.fix_match_augmentation(self.x[index]), self.x_paraphrases[index] \n",
        "          if self.show:\n",
        "            print_augmentations(lambda x: x, self.x_paraphrases[index])\n",
        "        \n",
        "\n",
        "        weak_aug_data_dict = { 'text': weak_augmented , 'label': self.y[index]}\n",
        "        # add tfidf deletion or subsitution\n",
        "        strong_aug_data_dict = { 'text': strong_augmented , 'label': self.y[index]}\n",
        "\n",
        "        if self.model_preprocessing is not None:\n",
        "          return self.model_preprocessing(weak_aug_data_dict), self.model_preprocessing(strong_aug_data_dict)\n",
        "\n",
        "        return tuple(weak_aug_data_dict.values()), tuple(strong_aug_data_dict.values()) \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "class FixMatchAugmentedImageDataset(Dataset):\n",
        "\n",
        "    def __init__(self, x, y,\n",
        "                 model_preprocessing = None,\n",
        "                 fix_match_augmentation = None,\n",
        "                 show=False):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.model_preprocessing = model_preprocessing\n",
        "        self.fix_match_augmentation = fix_match_augmentation\n",
        "        self.show = show\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # special dict convention for f: process_NLUHD \n",
        "        if self.fix_match_augmentation is not None:\n",
        "          weak_augmented, strong_augmented = \\\n",
        "           self.fix_match_augmentation(self.x[index]) \n",
        "          if self.show:\n",
        "            print_image_augmentations(lambda x: x, self.x[index])\n",
        "            print_image_augmentations(lambda x: x, weak_augmented)\n",
        "            print_image_augmentations(lambda x: x, strong_augmented)\n",
        "        \n",
        "        weak_aug_data_dict = { 'text': weak_augmented , 'label': self.y[index]}\n",
        "        strong_aug_data_dict = { 'text': strong_augmented , 'label': self.y[index]}\n",
        "\n",
        "        if self.model_preprocessing is not None:\n",
        "          return self.model_preprocessing(weak_aug_data_dict), self.model_preprocessing(strong_aug_data_dict)\n",
        "\n",
        "        return tuple(weak_aug_data_dict.values()), tuple(strong_aug_data_dict.values()) \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA1ZSYrtFVK6",
        "colab_type": "text"
      },
      "source": [
        "### Datasets related preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsGvdNvB90p7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_NLUHD(comment, nlp,  ner_abstract_tag: bool=True):\n",
        "  expression = r\"\\[.*?\\]\"\n",
        "  matches = []\n",
        "  for match in re.finditer(expression, comment.text):\n",
        "      start, end = match.span()\n",
        "      span = comment.char_span(start, end)\n",
        "      # This is a Span object or None if match doesn't map to valid token sequence\n",
        "      if span is not None:\n",
        "          # print(\"Found match:\", span.text)\n",
        "          if ner_abstract_tag:\n",
        "            expression_scd = r\"\\[.*?\\:\"\n",
        "          else:\n",
        "            expression_scd = r\"\\:.*?\\]\"\n",
        "\n",
        "          temp_doc = nlp(span.text)\n",
        "          scd_match = next(re.finditer(expression_scd, temp_doc.text))\n",
        "          start1, end1 = scd_match.span()\n",
        "          # print(start1, end1)\n",
        "          s1 = int(start1) + 1\n",
        "          e1 = int(end1) - 1\n",
        "          # print(type(e1))\n",
        "          replace_str = temp_doc.text[s1:e1].strip()\n",
        "          # scd_doc = temp_doc.char_span(start1 + 1, end1 - 2) \n",
        "          matches += [((start, end), replace_str)]\n",
        "\n",
        "  start_line = 0\n",
        "  new_comment = \"\"\n",
        "  for match in matches:\n",
        "    s = match[0][0]\n",
        "    e = match[0][1]\n",
        "    replace_word = match[1]\n",
        "    new_comment += comment.text[start_line:s] + replace_word \n",
        "    start_line = e\n",
        "  new_comment += comment.text[start_line:]\n",
        "  ret_val = nlp(new_comment)\n",
        "  return ret_val\n",
        "\n",
        "def preprocess_NLUHD(lowercase,\n",
        "                     remove_stopwords,\n",
        "                     with_ner_tags,\n",
        "                     nlp,\n",
        "                     label_encoder,\n",
        "                     sample):\n",
        "  \n",
        "  stops = stopwords.words(\"english\")\n",
        "  comment = sample['text']\n",
        "  if lowercase:\n",
        "      comment = comment.lower()\n",
        "  comment = nlp(comment)\n",
        "  if with_ner_tags is True:\n",
        "    comment = prepare_NLUHD(comment, ner_abstract_tag=True, nlp=nlp)\n",
        "  else:\n",
        "    comment = prepare_NLUHD(comment, ner_abstract_tag=False, nlp=nlp)\n",
        "  lemmatized = list()\n",
        "  if remove_stopwords:\n",
        "    for word in comment:\n",
        "        lemma = word.lemma_.strip()\n",
        "        if lemma:\n",
        "            if not remove_stopwords or (remove_stopwords and lemma not in stops):\n",
        "                lemmatized.append(lemma)\n",
        "    processed_text = \" \".join(lemmatized) \n",
        "  processed_text = comment.text\n",
        "  encoded_label = torch.tensor(int(label_encoder.transform([sample[\"label\"]])))\n",
        "  return {\"text\": processed_text,\n",
        "          \"label\": encoded_label}\n",
        "\n",
        "def preprocess_IMDB(label_encoder, sample: Dict):\n",
        "  pattern1 = re.compile(r'<.*?>')\n",
        "  # pattern2 = re.compile('[\\W_]+ ')\n",
        "  # text = pattern2.sub(' ', text)\n",
        "  text = pattern1.sub('', sample['text']).lower()\n",
        "  encoded_label = torch.tensor(int(label_encoder.transform([sample[\"label\"]])))\n",
        "  return {\"text\": text,\n",
        "          \"label\": encoded_label}\n",
        "          \n",
        "def preprocess_MR(label_encoder, sample: Dict):\n",
        "  remove_html_tags = re.compile(r'<.*?>')\n",
        "  remove_punctuation = re.compile(r'[^\\w\\s]+')\n",
        "  remove_extra_whitespaces = re.compile(r' +')\n",
        "\n",
        "  p1 = curry(remove_html_tags.sub)('') \n",
        "  p2 = curry(remove_punctuation.sub)('') \n",
        "  p3 = curry(remove_extra_whitespaces.sub)(' ') \n",
        "  p4 = str.lower\n",
        "  processing = compose(p4, p3, p2, p1)\n",
        "\n",
        "  text = processing(sample['text'])\n",
        "  encoded_label = torch.tensor(int(label_encoder.transform([sample[\"label\"]])))\n",
        "  return {\"text\": text,\n",
        "          \"label\": encoded_label}\n",
        "        \n",
        "def preprocess_MNIST(label_encoder, sample: Dict):\n",
        "  encoded_label = torch.tensor(int(label_encoder.transform([sample[\"label\"]])))\n",
        "  x = sample['text'].float().unsqueeze(0)\n",
        "  return {\"text\": x,\n",
        "          \"label\": encoded_label}\n",
        "          \n",
        "def preprocess_MNIST_FixMatch(label_encoder, sample: Dict):\n",
        "  encoded_label = torch.tensor(int(label_encoder.transform([sample[\"label\"]])))\n",
        "  x = sample['text'].float()\n",
        "  return {\"text\": x,\n",
        "          \"label\": encoded_label}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdCXdl-oxtlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "filtered_sentence = remove_stopwords(text)\n",
        "filtered_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGCcDLd_-udN",
        "colab_type": "text"
      },
      "source": [
        "### Model related preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvkT6fi64bEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transformer_preprocessing(model_type: str,\n",
        "                              MAX_LEN: int,\n",
        "                              tokenizer: BertTokenizer,\n",
        "                              sample:Dict,) -> Dict:\n",
        "  \n",
        "    inputs = tokenizer.encode_plus(\n",
        "            sample[\"text\"],\n",
        "            add_special_tokens=True,\n",
        "            max_length=MAX_LEN,\n",
        "            )\n",
        "    # Output of `tokenizer.encode_plus` is a dictionary.\n",
        "    if model_type == 'roberta-base':\n",
        "      token_type_ids = [] \n",
        "    else:\n",
        "      input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
        "    # For BERT, we need `attention_mask` along with `input_ids` as input.\n",
        "    attention_mask = [1] * len(input_ids)\n",
        "    # We are going to pad sequences.\n",
        "    padding_length = MAX_LEN - len(input_ids)\n",
        "    pad_id = tokenizer.pad_token_id\n",
        "    input_ids = input_ids + ([pad_id] * padding_length)\n",
        "    attention_mask = attention_mask + ([0] * padding_length)\n",
        "    token_type_ids = token_type_ids + ([pad_id] * padding_length)\n",
        "\n",
        "    assert len(input_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(input_ids), MAX_LEN)\n",
        "    assert len(attention_mask) == MAX_LEN, \"Error with input length {} vs {}\".format(len(attention_mask), MAX_LEN)\n",
        "    assert len(token_type_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(token_type_ids), MAX_LEN)\n",
        "\n",
        "    # Just a python list to `torch.tensor`\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_mask = torch.tensor(attention_mask)\n",
        "    token_type_ids = torch.tensor(token_type_ids)\n",
        "\n",
        "    # What we return will one instance in batch which `LightningModule.train_step` receives.\n",
        "    return {\n",
        "            \"label\": sample['label'],\n",
        "            \"embedding\": {\n",
        "                          \"input_ids\": input_ids,\n",
        "                          \"attention_mask\": attention_mask,\n",
        "                          \"token_type_ids\": token_type_ids\n",
        "                         }\n",
        "            }\n",
        "\n",
        "def generate_embeddings(\n",
        "                         hparams,\n",
        "                         tokenizer,\n",
        "                         embeder,\n",
        "                         sample):\n",
        "\n",
        "  embedding = torch.Tensor([token.vector for token in embeder(sample[\"text\"])])#torch.tensor(embeder.wv[tokens])\n",
        "\n",
        "  if embedding.size()[0] >= hparams['max_sentence_len']:\n",
        "    embedding = torch.narrow(embedding, 0, 0, hparams['max_sentence_len'])\n",
        "  else:\n",
        "    padding_length = hparams['max_sentence_len'] - len(embedding)\n",
        "    padding_vectors = torch.zeros((padding_length, hparams['embed_dim']))\n",
        "    embedding = torch.cat((embedding, padding_vectors)) \n",
        "\n",
        "  return {'label': sample['label'],\n",
        "          'embedding': embedding}\n",
        "\n",
        "def adjust_MNIST_to_pipeline(sample: Dict):\n",
        "  return {'label': sample['label'],\n",
        "          'embedding': sample['text']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShfV1EwDrX97",
        "colab_type": "text"
      },
      "source": [
        "## Composable ML Framework "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9CPFT7ormCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LitComposableFramework(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, hparams):\n",
        "    super().__init__()\n",
        "    self.hparams = hparams\n",
        "    self.num_classes = hparams['num_classes']\n",
        "    self.total_iterations = 0\n",
        "    self.current_step = 0 \n",
        "    self.loss_fct = getattr(nn, hparams['loss_function'])()\n",
        "\n",
        "\n",
        "    if self.hparams['model_arch'] == \"Convolution\":\n",
        "\n",
        "      self.embeder_dict = {\n",
        "                          'fastText': (create_ft_embeder, gensim_tokenizer),\n",
        "                          'fastText_with_spaCy':(create_spacy_nlp_embeder, lambda x: x)\n",
        "                          }\n",
        "      embeder, self.tokenizer_fun = self.embeder_dict[hparams['embeder_type']]\n",
        "      self.embeder = nlp #embeder#nlp # hardcoded\n",
        "      self.D = hparams['embed_dim']\n",
        "      self.Ci = hparams['Ci'] \n",
        "      self.Co = hparams['kernel_num']\n",
        "      self.Ks = list(map(int, hparams['kernel_sizes'].split(','))) # (3,4,5)\n",
        "      self.convs1 = nn.ModuleList([nn.Conv2d(self.Ci, self.Co, (K, self.D)) for K in self.Ks])\n",
        "      self.dropout = nn.Dropout(hparams['dropout'])\n",
        "      self.fc1 = nn.Linear(len(self.Ks) * self.Co, self.num_classes) \n",
        "\n",
        "    elif self.hparams['model_arch'] == 'ConvolutionMNIST':\n",
        "\n",
        "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "      self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "      self.dropout1 = nn.Dropout2d(self.hparams['dropout1'])\n",
        "      self.dropout2 = nn.Dropout2d(self.hparams['dropout2'])\n",
        "      self.fc1 = nn.Linear(9216, 128)\n",
        "      self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    elif self.hparams['model_arch'] == 'FFNNMNIST' or self.hparams['model_arch'] == 'FFNNMNIST_VAT':\n",
        "\n",
        "        self.fc1 = nn.Linear(28 * 28, 1200)\n",
        "        self.fc2 = nn.Linear(1200, 600)\n",
        "        self.fc3 = nn.Linear(600, 300)\n",
        "        self.fc4 = nn.Linear(300, 150)\n",
        "        self.fc5 = nn.Linear(150, 10)\n",
        "        self.bn1 = nn.BatchNorm1d(1200)\n",
        "        self.bn2 = nn.BatchNorm1d(600)\n",
        "        self.bn3 = nn.BatchNorm1d(300)\n",
        "        self.bn4 = nn.BatchNorm1d(150)\n",
        "\n",
        "    elif self.hparams['model_arch'] == \"Transformer\":\n",
        "      self.model_class_dict = {\n",
        "            \"bert-base-uncased\": BertModel,\n",
        "            \"roberta-base\": RobertaModel\n",
        "            }\n",
        "              \n",
        "      self.tokenizer_dict = {\n",
        "              \"bert-base-uncased\":\n",
        "                BertTokenizer.from_pretrained(\"bert-base-uncased\",\n",
        "                                              do_lower_case=True),\n",
        "              \"roberta-base\":\n",
        "                RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "              }\n",
        "  \n",
        "      self.model = self.model_class_dict[self.hparams['model_type']].from_pretrained(self.hparams['model_type'],\n",
        "                                                                output_attentions=True)\n",
        "      self.encoder_features =  self.model.config.hidden_size \n",
        "      print('encoder features: ', self.encoder_features)\n",
        "      self.num_classes = self.hparams['num_classes']\n",
        "      self.classification_head = nn.Sequential(\n",
        "            nn.Linear(self.encoder_features, self.encoder_features * 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(self.encoder_features * 2, self.encoder_features),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(self.encoder_features, self.num_classes),\n",
        "        )\n",
        "    else:\n",
        "      raise ValueError('Wrong model architecture type: {} \\\n",
        "       \\n Possible datasets: Transformer, Convolution'.format(self.hparams['model_arch']))\n",
        "\n",
        "\n",
        "  def forward(self, x, embeddings_only=False, val_mode=False):\n",
        "\n",
        "      if self.hparams['model_arch'] == \"Convolution\":\n",
        "\n",
        "        if embeddings_only == True:\n",
        "          logits = x\n",
        "\n",
        "        else:\n",
        "          x = x.unsqueeze(self.Ci)  # (N, Ci, W, D)\n",
        "          x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
        "          x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "          x = torch.cat(x, 1)\n",
        "          x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "          logits = self.fc1(x)  # (N, C)\n",
        "\n",
        "      elif self.hparams['model_arch'] == 'ConvolutionMNIST':\n",
        "\n",
        "        if embeddings_only == True:\n",
        "          logits = x\n",
        "        else:\n",
        "          x = self.conv1(x)\n",
        "          x = F.relu(x)\n",
        "          x = self.conv2(x)\n",
        "          x = F.relu(x)\n",
        "          x = F.max_pool2d(x, 2)\n",
        "          x = self.dropout1(x)\n",
        "          x = torch.flatten(x, 1)\n",
        "          x = self.fc1(x)\n",
        "          x = F.relu(x)\n",
        "          x = self.dropout2(x)\n",
        "          logits = self.fc2(x)\n",
        "      \n",
        "      elif self.hparams['model_arch'] == 'FFNNMNIST_VAT':\n",
        "\n",
        "        if embeddings_only == True:\n",
        "          logits = x\n",
        "        else:\n",
        "          out = x.view(x.size(0), -1)\n",
        "          out = F.relu(self.bn1(self.fc1(out)))\n",
        "          if not val_mode: out = out + out.clone().normal_(0, self.hparams['isotropic_noise'])\n",
        "          out = F.relu(self.bn2(self.fc2(out)))\n",
        "          if not val_mode: out = out + out.clone().normal_(0, self.hparams['isotropic_noise'])\n",
        "          out = F.relu(self.bn3(self.fc3(out)))\n",
        "          if not val_mode: out = out + out.clone().normal_(0, self.hparams['isotropic_noise'])\n",
        "          out = F.relu(self.bn4(self.fc4(out)))\n",
        "          if not val_mode: out = out + out.clone().normal_(0, self.hparams['isotropic_noise'])\n",
        "          logits = self.fc5(out)\n",
        "\n",
        "      elif self.hparams['model_arch'] == 'FFNNMNIST':\n",
        "\n",
        "        if embeddings_only == True:\n",
        "          logits = x\n",
        "        else:\n",
        "          out = x.view(x.size(0), -1)\n",
        "          out = F.relu(self.bn1(self.fc1(out)))\n",
        "          out = F.relu(self.bn2(self.fc2(out)))\n",
        "          out = F.relu(self.bn3(self.fc3(out)))\n",
        "          out = F.relu(self.bn4(self.fc4(out)))\n",
        "          logits = self.fc5(out)\n",
        "\n",
        "\n",
        "      elif self.hparams['model_arch'] == \"Transformer\":\n",
        "        h, _, _ = self.model(x['input_ids'],\n",
        "                             attention_mask=x['attention_mask'],\n",
        "                             token_type_ids=x['token_type_ids'] if self.hparams['model_type'] != \"roberta-base\" else None)\n",
        "        h_cls = h[:, 0]\n",
        "\n",
        "        if embeddings_only == True:\n",
        "          logits = h_cls\n",
        "        else:\n",
        "          logits = self.classification_head(h_cls)\n",
        "\n",
        "      else:\n",
        "        raise ValueError('Wrong model architecture type: {} \\\n",
        "         \\n Possible datasets: Transformer, Convolution, ConvolutionMNIST'.format(self.hparams['model_arch']))\n",
        "\n",
        "      return logits\n",
        "\n",
        "\n",
        "  def prepare_data(self):\n",
        "\n",
        "    if self.hparams['dataset'] == 'NLUHD':\n",
        "\n",
        "      not_none = lambda x: x[\"text\"] is not None \n",
        "      ds = lf.CsvDataset(self.hparams['dataset_path'], header=True).filter(not_none)\n",
        "      unique_labels = list(pd.DataFrame(ds).intent.unique())\n",
        "      self.le = preprocessing.LabelEncoder().fit(unique_labels)\n",
        "      print(f\"Unique labels: {unique_labels}\")\n",
        "      print(f\"Number of unique labels: {len(unique_labels)}\")\n",
        "      train, test = lf.cross_validation.split_dataset_random(ds,\n",
        "                                                            int(len(ds) * self.hparams['train_test_split']),\n",
        "                                                            seed=self.hparams['seed'])\n",
        "\n",
        "      nlp = spacy.load(\"en\", disable=['parser', 'tagger', 'ner'])\n",
        "\n",
        "      dataset_preprocessor = partial(preprocess_NLUHD,\n",
        "                                     lowercase=True,\n",
        "                                     remove_stopwords=True,\n",
        "                                     with_ner_tags=False,\n",
        "                                     nlp=nlp,\n",
        "                                     label_encoder=le,\n",
        "      )\n",
        "\n",
        "      train_df, test_df = pd.DataFrame(train), pd.DataFrame(test)\n",
        "      # maybe here you can shuffle with different seed\n",
        "      x_train, y_train = train_df['text'].values, train_df['label'].values\n",
        "      self.x_test, self.y_test = test_df['text'].values, test_df['label'].values\n",
        "\n",
        "      dataset_preprocessor = partial(\n",
        "                                     preprocess_MR,\n",
        "                                     self.le,\n",
        "                                    )\n",
        "\n",
        "    elif self.hparams['dataset'] == 'MR':\n",
        "\n",
        "      not_none = lambda x: x[\"text\"] is not None \n",
        "      ds = lf.CsvDataset(self.hparams['dataset_path'], header=True).filter(not_none)\n",
        "      df = pd.DataFrame(ds)\n",
        "\n",
        "      if self.hparams['training_method'] == \"FixMatch\":\n",
        "        create_tfidf_model(df)\n",
        "\n",
        "      unique_labels = list(df.label.unique())\n",
        "      self.le = preprocessing.LabelEncoder().fit(unique_labels)\n",
        "      print(f\"Unique labels: {unique_labels}\")\n",
        "      print(f\"Number of unique labels: {len(unique_labels)}\")\n",
        "      train, test = lf.cross_validation.split_dataset_random(ds,\n",
        "                                                            int(len(ds) * self.hparams['train_test_split']),\n",
        "                                                            seed=self.hparams['seed'])\n",
        "      \n",
        "      train_df, test_df = pd.DataFrame(train), pd.DataFrame(test)\n",
        "      print('train_df:')\n",
        "      print(train_df.describe())\n",
        "\n",
        "      print('test_df:')\n",
        "      print(test_df.describe())\n",
        "      # maybe here you can shuffle with different seed\n",
        "      x_train, y_train = train_df['text'].values, train_df['label'].values\n",
        "      self.x_test, self.y_test = test_df['text'].values, test_df['label'].values\n",
        "\n",
        "      dataset_preprocessor = partial(\n",
        "                                     preprocess_MR,\n",
        "                                     self.le,\n",
        "                                    )\n",
        "      \n",
        "    elif self.hparams['dataset'] == 'IMDB':\n",
        "\n",
        "      not_none = lambda x: x[\"text\"] is not None \n",
        "      ds = lf.CsvDataset(self.hparams['dataset_path'], header=True).filter(not_none)\n",
        "      # ds = lfds.Imdb('train') + lfds.Imdb('test')\n",
        "      # ds = ds.map(lambda x: {'text': x[0], 'label': x[1]})\n",
        "      df = pd.DataFrame(ds)\n",
        "\n",
        "      if self.hparams['training_method'] == \"FixMatch\":\n",
        "        create_tfidf_model(df)\n",
        "\n",
        "      print(df.info(memory_usage=True))\n",
        "      unique_labels = list(df.label.unique())\n",
        "      print(f'unique_labels: {unique_labels}')\n",
        "      print(f'number_of_categories : {len(unique_labels)}')\n",
        "      self.le = preprocessing.LabelEncoder().fit(unique_labels)\n",
        "      train, test = lf.cross_validation.split_dataset_random(ds,\n",
        "                                                             int(len(ds) * self.hparams['train_test_split']),\n",
        "                                                             seed=self.hparams['seed'])\n",
        "      dataset_preprocessor = partial(\n",
        "                                     preprocess_IMDB,\n",
        "                                     self.le,\n",
        "                                    )\n",
        "      \n",
        "      train_df, test_df = pd.DataFrame(train), pd.DataFrame(test)\n",
        "      # maybe here you can shuffle with different seed\n",
        "      x_train, y_train = train_df['text'].values, train_df['label'].values\n",
        "      self.x_test, self.y_test = test_df['text'].values, test_df['label'].values\n",
        "    \n",
        "    elif self.hparams['dataset'] == 'MNIST':\n",
        "\n",
        "      train_ds = torchvision.datasets.MNIST('./',\n",
        "                                          train=True, transform=None,\n",
        "                                          target_transform=None, download=True)\n",
        "      \n",
        "      test_ds = torchvision.datasets.MNIST('./',\n",
        "                                        train=False, transform=None,\n",
        "                                        target_transform=None, download=True)\n",
        "      \n",
        "      train_x, train_y  = train_ds.data, train_ds.targets\n",
        "      test_x, test_y  = test_ds.data, test_ds.targets\n",
        "      full_x, full_y = torch.cat((train_x, test_x), 0), torch.cat((train_y, test_y), 0)\n",
        "      \n",
        "      train_size = int(self.hparams['train_test_split'] * full_x.shape[0])\n",
        "      test_size = full_x.shape[0] - train_size\n",
        "      \n",
        "      x_train, self.x_test = size_splits(full_x,\n",
        "                                [train_size, test_size])\n",
        "      \n",
        "      y_train, self.y_test = size_splits(full_y,\n",
        "                                [train_size, test_size])\n",
        "      # check columns names x -> text, y -> label\n",
        "      unique_labels = list(np.array(torch.unique(train_y)))\n",
        "      print(f'unique_labels: {unique_labels}')\n",
        "      print(f'number_of_categories : {len(unique_labels)}')\n",
        "      self.le = preprocessing.LabelEncoder().fit(unique_labels)\n",
        "\n",
        "      dataset_preprocessor = partial(\n",
        "                                     preprocess_MNIST, # label encoding\n",
        "                                     self.le,\n",
        "                                    )\n",
        "      \n",
        "    else:\n",
        "      raise ValueError('Wrong dataset name : {} \\\n",
        "       \\n Possible datasets: IMDB, MR, NLUHD'.format(self.hparams['dataset']))\n",
        "\n",
        "    if self.hparams['model_arch'] == 'Transformer':\n",
        "\n",
        "      model_arch_preprocessor = partial(\n",
        "                                        transformer_preprocessing,\n",
        "                                        self.hparams['model_type'],\n",
        "                                        self.hparams['max_sentence_len'],\n",
        "                                        self.tokenizer_dict[self.hparams['model_type']],\n",
        "                                       )\n",
        "      \n",
        "    elif self.hparams['model_arch'] == 'Convolution':\n",
        "\n",
        "      model_arch_preprocessor = partial(\n",
        "                                        generate_embeddings,\n",
        "                                        self.hparams,\n",
        "                                        self.tokenizer_fun,\n",
        "                                        self.embeder,\n",
        "                                       )\n",
        "      \n",
        "    elif self.hparams['model_arch'] == 'ConvolutionMNIST':\n",
        "\n",
        "      model_arch_preprocessor = partial(adjust_MNIST_to_pipeline) # change text for embedding\n",
        "\n",
        "    elif self.hparams['model_arch'] == 'FFNNMNIST' or self.hparams['model_arch'] == 'FFNNMNIST_VAT':\n",
        "\n",
        "      model_arch_preprocessor = partial(adjust_MNIST_to_pipeline) # change text for embedding\n",
        "    \n",
        "    else:\n",
        "      raise ValueError('Wrong model architecture type: {} \\\n",
        "       \\n Possible architectures: Convolution, ConvolutionMNIST, Transformer'.format(self.hparams['model_arch']))\n",
        "      \n",
        "    preprocessor = toolz.compose(\n",
        "                                 model_arch_preprocessor,\n",
        "                                 dataset_preprocessor,\n",
        "                                )\n",
        "\n",
        "    # split's training parameters  \n",
        "    num_classes = len(unique_labels)\n",
        "    label_per_class =  self.hparams['n_labeled'] // num_classes \n",
        "    valid_size = self.hparams['valid_size_per_class']\n",
        "\n",
        "    labeled_idx = []\n",
        "    unlabeled_idx = []\n",
        "    val_idx = []\n",
        "    \n",
        "    for label in unique_labels:\n",
        "        idx = np.where(y_train == label)[0]\n",
        "        np.random.shuffle(idx)\n",
        "        labeled_idx.extend(idx[:label_per_class])\n",
        "        val_idx.extend(idx[label_per_class: label_per_class + valid_size])\n",
        "        unlabeled_idx.extend(idx[label_per_class + valid_size:])\n",
        "\n",
        "    self.x_labeled, self.y_labeled  = x_train[labeled_idx], y_train[labeled_idx]\n",
        "    self.x_unlabeled, self.y_unlabeled = x_train[unlabeled_idx], y_train[unlabeled_idx]\n",
        "    self.x_val, self.y_val = x_train[val_idx], y_train[val_idx]\n",
        "\n",
        "    \n",
        "    self._train_labeled_dataset = SimpleTextDataset(self.x_labeled,\n",
        "                                                    self.y_labeled,\n",
        "                                                    transform=preprocessor)\n",
        "    \n",
        "    if self.hparams['training_method'] == 'FixMatch' and self.hparams['dataset'] == 'MNIST':\n",
        "\n",
        "      \n",
        "      ## implement showing weakly and strongly perturbated images\n",
        "      self._train_unlabeled_dataset = \\\n",
        "         FixMatchAugmentedImageDataset(x=self.x_unlabeled,\n",
        "                                       y=self.y_unlabeled,\n",
        "                                       model_preprocessing=preprocessor,\n",
        "                                       show=self.hparams['show_augmentation'],\n",
        "                                       fix_match_augmentation=TransformFixImage(\n",
        "                                              mean=self.hparams['mean'],\n",
        "                                              std=self.hparams['std'],\n",
        "                                              n_strong=self.hparams['n_strong'],\n",
        "                                              m_strong=self.hparams['m_strong'],\n",
        "                                              n_weak=self.hparams['n_weak'],\n",
        "                                              m_weak=self.hparams['m_weak'],\n",
        "                                              )\n",
        "                                      )\n",
        "    elif self.hparams['training_method'] == 'FixMatch':\n",
        "      x_unlabeled_paraphrases = train_df['paraphrases'].values\n",
        "      self._train_unlabeled_dataset = \\\n",
        "         FixMatchAugmentedTextDataset(self.x_unlabeled,\n",
        "                                      x_unlabeled_paraphrases[unlabeled_idx],\n",
        "                                      self.y_unlabeled,\n",
        "                                      model_preprocessing=preprocessor,\n",
        "                                      show=self.hparams['show_augmentation'],\n",
        "                                      fix_match_augmentation=TransformFix(\n",
        "                                        n_weak=self.hparams['n_weak'],\n",
        "                                        n_strong=self.hparams['n_strong'],\n",
        "                                        show=self.hparams['show_augmentation']),\n",
        "                                     )\n",
        "    else:\n",
        "      self._train_unlabeled_dataset = SimpleTextDataset(self.x_unlabeled,\n",
        "                                                        self.y_unlabeled,\n",
        "                                                        transform=preprocessor)\n",
        "\n",
        "\n",
        "    self._val_dataset = SimpleTextDataset(self.x_val,\n",
        "                                          self.y_val,\n",
        "                                          transform=preprocessor)\n",
        "    \n",
        "    self._test_dataset = SimpleTextDataset(self.x_test,\n",
        "                                           self.y_test,\n",
        "                                           transform=preprocessor)\n",
        "    \n",
        "    if self.hparams['epoch_over'] == 'unlabeled_train_dataset':\n",
        "      if self.hparams.get('max_epochs') == None:\n",
        "        self.total_iterations = self.hparams['max_steps'] \n",
        "      else: \n",
        "        self.total_iterations = self.hparams['max_epochs'] * \\\n",
        "        len(self._train_unlabeled_dataset) // self.hparams['unl_batch_size']\n",
        "\n",
        "      print('total_iterations: ', self.total_iterations) \n",
        "\n",
        "    elif self.hparams['epoch_over'] == 'labeled_train_dataset':\n",
        "\n",
        "      if self.hparams.get('max_epochs') == None:\n",
        "        self.total_iterations = self.hparams['max_steps'] \n",
        "      else: \n",
        "        self.total_iterations = self.hparams['max_epochs'] * \\\n",
        "        len(self._train_labeled_dataset) // self.hparams['l_batch_size'] \n",
        "\n",
        "      print('total_iterations: ', self.total_iterations) \n",
        "\n",
        "    else:\n",
        "      raise ValueError('Wrong epoch_over type: {} \\\n",
        "       \\n Possibilities: unlabeled_train_dataset, labeled_train_dataset'.format(self.hparams['epoch_over']))\n",
        "\n",
        "    \n",
        "  def train_dataloader(self):\n",
        "    encoded_label = torch.tensor(self.le.transform(self.y_labeled))\n",
        "\n",
        "    if self.hparams['epoch_over'] == 'labeled_train_dataset':\n",
        "\n",
        "      encoded_label = torch.tensor(self.le.transform(self.y_labeled))\n",
        "      self.train_unlabeled_dataloader = torch.utils.data.DataLoader(\n",
        "                              self._train_unlabeled_dataset,\n",
        "                              batch_size=self.hparams['unl_batch_size'],\n",
        "                              shuffle=True,\n",
        "                              num_workers=0,\n",
        "                              )\n",
        "        \n",
        "      self.train_unlabeled_dataloader_iterator = iter(self.train_unlabeled_dataloader)\n",
        "  \n",
        "      train_labeled_dataloader = DataLoader(\n",
        "                        self._train_labeled_dataset,\n",
        "                        batch_size=self.hparams['l_batch_size'],\n",
        "                        num_workers=8,\n",
        "                        # shuffle=True # without shuffle it want work cause\n",
        "                        # it need to create map index before __get_item__ function\n",
        "                        sampler=BalancedBatchSampler(self._train_labeled_dataset,\n",
        "                                                    encoded_label),\n",
        "                      )\n",
        "      pl_dataloader = train_labeled_dataloader\n",
        "\n",
        "    elif self.hparams['epoch_over'] == 'unlabeled_train_dataset':\n",
        "\n",
        "      self.train_labeled_dataloader = DataLoader(\n",
        "                                    self._train_labeled_dataset,\n",
        "                                    batch_size=self.hparams['l_batch_size'],\n",
        "                                    num_workers=0,\n",
        "                                    # shuffle=True # without shuffle it want work cause\n",
        "                                    # it need to create map index before __get_item__ function\n",
        "                                    sampler=BalancedBatchSampler(self._train_labeled_dataset,\n",
        "                                    encoded_label),\n",
        "                                    )\n",
        "      self.train_labeled_dataloader_iterator = iter(self.train_labeled_dataloader)\n",
        "\n",
        "      train_unlabeled_dataloader = DataLoader(\n",
        "                      self._train_unlabeled_dataset,\n",
        "                      batch_size=self.hparams['unl_batch_size'],\n",
        "                      shuffle=True,\n",
        "                      num_workers=8,\n",
        "                     )\n",
        "      pl_dataloader = train_unlabeled_dataloader\n",
        "\n",
        "    else:\n",
        "      raise ValueError('Wrong epoch_over type: {} \\\n",
        "       \\n Possibilities: unlabeled_train_dataset, labeled_train_dataset'.format(self.hparams['epoch_over']))\n",
        "\n",
        "    return pl_dataloader \n",
        "\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "                      self._val_dataset,\n",
        "                      batch_size=self.hparams['val_batch_size'],\n",
        "                      num_workers=8\n",
        "                     )\n",
        "    \n",
        "  \n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "                      self._test_dataset,\n",
        "                      batch_size=self.hparams['test_batch_size'],\n",
        "                      num_workers=8\n",
        "                     )\n",
        "    \n",
        "  \n",
        "  def configure_optimizers(self):\n",
        "\n",
        "    if self.hparams['optimizer_type'] == 'AdamW':\n",
        "      param_optimizer = list(self.model.named_parameters())\n",
        "      no_decay = [\"bias\", 'LayerNorm.weight']\n",
        "      optimizer_grouped_parameters = [\n",
        "              {\n",
        "                  \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "                  \"weight_decay_rate\": 0.01\n",
        "                  },\n",
        "              {\n",
        "                  \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "                  \"weight_decay_rate\": 0.0\n",
        "                  },\n",
        "              ]\n",
        "      print('total_iterations: ', self.total_iterations)\n",
        "      optimizer = AdamW(\n",
        "                        optimizer_grouped_parameters,\n",
        "                        lr=self.hparams['lr'],\n",
        "                      )\n",
        "\n",
        "    elif self.hparams['optimizer_type'] == 'Adam':\n",
        "      optimizer =torch.optim.Adam(self.parameters(), lr=self.hparams['lr'])\n",
        "\n",
        "    elif self.hparams['optimizer_type'] == 'SGD':\n",
        "      optimizer = torch.optim.SGD(self.parameters(),\n",
        "                                  lr=self.hparams['lr'],\n",
        "                                  momentum=self.hparams['momentum'],\n",
        "                                  weight_decay=self.hparams['weight_decay'],\n",
        "                                  nesterov=self.hparams['nesterov'],\n",
        "                                  )\n",
        "    else:\n",
        "      raise ValueError('Wrong optimizer type: {} \\\n",
        "   \\n Possible types: AdamW, Adam, SGD '.format(self.hparams['optimizer_type']))\n",
        "\n",
        "\n",
        "    if self.hparams['scheduler_type'] == 'ExponentialLR':            \n",
        "      scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer,\n",
        "                                       gamma=self.hparams['exponential_decay'])\n",
        "\n",
        "    elif self.hparams['scheduler_type'] == 'StepLR':                    \n",
        "    # def __init__(self, optimizer, step_size, decay_step, gamma=0.1, last_epoch=-1):\n",
        "      scheduler = StepLR(optimizer,\n",
        "                         step_size=self.hparams['decay_step_size'],\n",
        "                         gamma=self.hparams['decay_gamma'],\n",
        "                         decay_step=self.hparams['decay_step'])\n",
        "\n",
        "    elif self.hparams['scheduler_type'] == 'CosineAnnealingLR':                    \n",
        "      scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "                                                             optimizer,\n",
        "                                                             self.total_iterations)\n",
        "      \n",
        "    elif self.hparams['scheduler_type'] == 'LinearWarmUpLR':\n",
        "      scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                  self.hparams['warmup_steps'],\n",
        "                                                  self.total_iterations,\n",
        "                                                  -1)\n",
        "      \n",
        "    elif self.hparams['scheduler_type'] == 'CosineWarmupLR':\n",
        "      scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
        "                                                  self.hparams['warmup_steps'],\n",
        "                                                  self.total_iterations,\n",
        "                                                  num_cycles=self.hparams['num_cycles'],\n",
        "                                                 )\n",
        "      \n",
        "    elif self.hparams['scheduler_type'] == 'CosineHardRestartWarmupLR':\n",
        "      scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer,\n",
        "                                                  num_warmup_steps=self.hparams['warmup_steps'],\n",
        "                                                  num_training_steps=self.total_iterations,\n",
        "                                                  num_cycles=self.hparams['num_cycles'],\n",
        "                                                 )\n",
        "    else:\n",
        "      print('Scheduler was not specified!')\n",
        "      return [optimizer]\n",
        "\n",
        "\n",
        "    scheduler_conf = {'scheduler': scheduler,\n",
        "                      'interval': self.hparams['opt_scheduler_interval']}\n",
        "\n",
        "    return [optimizer], [scheduler_conf]\n",
        "  \n",
        "\n",
        "  def supervised(self, texts, labels, logs):\n",
        "\n",
        "    if self.hparams['epoch_over'] == 'unlabeled_train_dataset':\n",
        "      texts = texts.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    logits = self.forward(texts)\n",
        "    loss = self.loss_fct(logits, labels)\n",
        "    return logits, loss, logs\n",
        "  \n",
        "\n",
        "  def pseudo_labelling(self, l_embeddings, labels, unl_embeddings, logs):\n",
        "\n",
        "    if self.hparams['epoch_over'] == 'unlabeled_train_dataset':\n",
        "      l_embeddings = l_embeddings.cuda()\n",
        "      labels = labels.cuda()\n",
        "      unl_embeddings = unl_embeddings['embedding']\n",
        "    elif self.hparams['epoch_over'] == 'labeled_train_dataset':\n",
        "      unl_embeddings = unl_embeddings['embedding'].cuda()\n",
        "    else:\n",
        "      raise ValueError('Wrong epoch_over type: {} \\\n",
        "       \\n Possibilities: unlabeled_train_dataset, labeled_train_dataset'.format(self.hparams['epoch_over']))\n",
        "\n",
        "    logits_l_x = self.forward(l_embeddings)\n",
        "    logits_unl_x = self.forward(unl_embeddings) \n",
        "\n",
        "    Lx = F.cross_entropy(logits_l_x, labels, reduction='mean')\n",
        "\n",
        "    pseudo_distribution = torch.softmax(logits_unl_x.detach(), dim=-1)\n",
        "    max_probs, targets_u = torch.max(pseudo_distribution, dim=-1)\n",
        "\n",
        "    confident_keys = ['unl_max_confident', 'unl_min_confident', \\\n",
        "                      'unl_mean_confident', 'unl_std_confident']\n",
        "    confident_values = juxt(torch.max, torch.min, torch.mean, torch.std) \\\n",
        "                           (max_probs)\n",
        "    confident_dict = dict(zip(confident_keys, confident_values))\n",
        "    logs.update(confident_dict)\n",
        "\n",
        "    Lu = F.cross_entropy(logits_unl_x, targets_u, reduction='none').mean()\n",
        "    ### here should be some kind of scheduler for lambda_u\n",
        "    if self.hparams['alpha_scheduler_interval'] == 'epoch':\n",
        "      interval = self.current_epoch\n",
        "\n",
        "    elif self.hparams['alpha_scheduler_interval'] == 'step':\n",
        "      interval = self.current_step\n",
        "      \n",
        "    else:\n",
        "      raise ValueError('Wrong alpha_scheduler_interval type: {} \\\n",
        "       \\n Possibilities: step, epoch'.format(self.hparams['alpha_scheduler_interval']))\n",
        "      \n",
        "    self.hparams['T2'] = self.total_iterations\n",
        "    def unlabeled_weight(interval):\n",
        "        alpha = 0.0\n",
        "\n",
        "        if interval > self.hparams['T1']:\n",
        "          alpha = (interval - self.hparams['T1']) / \\\n",
        "          (self.hparams['T2'] - self.hparams['T1']) * self.hparams['af']\n",
        "\n",
        "          if interval > self.hparams['T2']:\n",
        "            alpha = self.hparams['af']\n",
        "\n",
        "        return alpha\n",
        "\n",
        "    alpha = unlabeled_weight(interval)\n",
        "    loss = Lx + alpha * Lu\n",
        "    logs.update({\"Lu\": Lu, 'Lx': Lx, 'alpha': alpha})\n",
        "\n",
        "    return logits_l_x, loss, logs\n",
        "\n",
        "\n",
        "  def vat(self, l_embeddings, labels, unl_embeddings, logs):\n",
        "\n",
        "    # credits:\n",
        "    #https://github.com/jik0730/VAT-pytorch/blob/master/vat.py\n",
        "    #--------------------------------------------------------------------------------\n",
        "    class VAT(nn.Module):\n",
        "        \"\"\"\n",
        "        We define a function of regularization, specifically VAT.\n",
        "        \"\"\"\n",
        "    \n",
        "        def __init__(self, model, hparams):\n",
        "            super(VAT, self).__init__()\n",
        "            self.model = model\n",
        "            self.n_power = hparams['K']\n",
        "            self.XI = hparams['xi']\n",
        "            self.epsilon = hparams['eps']\n",
        "    \n",
        "        def forward(self, X, logit):\n",
        "            vat_loss = virtual_adversarial_loss(X, logit, self.model, self.n_power,\n",
        "                                                self.XI, self.epsilon)\n",
        "            return vat_loss  # already averaged\n",
        "    \n",
        "    \n",
        "    def kl_divergence_with_logit(q_logit, p_logit):\n",
        "        q = F.softmax(q_logit, dim=1)\n",
        "        qlogq = torch.mean(torch.sum(q * F.log_softmax(q_logit, dim=1), dim=1))\n",
        "        qlogp = torch.mean(torch.sum(q * F.log_softmax(p_logit, dim=1), dim=1))\n",
        "        return qlogq - qlogp\n",
        "    \n",
        "    \n",
        "    def get_normalized_vector(d):\n",
        "        d_abs_max = torch.max(\n",
        "            torch.abs(d.view(d.size(0), -1)), 1, keepdim=True)[0].view(\n",
        "                d.size(0), 1, 1, 1)\n",
        "        # print(d_abs_max.size())\n",
        "        d /= (1e-12 + d_abs_max)\n",
        "        d /= torch.sqrt(1e-6 + torch.sum(\n",
        "            torch.pow(d, 2.0), tuple(range(1, len(d.size()))), keepdim=True))\n",
        "        # print(torch.norm(d.view(d.size(0), -1), dim=1))\n",
        "        return d\n",
        "    \n",
        "    \n",
        "    def generate_virtual_adversarial_perturbation(x, logit, model, n_power, XI,\n",
        "                                                  epsilon):\n",
        "        d = torch.randn_like(x)\n",
        "    \n",
        "        for _ in range(n_power):\n",
        "            d = XI * get_normalized_vector(d).requires_grad_()\n",
        "            logit_m = model(x + d)\n",
        "            dist = kl_divergence_with_logit(logit, logit_m)\n",
        "            grad = torch.autograd.grad(dist, [d])[0]\n",
        "            d = grad.detach()\n",
        "    \n",
        "        return epsilon * get_normalized_vector(d)\n",
        "    \n",
        "    \n",
        "    def virtual_adversarial_loss(x, logit, model, n_power, XI, epsilon):\n",
        "        r_vadv = generate_virtual_adversarial_perturbation(x, logit, model,\n",
        "                                                          n_power, XI, epsilon)\n",
        "        logit_p = logit.detach()\n",
        "        logit_m = model(x + r_vadv)\n",
        "        loss = kl_divergence_with_logit(logit_p, logit_m)\n",
        "        return loss\n",
        "    #--------------------------------------------------------------------------------\n",
        "\n",
        "    if self.hparams['epoch_over'] == 'unlabeled_train_dataset':\n",
        "      l_embeddings = l_embeddings.cuda()\n",
        "      labels = labels.cuda()\n",
        "      unl_embeddings = unl_embeddings['embedding']\n",
        "    elif self.hparams['epoch_over'] == 'labeled_train_dataset':\n",
        "      unl_embeddings = unl_embeddings['embedding'].cuda()\n",
        "    else:\n",
        "      raise ValueError('Wrong epoch_over type: {} \\\n",
        "       \\n Possibilities: unlabeled_train_dataset, labeled_train_dataset'.format(self.hparams['epoch_over']))\n",
        "      \n",
        "    vat = VAT(model=self.forward, hparams=self.hparams)\n",
        "    \n",
        "    label_logit = self.forward(l_embeddings)\n",
        "    unlabel_logit = self.forward(unl_embeddings)\n",
        "    supervised_loss = self.loss_fct(label_logit, labels) \n",
        "    vat_loss = vat(unl_embeddings, unlabel_logit)\n",
        "    loss = supervised_loss + self.hparams['alpha'] * vat_loss\n",
        "      \n",
        "    return label_logit, loss, logs\n",
        "      \n",
        "\n",
        "\n",
        "  def fixmatch(self, l_embeddings, labels, unl_embeddings, logs):\n",
        "\n",
        "    unl_w_dict, unl_s_dict = unl_embeddings\n",
        "    unl_w, unl_s = unl_w_dict['embedding'], unl_s_dict['embedding']\n",
        "\n",
        "    if self.hparams['epoch_over'] == 'unlabeled_train_dataset':\n",
        "\n",
        "      if self.hparams['model_arch'] == 'transformer':\n",
        "        l_embeddings = toolz.dicttoolz.valmap(torch.Tensor.cuda, l_embeddings)\n",
        "        labels = labels.cuda()\n",
        "      else:\n",
        "        l_embeddings = l_embeddings.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "    elif self.hparams['epoch_over'] == 'labeled_train_dataset':\n",
        "  \n",
        "      if self.hparams['model_arch'] == 'transformer':\n",
        "        unl_w = toolz.dicttoolz.valmap(torch.Tensor.cuda, unl_w)\n",
        "        unl_s = toolz.dicttoolz.valmap(torch.Tensor.cuda, unl_s)\n",
        "      else:\n",
        "        unl_w = unl_w.cuda() \n",
        "        unl_s = unl_s.cuda() \n",
        "    else:\n",
        "      raise ValueError('Wrong epoch_over type: {} \\\n",
        "       \\n Possibilities: unlabeled_train_dataset, labeled_train_dataset'.format(self.hparams['epoch_over']))\n",
        "\n",
        "    # if self.hparams['model_arch'] == 'transformer':\n",
        "\n",
        "    #   stacked_inputs_ids = torch.cat((l_embeddings[\"input_ids\"],\n",
        "    #                                   unl_w['input_ids'],\n",
        "    #                                   unl_s['input_ids']))\n",
        "      \n",
        "    #   stacked_attention_mask = torch.cat((l_embeddings[\"attention_mask\"],\n",
        "    #                                       unl_w['attention_mask'],\n",
        "    #                                       unl_s['attention_mask']))\n",
        "      \n",
        "    #   stacked_token_type_ids = torch.cat((l_embeddings[\"token_type_ids\"],\n",
        "    #                                       unl_w['token_type_ids'],\n",
        "    #                                       unl_s['token_type_ids']))\n",
        "    \n",
        "    #   x = {\n",
        "    #        \"inputs_ids\": stacked_inputs_ids,\n",
        "    #        \"attention_mask\": stacked_attention_mask,\n",
        "    #        \"token_type_ids\": stacked_token_type_ids\n",
        "    #       }\n",
        "    # else:\n",
        "      # x = torch.cat((l_embeddings,\n",
        "      #                unl_w,\n",
        "      #                unl_s))\n",
        "\n",
        "    # logits = self.forward(x)\n",
        "    # batch_size = self.hparams['l_batch_size'] \n",
        "    logits_x = self.forward(l_embeddings)\n",
        "    # logits_u_w, logits_u_s = logits[batch_size:].chunk(2)\n",
        "    logits_u_w, logits_u_s = self.forward(unl_w), self.forward(unl_s) \n",
        "\n",
        "    # del logits\n",
        "     \n",
        "    Lx = F.cross_entropy(logits_x, labels, reduction='mean')\n",
        "\n",
        "    pseudo_label = torch.softmax(logits_u_w.detach_(), dim=-1)\n",
        "    max_probs, targets_u = torch.max(pseudo_label, dim=-1)\n",
        "\n",
        "    confident_keys = ['unl_max_confident', 'unl_min_confident',\n",
        "                      'unl_mean_confident', 'unl_std_confident']\n",
        "    confident_values = juxt(torch.max, torch.min, torch.mean, torch.std) \\\n",
        "                           (max_probs)\n",
        "    confident_dict = dict(zip(confident_keys, confident_values))\n",
        "    logs.update(confident_dict)\n",
        "\n",
        "    mask = max_probs.ge(self.hparams['threshold']).float()\n",
        "    Lu = (F.cross_entropy(logits_u_s, targets_u,\n",
        "                          reduction='none') * mask).mean()\n",
        "\n",
        "    loss = Lx + self.hparams['lambda_u'] * Lu\n",
        "    logs.update({\"Lu\": Lu, 'Lx': Lx})\n",
        "\n",
        "    return logits_x, loss, logs\n",
        "\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "\n",
        "    if self.hparams['epoch_over'] == 'unlabeled_train_dataset':\n",
        "\n",
        "      try:\n",
        "        # it it automatically that values are unpacked?\n",
        "        l_batch = next(self.train_labeled_dataloader_iterator)\n",
        "  \n",
        "      except StopIteration:\n",
        "        self.train_labeled_dataloader_iterator = iter(self.train_labeled_dataloader)\n",
        "        l_batch = next(self.train_labeled_dataloader_iterator)\n",
        "      \n",
        "      l_embeddings, labels = l_batch['embedding'], l_batch['label']\n",
        "\n",
        "      unlabeled = batch\n",
        "\n",
        "    elif self.hparams['epoch_over'] == 'labeled_train_dataset':\n",
        "\n",
        "      try:\n",
        "        unlabeled = next(self.train_unlabeled_dataloader_iterator)\n",
        "\n",
        "      except StopIteration:\n",
        "        self.train_unlabeled_dataloader_iterator = iter(self.train_unlabeled_dataloader)\n",
        "        unlabeled = next(self.train_unlabeled_dataloader_iterator)\n",
        "      \n",
        "      l_embeddings, labels = batch['embedding'], batch['label']\n",
        "\n",
        "    else:\n",
        "      raise ValueError('Wrong epoch_over type: {} \\\n",
        "       \\n Possibilities: unlabeled_train_dataset, labeled_train_dataset'.format(self.hparams['epoch_over']))\n",
        "    # print('x: ', l_embeddings.shape)\n",
        "    # print('y: ', labels.shape)\n",
        "    logs = dict()\n",
        "\n",
        "    if self.hparams['training_method'] == \"Supervised\":\n",
        "      logits, loss, logs = self.supervised(l_embeddings, labels, logs)\n",
        "    \n",
        "    elif self.hparams['training_method'] == \"PseudoLabelling\":\n",
        "      logits, loss, logs = self.pseudo_labelling(l_embeddings, labels, unlabeled, logs)\n",
        "\n",
        "    elif self.hparams['training_method'] == 'VAT':\n",
        "      logits, loss, logs = self.vat(l_embeddings, labels, unlabeled, logs)\n",
        "\n",
        "    elif self.hparams['training_method'] == \"FixMatch\":\n",
        "      logits, loss, logs = self.fixmatch(l_embeddings, labels, unlabeled, logs)\n",
        "\n",
        "    else:\n",
        "      raise ValueError('Wrong training method type: {} \\n \\\n",
        "        Possible methods : VAT, FixMatch, Supervised'.format(self.hparams['traning_method']))\n",
        "\n",
        "    probabilities = torch.softmax(logits.detach(), dim=-1)\n",
        "    gpu_max_probs, gpu_labels_hat = torch.max(probabilities, dim=-1)\n",
        "\n",
        "    cpu_labels = labels.detach().cpu().numpy()\n",
        "    cpu_labels_hat = gpu_labels_hat.detach().cpu().numpy()\n",
        "    cpu_max_probs = gpu_max_probs.detach().cpu().numpy()\n",
        "    cpu_loss = loss.clone().detach().cpu().numpy()\n",
        "\n",
        "\n",
        "    metrics_dict = create_metrics_dict('train',\n",
        "                                       cpu_loss,\n",
        "                                       cpu_labels,\n",
        "                                       cpu_labels_hat,\n",
        "                                       cpu_max_probs,\n",
        "                                      )\n",
        "\n",
        "    logs.update(metrics_dict)    \n",
        "    logs.update({'step': self.current_step})\n",
        "    self.current_step += 1\n",
        "\n",
        "    return {\n",
        "            'loss': loss,\n",
        "            # \"progress_bar\": logs,\n",
        "            'log': logs}\n",
        "\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "\n",
        "    embeddings = batch['embedding']\n",
        "    labels = batch['label']\n",
        "  \n",
        "    logits = self.forward(embeddings, val_mode=True)\n",
        "    loss = self.loss_fct(logits, labels)\n",
        "\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    max_probs, labels_hat = torch.max(probabilities, dim=-1)\n",
        "\n",
        "    cpu_labels = labels.detach().cpu().numpy()\n",
        "    cpu_labels_hat = labels_hat.detach().cpu().numpy()\n",
        "    cpu_max_probs = max_probs.detach().cpu().numpy()\n",
        "    cpu_loss = loss.clone().detach().cpu().numpy()\n",
        "\n",
        "    output = create_metrics_dict('val',\n",
        "                                 cpu_loss,\n",
        "                                 cpu_labels,\n",
        "                                 cpu_labels_hat,\n",
        "                                 cpu_max_probs)\n",
        "    output['val_gpu_loss'] = loss\n",
        "    \n",
        "    return output\n",
        "\n",
        "  def validation_epoch_end(self, outputs):\n",
        "    val_loss_mean = torch.mean(torch.tensor([output.pop('val_gpu_loss') for output in outputs]))\n",
        "    val_accuracy_error_mean = torch.mean(torch.Tensor([output['val_accuracy_error'] for output in outputs]))\n",
        "    tqdm_dict = toolz.merge_with(np.mean, outputs)\n",
        "    return {\n",
        "            \"progress_bar\": tqdm_dict,\n",
        "            \"log\": tqdm_dict,\n",
        "            'val_loss': val_loss_mean,\n",
        "            'val_accuracy_error': val_accuracy_error_mean\n",
        "           }\n",
        "\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "\n",
        "    embeddings = batch[\"embedding\"]\n",
        "    labels = batch[\"label\"]\n",
        "  \n",
        "    logits = self.forward(embeddings, val_mode=True)\n",
        "    loss = self.loss_fct(logits, labels)\n",
        "\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    max_probs, labels_hat = torch.max(probabilities, dim=-1)\n",
        "\n",
        "    cpu_labels = labels.detach().cpu().numpy()\n",
        "    cpu_labels_hat = labels_hat.detach().cpu().numpy()\n",
        "    cpu_max_probs = max_probs.detach().cpu().numpy()\n",
        "    cpu_loss = loss.detach().cpu().numpy()\n",
        "    \n",
        "    output = create_metrics_dict('test',\n",
        "                                 cpu_loss,\n",
        "                                 cpu_labels,\n",
        "                                 cpu_labels_hat,\n",
        "                                 cpu_max_probs)\n",
        "    output['test_loss_gpu'] = loss\n",
        "    \n",
        "    return output \n",
        "\n",
        "\n",
        "  def test_epoch_end(self, outputs):\n",
        "    test_loss_mean = torch.mean(torch.tensor([output.pop('test_loss_gpu') for output in outputs]))\n",
        "    tqdm_dict = toolz.merge_with(np.mean, outputs)\n",
        "\n",
        "    return {\n",
        "            \"progress_bar\": tqdm_dict,\n",
        "            \"log\": tqdm_dict,\n",
        "            'test_loss': test_loss_mean \n",
        "           }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aYX9ZJVIoEs",
        "colab_type": "text"
      },
      "source": [
        "### Configure experiment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC9zE6cKkbPi",
        "colab_type": "text"
      },
      "source": [
        "##### Choose dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEwfu7pNkDJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset = 'MNIST'\n",
        "# dataset = \"IMDB\"\n",
        "dataset = \"MR\"\n",
        "\n",
        "if dataset == 'IMDB':\n",
        "  dataset_path = str(Path()/\n",
        "                        'gdrive'/\n",
        "                        'My Drive'/\n",
        "                        'praca_magisterska'/\n",
        "                        'pytorch_lightning'/\n",
        "                        'datasets'/\n",
        "                        'imdb_with_bt.csv')\n",
        "  \n",
        "  hparams = {\"dataset\": 'IMDB',\n",
        "            \"num_classes\": 2,\n",
        "            \"dataset_path\": dataset_path,\n",
        "            }\n",
        "\n",
        "\n",
        "elif dataset == 'MR':\n",
        "  dataset_path = str(Path()/\n",
        "                        'gdrive'/\n",
        "                        'My Drive'/\n",
        "                        'praca_magisterska'/\n",
        "                        'pytorch_lightning'/\n",
        "                        'datasets'/\n",
        "                        'mr_with_bt2.csv')\n",
        "  \n",
        "  hparams = {\"dataset\": 'MR',\n",
        "            \"num_classes\": 2,\n",
        "            \"dataset_path\": dataset_path,\n",
        "            }\n",
        "\n",
        "elif dataset == 'MNIST':\n",
        "  dataset_path = str(Path()/\n",
        "                        'gdrive'/\n",
        "                        'My Drive'/\n",
        "                        'praca_magisterska'/\n",
        "                        'pytorch_lightning'/\n",
        "                        'datasets'\n",
        "                        )\n",
        "  \n",
        "  hparams = {\"dataset\": 'MNIST',\n",
        "            \"num_classes\": 10,\n",
        "            \"dataset_path\": dataset_path,\n",
        "            'mean': 0.1307,\n",
        "            'std': 0.3081,\n",
        "            }\n",
        "\n",
        "elif dataset == 'NLUHD':\n",
        "  dataset_path = str(Path()/\n",
        "                    'gdrive'/\n",
        "                    'My Drive'/\n",
        "                    'praca_magisterska'/\n",
        "                    'pytorch_lightning'/\n",
        "                    'datasets'/\n",
        "                    'NLU-Data-Home-Domain-preprocessed-without-ner.csv')\n",
        "  \n",
        "  hparams = {\"dataset\": 'NLUHD',\n",
        "            \"num_classes\": 68,\n",
        "            \"dataset_path\": dataset_path}\n",
        "            \n",
        "else:\n",
        "  raise ValueError('Wrong dataset name : {} \\\n",
        "   \\n Possible datasets: IMDB, MR, NLUHD'.format(hparams['dataset']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uf3R7m6kd6z",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##### Choose traning method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxhbdqoNkeGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_method = 'Supervised' \n",
        "# training_method = 'PseudoLabelling' \n",
        "# training_method = 'VAT' \n",
        "# training_method = 'FixMatch' \n",
        "\n",
        "if training_method == 'Supervised':\n",
        "  hparams.update({\"training_method\": 'Supervised',\n",
        "                  \n",
        "                  'l_batch_size': 32,\n",
        "                  'unl_batch_size': 32, \n",
        "                  \n",
        "                  'optimizer_type': 'Adam',\n",
        "                  'lr': 1e-05,\n",
        "                  \n",
        "                  'scheduler_type': 'None',\n",
        "                  # 'opt_scheduler_interval': 'epoch',\n",
        "                  # 'decay_step_size': 10000,\n",
        "                  # 'decay_gamma':0.5,\n",
        "                  'max_steps': 1000\n",
        "                  # 'max_epochs': 3,\n",
        "                  # 'min_epochs': 1 \n",
        "\n",
        "  })\n",
        "  \n",
        "elif training_method == 'PseudoLabelling':\n",
        "  hparams.update({\"training_method\": 'PseudoLabelling',\n",
        "                  \n",
        "                  'T1': 2000,\n",
        "                  # 'T2': 5600, == total_iterations\n",
        "                  'af': 1,                  \n",
        "                  'alpha_scheduler_interval': 'step',\n",
        "\n",
        "                  'l_batch_size': 32,\n",
        "                  'unl_batch_size': 32, \n",
        "                  \n",
        "                  'optimizer_type': 'Adam',\n",
        "                  'lr': 1e-05,\n",
        "                  'max_steps': 10000\n",
        "\n",
        "                  # 'scheduler_type': 'None',\n",
        "                  # 'opt_scheduler_interval': 'epoch',\n",
        "                  # 'decay_step_size': 10000,\n",
        "                  # 'decay_gamma':0.5,\n",
        "                  # 'max_epochs': 3,\n",
        "                  # 'min_epochs': 1 \n",
        "  })\n",
        "\n",
        "elif training_method == 'VAT':\n",
        "  hparams.update({\"training_method\": 'VAT',\n",
        "                  \n",
        "                  'l_batch_size': 64,\n",
        "                  'unl_batch_size': 256, # mu = 7\n",
        "                  \n",
        "                  'xi':1e-6,\n",
        "                  'eps':3, \n",
        "                  'K':1, \n",
        "                  'alpha':1,\n",
        "\n",
        "                  'optimizer_type': 'Adam',\n",
        "                  'lr': 2e-05,\n",
        "                  'scheduler_type': 'StepLR',\n",
        "                  'opt_scheduler_interval': 'step',\n",
        "                  'decay_gamma': 0.5, # multiplicative factor of learning rate decay. Default: 0.1.\n",
        "                  'decay_step_size': 2000, # period of learning rate decay\n",
        "\n",
        "                  'decay_step': 2000, # when to lunch scheduler\n",
        "                  'max_steps': 10000,\n",
        "                })\n",
        "  \n",
        "  \n",
        "elif training_method == 'FixMatch':\n",
        "  hparams.update({\n",
        "                  'training_method': 'FixMatch',\n",
        "                  'l_batch_size': 32,\n",
        "                  'unl_batch_size': 224, # mu = 7\n",
        "\n",
        "                  'mu': 7, \n",
        "                  'threshold': 0.999,\n",
        "                  'lambda_u': 0.1,\n",
        "                  'n_weak': 1,\n",
        "                  'n_strong': 3,\n",
        "                  'm_weak': 2,\n",
        "                  'm_strong': 5,\n",
        "\n",
        "                  'optimizer_type': 'SGD',\n",
        "                  'lr': 0.03,\n",
        "                  'momentum': 0.9,\n",
        "                  'weight_decay': 0.0005,\n",
        "                  'nesterov': False,\n",
        "                  # 'optimizer_type': 'Adam',\n",
        "                  # 'lr': 1e-05,\n",
        "                  # 'scheduler_type': 'StepLR',\n",
        "\n",
        "                  # 'opt_scheduler_interval': 'step',\n",
        "                  # 'decay_gamma': 0.5, # multiplicative factor of learning rate decay. Default: 0.1.\n",
        "                  # 'decay_step_size': 2000, # period of learning rate  decay\n",
        "\n",
        "                  # 'decay_step': 2000, # when to lunch scheduler\n",
        "                  # 'max_steps': 10000,\n",
        "                  # sprobuj tak samo jak z VATEM czyli StepLR\n",
        "                  \n",
        "                  # 'scheduler_type': None,\n",
        "                  # 'scheduler_type': 'CosineAnnealingLR',\n",
        "                  'scheduler_type': 'LinearWarmUpLR',\n",
        "                  # 'scheduler_type': \"CosineWarmupLR\",\n",
        "                  'warmup_steps': 1000,\n",
        "                  # 'num_cycles': 7./16.,\n",
        "                  # 'num_cycles': 2,\n",
        "                  'opt_scheduler_interval': 'step',\n",
        "\n",
        "                  'show_augmentation': False,\n",
        "                  'max_steps': 6000,\n",
        "                  # 'max_epochs': 3,\n",
        "                  # 'min_epochs': 1 \n",
        "                })\n",
        "  \n",
        "else:\n",
        "  raise ValueError('Wrong training method type: {} \\\n",
        "     \\n Possible methods : VAT, FixMatch, Supervised'.format(self.hparams['training_method']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FownSMlUmIzo",
        "colab_type": "text"
      },
      "source": [
        "#### Choose model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH4lZGqlmJAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_arch = 'ConvolutionMNIST'\n",
        "model_arch = 'Convolution'\n",
        "# model_arch = 'FFNNMNIST'\n",
        "# model_arch = 'FFNNMNIST_VAT'\n",
        "\n",
        "if model_arch == \"Transformer\":\n",
        "  hparams.update({\n",
        "      'model_arch': model_arch,\n",
        "      'model_type': 'bert-base-uncased',\n",
        "      'max_sentence_len': 156,\n",
        "\n",
        "      'xi': 0.00001,\n",
        "      'lr': 5e-05,\n",
        "      'weight_decay': 0.01,\n",
        "      'adam_eps': 1e-06,\n",
        "      'warmup_steps': 150,\n",
        "      })\n",
        "\n",
        "elif model_arch == 'Convolution':\n",
        "  hparams.update({\n",
        "           'model_arch': model_arch,\n",
        "           'max_sentence_len': 700,\n",
        "           'embeder_type': 'fastText_with_spaCy',\n",
        "           'embed_dim': 300,\n",
        "           'Ci': 1,\n",
        "           'kernel_num': 100,\n",
        "           'kernel_sizes': '3,4,5',\n",
        "           'dropout':0.0, \n",
        "  })\n",
        "\n",
        "elif model_arch == 'ConvolutionMNIST':\n",
        "  hparams.update({\n",
        "           'model_arch': model_arch,\n",
        "           'dropout1':0.25,\n",
        "           'dropout2':0.5,\n",
        "  })\n",
        "\n",
        "elif model_arch == 'FFNNMNIST_VAT':\n",
        "  hparams.update({\n",
        "           'model_arch': model_arch,\n",
        "           'isotropic_noise': 0.5,\n",
        "  })\n",
        "\n",
        "elif model_arch == 'FFNNMNIST':\n",
        "  hparams.update({\n",
        "           'model_arch': model_arch,\n",
        "  })\n",
        "else:\n",
        "  raise ValueError('Wrong model architecture type: {} \\\n",
        "   \\n Possible datasets: Transformer, Convolution'.format(self.hparams['model_arch']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st6sL-cOwym2",
        "colab_type": "text"
      },
      "source": [
        "#### Choose training params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8YWsCR-jGM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " hparams.update({\n",
        "           'seed': 42,\n",
        "          #  'seed': 1, change every fold_run\n",
        "          #  'seed': 102,\n",
        "\n",
        "           'train_test_split': 0.9,\n",
        "           'val_batch_size': 16,\n",
        "           'test_batch_size': 16,\n",
        "           'n_labeled': 1600, # number of labeled samples  # must be a multiplication of l_batch_size\n",
        "          #  'n_labeled': 500, # number of labeled samples  # must be a multiplication of l_batch_size\n",
        "          #  'n_labeled': 1000, # number of labeled samples  # must be a multiplication of l_batch_size\n",
        "           'valid_size_per_class': 96, # 68 class => n_val_samples = 68 * 10 \n",
        "          #  'valid_size_per_class': 25, # 68 class => n_val_samples = 68 * 10 \n",
        "          #  'valid_size_per_class': 100, # 68 class => n_val_samples = 68 * 10 \n",
        "\n",
        "           'loss_function':'CrossEntropyLoss',\n",
        "\n",
        "           'test_run': False,\n",
        "           'save_best_model': True,\n",
        "           'epoch_over': 'labeled_train_dataset',           \n",
        "          #  'epoch_over': 'unlabeled_train_dataset',           \n",
        "          #  'val_check_interval': 0.5, # change interval if epoch is on unlabeled \n",
        "          #  'patience': 15, # early stopping callback parameter\n",
        " }) \n",
        "\n",
        "tags = []\n",
        "tags.append(hparams['dataset'])\n",
        "tags.append(hparams['model_arch'])\n",
        "tags.append(hparams['training_method'])\n",
        "tags.append(str(hparams['n_labeled']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjha3vit9omj",
        "colab_type": "text"
      },
      "source": [
        "### Tests "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DWq_Q17ENpc",
        "colab_type": "text"
      },
      "source": [
        "#### Test if lf.cv.split splits in stratified fashion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e-bcGspDUnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ds = lf.CsvDataset(os.path.join(os.environ['DATASETS_PATH'], 'NLU-Data-Home-Domain-preprocessed-without-ner.csv'), header=True)\n",
        "# ds = ds.filter(lambda x: x['text'] is not None)\n",
        "\n",
        "# train, test = lf.cross_validation.split_dataset_random(ds, int(len(ds) * 0.8), seed=42)\n",
        "# df_train = pd.DataFrame(train)\n",
        "# df_test = pd.DataFrame(test)\n",
        "# # df_train['intent'].value_counts().plot(kind=\"bar\", figsize= (21,20))\n",
        "# df_test['intent'].value_counts().plot(kind=\"bar\", figsize= (21,20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vhpT-QpSOrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pd.set_option('display.max_rows', None)\n",
        "# df_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfAShMKL9oH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nlp = spacy.load(\"en\", disable=['parser', 'tagger', 'ner'])\n",
        "# uter = '[greetings : Hello] there what is [swear_word: fuck] up ?'\n",
        "# # uter =  '[greetings : Hello] there what is fuck up ?'\n",
        "# # uter = \"hello adfafdasfsaf sfsafdsafsa\"\n",
        "# comment = nlp(uter)\n",
        "# processed_comment = prepare_NLUHD(comment, nlp=nlp,ner_abstract_tag=False)\n",
        "# processed_comment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isgALgNl86Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train = lfds.MsrParaphrase(\"train\")\n",
        "# print(len(train))\n",
        "# test = lfds.MsrParaphrase(\"test\")\n",
        "# train.first()\n",
        "# def nonefilter(dataset):\n",
        "#   filtered = []\n",
        "#   for x in dataset:\n",
        "#       if x[\"string1\"] is None:\n",
        "#           continue\n",
        "#       if x[\"string2\"] is None:\n",
        "#           continue\n",
        "#       filtered.append(x)\n",
        "#   return lf.Dataset(filtered)\n",
        "# # train = nonefilter(train)\n",
        "# train = train.filter(lambda x: x[\"string1\"] is not None and x[\"string2\"] is not None)\n",
        "# print(len(train))\n",
        "# train.take(3)\n",
        "# unique = list(['ale', 'beka'])\n",
        "# le = preprocessing.LabelEncoder().fit(unique)\n",
        "# torch.tensor(int(le.transform(['ale'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9cu0GG3qjHz",
        "colab_type": "text"
      },
      "source": [
        "#### Test IMDB preprocessing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOH9NEJHhTyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hparams = {'max_sentence_len': 200,\n",
        "#            'embed_dim': 300,\n",
        "#            'seed': 42,\n",
        "#            'train_test_split': 0.8}\n",
        "\n",
        "# train = lfds.Imdb('train')\n",
        "# test = lfds.Imdb('test')\n",
        "# ds = train + test\n",
        "# ds = ds.map(lambda x: {'text':x[0] , 'label': x[1]})\n",
        "# embeder = nlp \n",
        "# tokenizer_fun = lambda x: x#gensim_tokenizer\n",
        "# unique_labels = list(pd.DataFrame(ds).label.unique())\n",
        "# le = preprocessing.LabelEncoder().fit(unique_labels)\n",
        "\n",
        "# preprocessor = partial(\n",
        "#                       preprocess_IMDB,\n",
        "#                       hparams,\n",
        "#                       tokenizer_fun, \n",
        "#                       embeder,\n",
        "#                       le,\n",
        "#                       )\n",
        "# s = ds.first()\n",
        "# print(s)\n",
        "# preprocessor(s)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YDThFsqiBYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# train = lfds.Imdb('train')\n",
        "# test = lfds.Imdb('test')\n",
        "# ds = train + test\n",
        "# ds = ds.map(lambda x: {'text':x[0] , 'label': x[1]})\n",
        "# df = pd.DataFrame(ds)\n",
        "# pattern1 = re.compile(r'<.*?>')\n",
        "# # pattern2 = re.compile('[\\W_]+')\n",
        "# # text = pattern1.sub('', sample['text'])\n",
        "# # print('text after p1: ', text)\n",
        "# # text = text.replace('_', '').lower()\n",
        "# func = partial(pattern1.sub,\n",
        "#                '')\n",
        "# df['text'] = df['text'].apply(func)\n",
        "# # df\n",
        "# texts = list(df['text'])\n",
        "# texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ac1FViOh833",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ft.build_vocab(texts, update=True)\n",
        "# ft.train(new_sentences, total_examples=len(texts), epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHn7X8Oc2IJN",
        "colab_type": "text"
      },
      "source": [
        "#### Test FixMatchTransform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIOUS2Fr2NLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf = TransformFix(1,show=True)\n",
        "# s = tf(\"what will be the weather like tomorrow, please tell me\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0Yw_j3YaDTg",
        "colab_type": "text"
      },
      "source": [
        "#### Test balanced sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-29zVc12aDe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# not_none = lambda x: x[\"text\"] is not None \n",
        "# # ds = lf.CsvDataset(self.hparams['dataset_path'], header=True).filter(not_none)\n",
        "# ds = lfds.Imdb('train') + lfds.Imdb('test')\n",
        "# ds = ds.map(lambda x: {'text': x[0], 'label': x[1]})\n",
        "# df = pd.DataFrame(ds)\n",
        "\n",
        "# create_tfidf_model(df)\n",
        "\n",
        "# print(df.info(memory_usage=True))\n",
        "# unique_labels = list(df.label.unique())\n",
        "# print(f'unique_labels: {unique_labels}')\n",
        "# print(f'number_of_categories : {len(unique_labels)}')\n",
        "# le = preprocessing.LabelEncoder().fit(unique_labels)\n",
        "# train, test = lf.cross_validation.split_dataset_random(ds,\n",
        "#                                                         int(len(ds) * 0.9),\n",
        "#                                                         seed=42)\n",
        "\n",
        "# dataset_preprocessor = partial(\n",
        "#                                 preprocess_IMDB,\n",
        "#                                 le,\n",
        "#                               )\n",
        "\n",
        "# tokenizer_dict = {\n",
        "#         \"bert-base-uncased\":\n",
        "#           BertTokenizer.from_pretrained(\"bert-base-uncased\",\n",
        "#                                         do_lower_case=True),\n",
        "#         \"roberta-base\":\n",
        "#           RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "#         }\n",
        "\n",
        "\n",
        "# model_arch_preprocessor = partial(\n",
        "#                                   transformer_preprocessing,\n",
        "#                                   'bert-base-uncased',\n",
        "#                                   156,\n",
        "#                                   tokenizer_dict['bert-base-uncased'],\n",
        "#                                   )\n",
        "\n",
        "\n",
        "# preprocessor = toolz.compose(\n",
        "#                             model_arch_preprocessor,\n",
        "#                             dataset_preprocessor,\n",
        "#                             )\n",
        "\n",
        "# train_df, test_df = pd.DataFrame(train), pd.DataFrame(test)\n",
        "# x_train, y_train = train_df['text'].values, train_df['label'].values\n",
        "# x_test, y_test = test_df['text'].values, test_df['label'].values\n",
        "\n",
        "# # split's training parameters  \n",
        "# num_classes = len(unique_labels)\n",
        "# label_per_class = 1000 // num_classes\n",
        "# valid_size = 1000 \n",
        "\n",
        "# labeled_idx = []\n",
        "# unlabeled_idx = []\n",
        "# val_idx = []\n",
        "\n",
        "# for label in unique_labels:\n",
        "#   idx = np.where(y_train == label)[0]\n",
        "#   np.random.shuffle(idx)\n",
        "#   labeled_idx.extend(idx[:label_per_class])\n",
        "#   val_idx.extend(idx[label_per_class: label_per_class + valid_size])\n",
        "#   unlabeled_idx.extend(idx[label_per_class + valid_size:])\n",
        "\n",
        "# x_labeled, y_labeled  = x_train[labeled_idx], y_train[labeled_idx]\n",
        "# x_unlabeled, y_unlabeled = x_train[unlabeled_idx], y_train[unlabeled_idx]\n",
        "# x_val, y_val = x_train[val_idx], y_train[val_idx]\n",
        "\n",
        "\n",
        "# train_labeled_dataset = SimpleTextDataset(x_labeled,\n",
        "#                                               y_labeled,\n",
        "#                                               transform=preprocessor)\n",
        "# train_unlabeled_dataset = SimpleTextDataset(x_unlabeled,\n",
        "#                                                   y_unlabeled,\n",
        "#                                                   transform=preprocessor)\n",
        "\n",
        "# val_dataset = SimpleTextDataset(x_val,\n",
        "#                                     y_val,\n",
        "#                                     transform=preprocessor)\n",
        "\n",
        "# test_dataset = SimpleTextDataset(x_test,\n",
        "#                                       y_test,\n",
        "#                                       transform=preprocessor)\n",
        "\n",
        "\n",
        "\n",
        "# train_labeled_dataloader = torch.utils.data.DataLoader(\n",
        "#                       train_labeled_dataset,\n",
        "#                       batch_size=64,\n",
        "#                       # shuffle=True,\n",
        "#                       num_workers=0,\n",
        "#                       sampler=BalancedBatchSampler(train_labeled_dataset, y_labeled),\n",
        "#                       )\n",
        "\n",
        "# train_labeled_dataloader_iterator = iter(train_labeled_dataloader)\n",
        "# train_unlabeled_dataloader = DataLoader(\n",
        "#                 train_unlabeled_dataset,\n",
        "#                 batch_size=64,\n",
        "#                 num_workers=8,\n",
        "#                 shuffle=True # without shuffle it want work cause it need to create map index before __get_item__ function\n",
        "#                 )\n",
        "\n",
        "# train_labeled_dataloader_iterator = iter(train_labeled_dataloader)\n",
        "# batch = next(train_labeled_dataloader_iterator)\n",
        "# print(torch.sum(batch['label']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMARxMrnTMzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epochs = 3\n",
        "# size = 20\n",
        "# features = 5\n",
        "# classes_prob = torch.tensor([0.1, 0.4, 0.5])\n",
        "\n",
        "# dataset_X = torch.randn(size, features)\n",
        "# dataset_Y = torch.distributions.categorical.Categorical(classes_prob.repeat(size, 1)).sample()\n",
        "# print(dataset_Y)\n",
        "\n",
        "# dataset = torch.utils.data.TensorDataset(dataset_X, dataset_Y)\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(dataset, sampler=BalancedBatchSampler(dataset, dataset_Y), batch_size=6)\n",
        "\n",
        "# for epoch in range(0, epochs):\n",
        "#     for batch_x, batch_y in train_loader:\n",
        "#         print(\"epoch: %d labels: %s\\ninputs: %s\\n\" % (epoch, batch_y, batch_x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVxlMTAX9hUH",
        "colab_type": "text"
      },
      "source": [
        "#### Test embeder if exist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfDzoDan9gkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokens = nlp('213213dsf ma kota')\n",
        "# tokenlist = [token.vector for token in tokens]\n",
        "# t = torch.Tensor(tokenlist)\n",
        "# t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCpso0jN-jKw",
        "colab_type": "text"
      },
      "source": [
        "#### Test weights and biases changes in model architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN-ernJqP0dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from torchtest import assert_vars_change, assert_vars_same\n",
        "# from torch.autograd import Variable\n",
        "\n",
        "# model = LitComposableFramework(hparams)\n",
        "# model.prepare_data()\n",
        "# model.train_dataloader()\n",
        "\n",
        "# # what are the variables?\n",
        "# print('Our list of parameters', [ np[0] for np in model.named_parameters() ])\n",
        "\n",
        "# # do they change after a training step?\n",
        "\n",
        "# batch = next(model.train_unlabeled_dataloader_iterator)\n",
        "\n",
        "# class Wrapper():\n",
        "#   def __init__(self, values, model_arch):\n",
        "#     self.values = values \n",
        "#     self.model_arch = model_arch\n",
        "\n",
        "#   def to(self, device):\n",
        "#     if self.model_arch == 'Transformer':\n",
        "#       for k, v in self.values.items():\n",
        "#           self.values[k] = v.to(device)\n",
        "#       return self.values\n",
        "#     else:\n",
        "#       return self.values.to(device) \n",
        "\n",
        "# def convert_batch_format(embedding, label):\n",
        "#   return [Wrapper(embedding, hparams['model_arch']),\n",
        "#           label, hparams['model_arch']]\n",
        "\n",
        "# converted_batch = convert_batch_format(**batch)\n",
        "\n",
        "# if hparams['model_arch'] == 'Transformer':\n",
        "#   assert_vars_same(\n",
        "#       model=model,\n",
        "#       loss_fn=F.cross_entropy,\n",
        "#       optim=torch.optim.Adam(model.parameters()),\n",
        "#       device= torch.cuda.current_device(),\n",
        "#       batch=converted_batch,\n",
        "#       params=[('model.pooler.dense.weight', model.model.pooler.dense.weight)])\n",
        "# else:\n",
        "#   assert_vars_change(\n",
        "#       model=model,\n",
        "#       loss_fn=F.cross_entropy,\n",
        "#       optim=torch.optim.Adam(model.parameters()),\n",
        "#       device= torch.cuda.current_device(),\n",
        "#       batch=converted_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvLcy17JrmCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gradients\n",
        "# for n, p in named_parameters:\n",
        "#         if(p.requires_grad) and (\"bias\" not in n):\n",
        "#             layers.append(n)\n",
        "#             ave_grads.append(p.grad.abs().mean())\n",
        "#             max_grads.append(p.grad.abs().max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1K0b38hTGez",
        "colab_type": "text"
      },
      "source": [
        "#### Test split_size of pytorch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-LRJLFlTHgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_ds = torchvision.datasets.MNIST('./',\n",
        "#                                     train=True, transform=None,\n",
        "#                                     target_transform=None, download=True)\n",
        "\n",
        "# test_ds = torchvision.datasets.MNIST('./',\n",
        "#                                   train=False, transform=None,\n",
        "#                                   target_transform=None, download=True)\n",
        "# train_x, train_y  = train_ds.data, train_ds.targets\n",
        "# test_x, test_y  = test_ds.data, test_ds.targets\n",
        "# full_x, full_y = torch.cat((train_x, test_x), 0), torch.cat((train_y, test_y), 0)\n",
        "\n",
        "# train_size = int(0.9 * full_x.shape[0])\n",
        "# test_size = full_x.shape[0] - train_size\n",
        "\n",
        "# train_x, test_x = size_splits(full_x,\n",
        "#                           [train_size, test_size])\n",
        "\n",
        "# train_y, test_y = size_splits(full_y,\n",
        "#                           [train_size, test_size])\n",
        "# train_y.shape\n",
        "# list(np.array(torch.unique(train_y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqmlfwNN175S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class TestSheduler:\n",
        "  def __init__(self):\n",
        "    self.current_epoch = 1\n",
        "    self.hparams = dict()\n",
        "    self.hparams['T1'] = 0\n",
        "\n",
        "                  # 'T1': 100,\n",
        "                  # 'T2': 600,\n",
        "                  # 'af': 0.3,                  \n",
        "    self.hparams['T2'] = 10 \n",
        "    self.hparams['af'] = 1 \n",
        "\n",
        "  def unlabeled_weight(self):\n",
        "      alpha = 0.0\n",
        "      if self.current_epoch > self.hparams['T1']:\n",
        "          alpha = (self.current_epoch-self.hparams['T1']) / \\\n",
        "            (self.hparams['T2']-self.hparams['T1']) * self.hparams['af']\n",
        "          if self.current_epoch > self.hparams['T2']:\n",
        "              alpha = self.hparams['af']\n",
        "      return alpha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLZ7W0al2HQ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc313c4-dd0c-412f-a379-4c426924c02e"
      },
      "source": [
        "test_scheduler = TestSheduler()\n",
        "epochs = 10\n",
        "for i in range(1, epochs):\n",
        "  print(test_scheduler.unlabeled_weight())\n",
        "  test_scheduler.current_epoch = i\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1\n",
            "0.1\n",
            "0.2\n",
            "0.3\n",
            "0.4\n",
            "0.5\n",
            "0.6\n",
            "0.7\n",
            "0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPPRVG2jlWZx",
        "colab_type": "text"
      },
      "source": [
        "#### Test data augmentation for MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjvnMt00XRIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean = 0.1307\n",
        "# std = 0.3081\n",
        "# n_strong = 1\n",
        "# m_strong = 3\n",
        "\n",
        "# n_weak = 1\n",
        "# m_weak = 2\n",
        "\n",
        "# fix_match_augmentation = TransformFixImage(\n",
        "#                                            mean=mean,\n",
        "#                                            std=std,\n",
        "#                                            n_strong=n_strong,\n",
        "#                                            m_strong=m_strong,\n",
        "#                                            n_weak=n_weak,\n",
        "#                                            m_weak=m_weak,\n",
        "#                                          )\n",
        "\n",
        "# train_loader_org = torchvision.datasets.MNIST(root ='./data',\n",
        "#                                         download=True,\n",
        "#                                         transform=transforms.Compose(\n",
        "#         [transforms.ToTensor()]\n",
        "#     ))\n",
        "# images, labels = next(iter(train_loader_org))\n",
        "# plt.imshow(images[0].reshape(28,28), cmap=\"gray\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1Z_VglNWJAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_loader = torchvision.datasets.MNIST(root ='./data',\n",
        "#                                         download=True,\n",
        "#                                         transform=transforms.Compose(\n",
        "#         [transforms.ToTensor(), fix_match_augmentation ]\n",
        "#     ))\n",
        "# (images_w, images_s), labels = next(iter(train_loader))\n",
        "# plt.imshow(images_s[0].reshape(28,28), cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWGET3Zti_cY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(images_w[0].reshape(28,28), cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4n0cvZNw5Ec",
        "colab_type": "text"
      },
      "source": [
        "### Conduct Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-QNE7zN8Q2a",
        "colab_type": "text"
      },
      "source": [
        "#### Hyperparameters sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRk7gdudTaaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "0bac2a4e-c785-4242-c5cd-0ff155156616"
      },
      "source": [
        "hparams"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ci': 1,\n",
              " 'dataset': 'MR',\n",
              " 'dataset_path': 'gdrive/My Drive/praca_magisterska/pytorch_lightning/datasets/mr_with_bt2.csv',\n",
              " 'dropout': 0.0,\n",
              " 'embed_dim': 300,\n",
              " 'embeder_type': 'fastText_with_spaCy',\n",
              " 'epoch_over': 'unlabeled_train_dataset',\n",
              " 'kernel_num': 100,\n",
              " 'kernel_sizes': '3,4,5',\n",
              " 'l_batch_size': 32,\n",
              " 'loss_function': 'CrossEntropyLoss',\n",
              " 'lr': 1e-05,\n",
              " 'max_sentence_len': 700,\n",
              " 'max_steps': 1000,\n",
              " 'model_arch': 'Convolution',\n",
              " 'n_labeled': 1600,\n",
              " 'num_classes': 2,\n",
              " 'optimizer_type': 'Adam',\n",
              " 'save_best_model': True,\n",
              " 'scheduler_type': 'None',\n",
              " 'seed': 42,\n",
              " 'test_batch_size': 16,\n",
              " 'test_run': False,\n",
              " 'train_test_split': 0.9,\n",
              " 'training_method': 'Supervised',\n",
              " 'unl_batch_size': 32,\n",
              " 'val_batch_size': 16,\n",
              " 'valid_size_per_class': 96}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zau6FpLJ8k4x",
        "colab_type": "text"
      },
      "source": [
        "#### Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "velwnCrgNCeb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ccb23d2bd3664952b40ce32f63d5e311",
            "15db53f73b5745a09842c08dc689cbd4",
            "f0e18e37d196446d95345029358ba918",
            "d3a6e8c21ce6414997e6e3f6dc26bea0",
            "77f22d80472f408cb4d4bc7678814418",
            "2ff83b28b8c643cf84f562c324053f56",
            "9bdfb72e1c6e4aa09996238a1d58c812",
            "d63aaf40920a4747b94f8e9ef9541c71",
            "c209f4d221a24d3d8e30fd82191b0549",
            "452c2f73bbf049849ea49aff316e17b7",
            "e5475fc6bbad4e57bb707b5be32b4b7c",
            "a4e41a3ff852408f98db6fb713cfa6a1",
            "0bac890337944a4e813bb2e752996f81",
            "699f19fda48444548c3a8ae1497dcee0",
            "c31f8c50e8684b808a60ac212d2240e3",
            "819469515a9b4f058c8f7b5838f50d72",
            "102ba5246571456ea1fad3ba350240d3",
            "9604f46d1dc043dfbacad9dffb9fb079",
            "4c343c24184744b2b4797f963cf5d47d",
            "b689fe3bea5a42039c7d48078e2147ed",
            "b97a68ee35a641958ce5bc405bc8c2a9",
            "21693a05e55f41fe88d00478369e1491",
            "1a76609c8ee14f3c95e5bb77d0e56cbe",
            "d6f5eb677ce54938975342288df58e66",
            "8d8b7d2266e140f9bda3d3b25cf6e1e8",
            "046459bd34244f7ea2fc4ca110045aa3",
            "b9c3cdb42b0c45f480cec65b171b8130",
            "a069eb6ac0b94200bddea9692ed25094",
            "0f4820fbc24f4b0a843510ee4c5866f7",
            "09c1f8af23584e63b20afc2918f11ebf",
            "f9915dbf25624894a875884cb9efe5db",
            "452816a5a1e541358a33f13bd00079db",
            "fcf6618e3db244e4a32efc4b5eb9c41a",
            "a68bed56f4df4dcfbb36026b7e03f8de",
            "e310af69b8af49868004f3b492ca3d21",
            "a0fabfd8580f4717b984556ede8a1221",
            "89512d11c2f34e1fba7c001a82cc47b3",
            "356009deb2444eb79d262fc0465c5429",
            "4326cf3e2d6c4b5d8f52d15b6a3261ac",
            "8e2dbe11837b473b8365fa3efba99508",
            "142d18ceab09490d848d6ba07382833b",
            "d3635d58791447fdb82303634e0c596b",
            "8d1b17a91dc7464dbaae5f6ced020c11",
            "a9eb7b2e332f4a9aacb95777aee9bc6e",
            "9597b48314f5437f9d2b6f4b0a1451c2",
            "f418f8306fba4d7686b995442c22e8d3",
            "2f8ab160ffa145e696aaf1890126e5a6",
            "aeae74414d7d4e8b8804f864134d0234",
            "f877548252504fccaca2d072f4c4237a",
            "a02a07d529184b24b65e6b7a36ddfdc2",
            "0722969be7fa4b29b2684979052a0f1e",
            "284bcb9cfaf9429b93227de27a44ee49",
            "95f91510811b491f8fd30aa8851a7f34",
            "fe256bb1db8e460d8e6d9c758fcc773a",
            "9f32c21b90ef4a70961205c7453db1ec",
            "cfde523e820b4666a1ace486c6e2ac53",
            "5d462a2e459649d99737552ff0be0028",
            "69c8a3a30c8643ff978ced9a2e06fd54",
            "0c7ad61836ce4ef8883f6b73aa49883b",
            "27c55514fc244b92a06dd0f1d3d4ed64",
            "d860f0d91e3541a78bf2b78bcdd3bb02",
            "4d2483f903e642c8bfd4c494278c636c",
            "95a55d5996bf452bac8ceb89bbd5b308",
            "b237977c3fd94faa89c9dcb9eb7f4923",
            "c991ccf612ce45c2a0cd0f555901f3c7",
            "ad42b2cc1f7a44d2ad0208bf269d2dd6",
            "1d1b2b66f5f04b288f2ec468235a5fad",
            "b61251b09cdd4dcd8db270235716a0f0",
            "3146a9f4f0924a77810164d2835b220a",
            "193e44e86cc744388aad899880e4bf1e",
            "1c5655f54cec4d039da8e14ab7aa0bd9",
            "927d23a9e25f4098b69e4f06b0ca6f85",
            "9520c8c49c9343d6a4832f2dab5809c7",
            "1fd89f5e3e074e2b8e97ebcb4318a7ee",
            "3cf10af0fbd044d0b6e4e328a49d826f",
            "b81b89f870de42acb39e514b05bcba61",
            "cc4be049540d41e49a7370f63185755f",
            "75ef56e0830e49a5afd7dd2a019ba5f2",
            "8f17a4cab2bb4777af77e94f135cc558",
            "0fb4f00871cc44659835a0b2f698066a",
            "6946cba2a68a421f9ec1703c17056379",
            "262e3d2c427e41ec9c1fad58ba7f53bb",
            "a3e140e9cb2a4df7b81f73572597960f",
            "bd23209c736a425ebebe3f5152701c20",
            "0fe2e60191814208914553232e495b86",
            "a0a45a8a98d541e990130c6860ca6210",
            "8e773c5c11514094a0d71b58ef737f45",
            "191b502762c44738b1555fa754bb86fc",
            "47faede77945479bb9080703299e3147",
            "d6e72c33bd2a4398bc065166cb277675",
            "2e78bc39821f48ad992436add7480e59",
            "52ba0a87cf494110a22c42db6b17d571",
            "01ade2d865774b21a374083d6b346741",
            "b943ddf1dcde49ca83993c3a6834f2a3",
            "9b90920772a94e098af162a55bd41be4",
            "600e40fb36014ddcbaa516ba79c48ab9",
            "3739205ae04b4e30bd309a12118ebc7a",
            "29c78beeabcf4b1e92d8e1be4399ec81",
            "67d069e61cad43cebb88bfbe66829548",
            "d51e93e261a54eae97d9ed6b63d1d7c7",
            "efbf16e0c5484b1584b2e008b6916d17",
            "1823dde075af45e184982f3ba852be8b",
            "a5d2ec0ec2d34e2686e068172e64900c",
            "a7e582ae60a147d0b3776700ce96cc1e",
            "4875a1fa14c44235903da90d5476c5b1",
            "9a2c92d4f1b3437f9edfa17d246bd7f6",
            "ad804deaa56543b0aea4a1637b390ad2",
            "5bd54dd59b054f84a144aed7087f4783",
            "1c7ef8df66cd48268cc0d5c5f9e1e772",
            "5ac3a60e85a24b53aaaade4518ca897f",
            "576bbc64bf4c46e29bf4e75facff3ef2",
            "506bb610461640cc9792e3f6f63069ef",
            "7ab3f70501f7463b9ce45cc8cb05ecae",
            "fe723c8a30a945c68a4e3868c50a9bdb",
            "1286adbcf69d45249306a479c3599d4b",
            "e3a1d4a1c5bf44ddafeb089b9dd1fb13",
            "481202dbb6d84c388d54f60c14a6198a",
            "7a5a7701d3dc4c3ba35849c44edbada6",
            "7429892e32da497da4518f5a46021316",
            "3fe4339b94a84240babd514bb8aa3fe2",
            "e3b1d1c4392843889d3e20568e242ac8",
            "e180856f32da4d93a6d7c16e72d390c6",
            "a4183239b34a482e90f314e481bcb41a",
            "a4170f571e394c36a3a06f5a401a7df9",
            "fc2d47376a084d44bdb8c8c1c40d38a1",
            "a9c46420abea47679175fb1172407e7a",
            "5c158a90fa2e49cb931f6759c2b96c7e",
            "f19279518a4c42ab954681e1cc4247fb",
            "a78e4fbd75de4ce7bd85b4a0ad42219e",
            "db12a09cc1224d65a2735ecad9cb5bc4",
            "51a2ee2b50d849069102e2c19483487f",
            "d09ba6c300b540f8b55ba75349a0e74e",
            "b5d354a4aa6e45608b5cb62a3a6efd4c",
            "5dc211aa75fe43ab85802e89cbb452eb",
            "abbe91a5479446ab87f5fcabe4c68069",
            "9a8707dd35e547509d96365c003a113a",
            "f4538294c30d4fe393c94cf4ac04c734",
            "3e85a86402b443719ff00d3b3ae24fb9",
            "e786fff8a20b43c0b51fae73efbe8acf",
            "185ae6085f4c4fb59c7c9b11014bf6b2",
            "e6bf2a9a3c7540459b858b5af4506a96",
            "8de7cdb96d574acea2cadac03203d5b0",
            "f5f22d1af25949b99ff6f12e8e182e92",
            "3a23dc0a026c4a8a8b35d6a542b43f78",
            "589bc446802648d0b4dd357cb313cf8f",
            "38d8548fbe154c26ab1df93d7cb38c03",
            "47a68c1dc5c54276b82ba85c933914e5",
            "2b59c7597e544938adb357571aa62ded",
            "4325f9011a1d4609ba8e7d2d01a4c400",
            "6de36b99e6964d95ae9e7d4764560b74",
            "b0ab178ce1ce482184111edc5ad53f9b",
            "43f0a71dbf344a42bf130926490e76bc",
            "157352ae341942688234a2f1d4ec8a28",
            "b47ed1a9a3d44370833fd9ce5ab89769",
            "bae239a27d0b49ada102e5b60078049f",
            "abaab506a88242e8bfbea044705ae0dc",
            "09266302e4bf4a5d93e8d2c4ad3b02ec",
            "fa8dbd0636e04bb69c374991f0a6657a",
            "5c04996d0eb1407c9e976e326ba237cd",
            "7d7db01e77774d5380bc3a63239b68d5",
            "c233cc569cd44d328d7e9e5c036c2506",
            "95b86536fdd24ab09ef05fbf45ba5a06",
            "5360a12f0e9d4f7c9202d592dbee1fe3",
            "aab5b732ef2c487f91e0e836478023f7",
            "aa22bd175b1343a8b67799f78f1ee039",
            "f51869fc4740430dbd22d33f2400ec8b",
            "ddf80480661148fe8e26c285334d164c",
            "e25bbc16d5544408b98a8af6dd7d49b7",
            "e7f3a1829cb44a20a064b4ece2ee40a8",
            "385e92e1a9d64900ae0417ab2572b9bc",
            "9fa28873fc164f38bb8a627173157a19",
            "8879a680c7d54d2d855d48f09626c6df",
            "9d7cfcbdbd5647369f6fb2cc6e1268ca",
            "914b8549ec1e4701a31d76cad4ceb199",
            "321320e563e048469cb4481fe3a93c68",
            "3be769bb141e47c9ab3f8ce973a9a3b7"
          ]
        },
        "outputId": "a629243f-b79e-4aed-acfa-6f877f09336b"
      },
      "source": [
        "set_seed(hparams['seed'])\n",
        "experiment_name = dataset + \"-\" + model_arch + \"-\" + training_method  \n",
        "project_name = \"mr\"\n",
        "\n",
        "# logers\n",
        "\n",
        "# neptune_logger = NeptuneLogger(\n",
        "#                                project_name=\"m1f1/lightning-exps-text,\n",
        "#                                close_after_fit=False,\n",
        "#                                experiment_name=experiment_name,  # Optional,\n",
        "#                                params=hparams, # Optional,\n",
        "#                                tags=tags # Optional,\n",
        "#                               )\n",
        "\n",
        "wandb_logger = WandbLogger(project=project_name,\n",
        "                           name=experiment_name,\n",
        "                           tags=tags)\n",
        "\n",
        "wandb_logger.log_hyperparams(hparams)\n",
        "\n",
        "\n",
        "# callbacks\n",
        "# early_stop_callback = EarlyStopping(\n",
        "#                         monitor=\"val_loss\",\n",
        "#                         min_delta=0.0,\n",
        "#                         patience=hparams['patience'],\n",
        "#                         verbose=True,\n",
        "#                         mode='min'\n",
        "#                       )\n",
        "lr_logger = LearningRateLogger()\n",
        "# Path(\"./checkpoints\").mkdir(parents=True, exist_ok=True)\n",
        "# model_checkpoint = pl.callbacks.ModelCheckpoint(filepath='./checkpoints') # check if it overwrite last checkpoint\n",
        "\n",
        "[print(f'{k}: {v}') for k, v in hparams.items()]\n",
        "\n",
        "if hparams['save_best_model']:\n",
        "  checkpoint_path = os.path.join(os.environ['MODEL_CHECKPOINT_PATH'], '{epoch}-{val_accuracy_error:.2f}')\n",
        "  checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                        mode='min',\n",
        "                                        monitor='val_accuracy_error',\n",
        "                                        save_top_k=1)\n",
        "else:\n",
        "  checkpoint_callback = None\n",
        "\n",
        "# training and evaluating model\n",
        "trainer = pl.Trainer(\n",
        "                gpus=1,\n",
        "                # logger=neptune_logger,\n",
        "                logger=wandb_logger,\n",
        "                checkpoint_callback=checkpoint_callback,\n",
        "                # early_stop_callback=early_stop_callback,\n",
        "                # val_check_interval=hparams['val_check_interval'],\n",
        "                # distributed_backend=hparams['distributed_backend'],\n",
        "                # default_root_dir=\"./test_run_logs\",\n",
        "                callbacks=[lr_logger],\n",
        "                fast_dev_run=hparams['test_run'],\n",
        "              #  train_percent_check=0.001,\n",
        "              #  val_percent_check=0.001,\n",
        "                # min_epochs=hparams['min_epochs'],\n",
        "                max_steps =hparams['max_steps'],\n",
        "          )\n",
        "\n",
        "model = LitComposableFramework(hparams)\n",
        "\n",
        "wandb_logger.watch(model, log='all', log_freq=10)\n",
        "\n",
        "trainer.fit(model)\n",
        "\n",
        "if hparams['save_best_model']:\n",
        "  model_loaded= LitComposableFramework.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
        "  trainer.test(model_loaded)\n",
        "else:\n",
        "  trainer.test(model)\n",
        "\n",
        "# neptune_logger.experiment.log_artifact('./checkpoints')\n",
        "# neptune_logger.experiment.log_artifact(os.environ['REQUIREMENTS_PATH'])\n",
        "# neptune_logger.experiment.stop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/mifi/mr\" target=\"_blank\">https://app.wandb.ai/mifi/mr</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/mifi/mr/runs/3lv38wyt\" target=\"_blank\">https://app.wandb.ai/mifi/mr/runs/3lv38wyt</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "dataset: MR\n",
            "num_classes: 2\n",
            "dataset_path: gdrive/My Drive/praca_magisterska/pytorch_lightning/datasets/mr_with_bt2.csv\n",
            "training_method: Supervised\n",
            "l_batch_size: 32\n",
            "unl_batch_size: 32\n",
            "optimizer_type: Adam\n",
            "lr: 1e-05\n",
            "scheduler_type: None\n",
            "max_steps: 1000\n",
            "model_arch: Convolution\n",
            "max_sentence_len: 700\n",
            "embeder_type: fastText_with_spaCy\n",
            "embed_dim: 300\n",
            "Ci: 1\n",
            "kernel_num: 100\n",
            "kernel_sizes: 3,4,5\n",
            "dropout: 0.0\n",
            "seed: 42\n",
            "train_test_split: 0.9\n",
            "val_batch_size: 16\n",
            "test_batch_size: 16\n",
            "n_labeled: 1600\n",
            "valid_size_per_class: 96\n",
            "loss_function: CrossEntropyLoss\n",
            "test_run: False\n",
            "save_best_model: True\n",
            "epoch_over: labeled_train_dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Unique labels: ['neg ', 'pos ']\n",
            "Number of unique labels: 2\n",
            "train_df:\n",
            "              ...                                        paraphrases\n",
            "count   1800  ...                                               1800\n",
            "unique  1800  ...                                               1800\n",
            "top     1419  ...  in this good, naturalized comedy, enjoyable an...\n",
            "freq       1  ...                                                  1\n",
            "\n",
            "[4 rows x 5 columns]\n",
            "test_df:\n",
            "            Unnamed: 0  ... label                                        paraphrases\n",
            "count   200        200  ...   200                                                200\n",
            "unique  200        200  ...     2                                                200\n",
            "top     327        327  ...  pos      For over twenty minutes on impossible missi...\n",
            "freq      1          1  ...   105                                                  1\n",
            "\n",
            "[4 rows x 5 columns]\n",
            "total_iterations:  1000\n",
            "Scheduler was not specified!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name     | Type             | Params\n",
            "----------------------------------------------\n",
            "0 | loss_fct | CrossEntropyLoss | 0     \n",
            "1 | convs1   | ModuleList       | 360 K \n",
            "2 | dropout  | Dropout          | 0     \n",
            "3 | fc1      | Linear           | 602   \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccb23d2bd3664952b40ce32f63d5e311",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning:\n",
            "\n",
            "You are using LearningRateLogger callback with models that have no learning rate schedulers. Please see documentation for `configure_optimizers` method.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c209f4d221a24d3d8e30fd82191b0549",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "102ba5246571456ea1fad3ba350240d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning:\n",
            "\n",
            "The metric you returned 0.5034722222222222 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_accuracy_error in validation_epoch_end()?\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d8b7d2266e140f9bda3d3b25cf6e1e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning:\n",
            "\n",
            "The metric you returned 0.4927083333333333 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_accuracy_error in validation_epoch_end()?\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcf6618e3db244e4a32efc4b5eb9c41a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning:\n",
            "\n",
            "The metric you returned 0.4708333333333334 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_accuracy_error in validation_epoch_end()?\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "142d18ceab09490d848d6ba07382833b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning:\n",
            "\n",
            "The metric you returned 0.434375 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_accuracy_error in validation_epoch_end()?\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f877548252504fccaca2d072f4c4237a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning:\n",
            "\n",
            "The metric you returned 0.4236111111111111 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_accuracy_error in validation_epoch_end()?\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d462a2e459649d99737552ff0be0028",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning:\n",
            "\n",
            "The metric you returned 0.4239583333333334 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_accuracy_error in validation_epoch_end()?\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c991ccf612ce45c2a0cd0f555901f3c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning:\n",
            "\n",
            "The metric you returned 0.41875 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_accuracy_error in validation_epoch_end()?\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9520c8c49c9343d6a4832f2dab5809c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning:\n",
            "\n",
            "The metric you returned 0.4291666666666667 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_accuracy_error in validation_epoch_end()?\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6946cba2a68a421f9ec1703c17056379",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47faede77945479bb9080703299e3147",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3739205ae04b4e30bd309a12118ebc7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning:\n",
            "\n",
            "The metric you returned 0.4395833333333334 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_accuracy_error in validation_epoch_end()?\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4875a1fa14c44235903da90d5476c5b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ab3f70501f7463b9ce45cc8cb05ecae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning:\n",
            "\n",
            "The metric you returned 0.4447916666666667 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_accuracy_error in validation_epoch_end()?\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3b1d1c4392843889d3e20568e242ac8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a78e4fbd75de4ce7bd85b4a0ad42219e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4538294c30d4fe393c94cf4ac04c734",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "589bc446802648d0b4dd357cb313cf8f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "157352ae341942688234a2f1d4ec8a28",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c233cc569cd44d328d7e9e5c036c2506",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning:\n",
            "\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Unique labels: ['neg ', 'pos ']\n",
            "Number of unique labels: 2\n",
            "train_df:\n",
            "              ...                                        paraphrases\n",
            "count   1800  ...                                               1800\n",
            "unique  1800  ...                                               1800\n",
            "top     1419  ...  in this good, naturalized comedy, enjoyable an...\n",
            "freq       1  ...                                                  1\n",
            "\n",
            "[4 rows x 5 columns]\n",
            "test_df:\n",
            "            Unnamed: 0  ... label                                        paraphrases\n",
            "count   200        200  ...   200                                                200\n",
            "unique  200        200  ...     2                                                200\n",
            "top     327        327  ...  pos      For over twenty minutes on impossible missi...\n",
            "freq      1          1  ...   105                                                  1\n",
            "\n",
            "[4 rows x 5 columns]\n",
            "total_iterations:  1000\n",
            "Scheduler was not specified!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7f3a1829cb44a20a064b4ece2ee40a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-277b5d196ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'save_best_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0mmodel_loaded\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLitComposableFramework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_loaded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, test_dataloaders, ckpt_path)\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__test_given_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__test_using_best_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__test_given_model\u001b[0;34m(self, model, test_dataloaders)\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tpu\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no-cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreinit_scheduler_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;31m# only load test dataloader for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;31m# self.reset_test_dataloader(ref_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# remove all cuda tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, test_mode)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;31m# run evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# enable no returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, model, dataloaders, max_batches, test_mode)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mdl_max_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataloader_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Loooc9iAcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = pd.read_csv(str(Path(os.environ['DATASETS_PATH'])/'imdb_with_bt.csv'))\n",
        "# df\n",
        "# df = df.rename(columns={'intent': 'label', 'bt': 'paraphrases'})\n",
        "# df.to_csv(str(Path(os.environ['DATASETS_PATH'])/'imdb_with_bt.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfaD-N-RFmpH",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhTVU9r32eyI",
        "colab_type": "text"
      },
      "source": [
        "#### System spec\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucbrH_0LsQ8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class LitYKConv_HPO(pl.LightningModule):\n",
        "\n",
        "#   def __init__(self, hparams, trial):\n",
        "\n",
        "#     super().__init__()\n",
        "#     self.hparams = hparams\n",
        "\n",
        "#     if self.hparams['with_VAT']:\n",
        "#       xi_interval = list(map(float, hparams['xi'].split(',')))\n",
        "#       eps_interval = list(map(float, hparams['eps'].split(',')))\n",
        "#       ip_interval = list(map(int, hparams['ip'].split(',')))\n",
        "#       alpha_interval = list(map(float, hparams['alpha'].split(',')))\n",
        "\n",
        "#       self.xi = trial.suggest_uniform('xi', *xi_interval)\n",
        "#       print('xi: ', self.xi)\n",
        "#       self.eps = trial.suggest_uniform('eps', *eps_interval)\n",
        "#       print('eps: ', self.eps)\n",
        "#       self.ip = trial.suggest_int('ip', *ip_interval)\n",
        "#       print('ip: ', self.ip)\n",
        "#       self.alpha = trial.suggest_uniform('alpha', *alpha_interval)\n",
        "#       print('alpha: ', self.alpha)\n",
        "\n",
        "#     lr_interval = list(map(float, hparams['lr'].split(',')))\n",
        "#     print(lr_interval)\n",
        "#     kernel_num_interval = list(map(int, hparams['kernel_num'].split(','))) \n",
        "#     print(kernel_num_interval)\n",
        "#     dropout_interval = list(map(float, hparams['dropout'].split(','))) \n",
        "#     print(dropout_interval)\n",
        "\n",
        "#     self.lr = trial.suggest_loguniform('learning_rate', *lr_interval)\n",
        "#     print('lr: ', self.lr)\n",
        "#     self.Co = trial.suggest_int('kernel_num', *kernel_num_interval) #hparams['kernel_num']\n",
        "#     print('kernel_num: ', self.Co)\n",
        "#     dropout = trial.suggest_uniform('dropout', *dropout_interval)\n",
        "#     print('dropout: ', dropout)\n",
        "#     self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "#     self.embeder_dict = {\n",
        "#                          'fastText': (create_ft_embeder, gensim_tokenizer),\n",
        "#                          'spaCy':(create_spacy_nlp_embeder, lambda x: x)\n",
        "#                         }\n",
        "#     embeder, self.tokenizer_fun = self.embeder_dict[hparams['embeder_type']]\n",
        "#     self.embeder = nlp #embeder()\n",
        "#     self.D = hparams['embed_dim']\n",
        "#     self.Ci = hparams['Ci'] \n",
        "    \n",
        "#     self.loss_fct = getattr(nn, hparams['loss_function'])()\n",
        "#     self.num_classes = hparams['num_classes']\n",
        "\n",
        "#     self.Ks = list(map(int, hparams['kernel_sizes'].split(','))) # (3,4,5)\n",
        "#     self.convs1 = nn.ModuleList([nn.Conv2d(self.Ci, self.Co, (K, self.D)) for K in self.Ks])\n",
        "#     self.fc1 = nn.Linear(len(self.Ks) * self.Co, self.num_classes) \n",
        "\n",
        "#     self.total_iterations = 0 \n",
        "\n",
        "#   def forward(self, x):\n",
        "#       # print('org: ', x.size())\n",
        "#       x = x.unsqueeze(self.Ci)  # (N, Ci, W, D)\n",
        "#       # from pdb import set_trace as st\n",
        "#       # st() \n",
        "#       # print(f'unsqueeze {self.Ci}: {x.size()}')\n",
        "#       x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
        "#       # print(f'conv, relu, squeeze : {x.size()}')\n",
        "#       x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "#       # print(f'max_pool1d, squeeze : {x.size()}')\n",
        "#       x = torch.cat(x, 1)\n",
        "#       # print(f' cat: {x.size()}')\n",
        "#       x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "#       logit = self.fc1(x)  # (N, C)\n",
        "#       # print(f' logit: {logit.size()}')\n",
        "#       return logit\n",
        "\n",
        "\n",
        "#   def prepare_data(self):\n",
        "\n",
        "#     if self.hparams['dataset'] == 'NLUHD':\n",
        "\n",
        "#       not_none = lambda x: x[\"text\"] is not None \n",
        "#       ds = lf.CsvDataset(self.hparams['dataset_path'], header=True).filter(not_none)\n",
        "#       unique_labels = list(pd.DataFrame(ds).intent.unique())\n",
        "#       le = preprocessing.LabelEncoder().fit(unique_labels)\n",
        "#       print(f\"Unique labels: {unique_labels}\")\n",
        "#       print(f\"Number of unique labels: {len(unique_labels)}\")\n",
        "#       train, test = lf.cross_validation.split_dataset_random(ds,\n",
        "#                                                             int(len(ds) * self.hparams['train_test_split']),\n",
        "#                                                             seed=self.hparams['seed'])\n",
        "#       preprocessor = partial(\n",
        "#                             preprocess_NLUHD,\n",
        "#                             self.hparams['model_type'],\n",
        "#                             self.hparams['max_sentence_len'],\n",
        "#                             self.tokenizer_dict[self.hparams['model_type']],\n",
        "#                             le,\n",
        "#                             )\n",
        "      \n",
        "#     elif self.hparams['dataset'] == 'MR':\n",
        "\n",
        "#       preprocessor = partial(\n",
        "#                             preprocess_MR,\n",
        "#                             self.hparams,\n",
        "#                             self.tokenizer_fun, \n",
        "#                             self.embeder,\n",
        "#                             le,\n",
        "#                             )\n",
        "\n",
        "#     elif self.hparams['dataset'] == 'IMDB':\n",
        "\n",
        "#       ds = lfds.Imdb('train') + lfds.Imdb('test')\n",
        "#       ds = ds.map(lambda x: {'text': x[0], 'label': x[1]})\n",
        "#       df = pd.DataFrame(ds)\n",
        "#       # self.embeder.build_vocab(new_sentences, update=True)\n",
        "#       # self.embeder.train(new_sentences, total_examples=len(new_sentences), epochs=)\n",
        "#       print(df.info(memory_usage=True))\n",
        "#       unique_labels = list(df.label.unique())\n",
        "#       print(f'unique_labels: {unique_labels}')\n",
        "#       print(f'number_of_categories : {len(unique_labels)}')\n",
        "#       le = preprocessing.LabelEncoder().fit(unique_labels)\n",
        "#       train, test = lf.cross_validation.split_dataset_random(ds,\n",
        "#                                                              int(len(ds) * self.hparams['train_test_split']),\n",
        "#                                                              seed=self.hparams['seed'])\n",
        "#       preprocessor = partial(\n",
        "#                              preprocess_IMDB,\n",
        "#                              self.hparams,\n",
        "#                              self.tokenizer_fun, \n",
        "#                              self.embeder,\n",
        "#                              le,\n",
        "#                             )\n",
        "#     else:\n",
        "#       raise ValueError('Wrong dataset name : {}'.format(self.hparams['dataset']))\n",
        "\n",
        "    \n",
        "#     train_df, test_df = pd.DataFrame(train), pd.DataFrame(test)\n",
        "#     x_train, y_train = train_df['text'].values, train_df['label'].values\n",
        "#     x_test, y_test = test_df['text'].values, test_df['label'].values\n",
        "\n",
        "#     # split's parameters  \n",
        "#     num_classes = len(unique_labels)\n",
        "#     label_per_class = self.hparams['n_labeled'] // num_classes\n",
        "#     valid_size = self.hparams['valid_size_per_class']\n",
        "\n",
        "#     labeled_idx = []\n",
        "#     unlabeled_idx = []\n",
        "#     val_idx = []\n",
        "    \n",
        "#     for label in unique_labels:\n",
        "#         idx = np.where(y_train == label)[0]\n",
        "#         np.random.shuffle(idx)\n",
        "#         labeled_idx.extend(idx[:label_per_class])\n",
        "#         val_idx.extend(idx[label_per_class: label_per_class + valid_size])\n",
        "#         unlabeled_idx.extend(idx[label_per_class + valid_size:])\n",
        "\n",
        "#     x_labeled, y_labeled  = x_train[labeled_idx], y_train[labeled_idx]\n",
        "#     x_unlabeled, y_unlabeled = x_train[unlabeled_idx], y_train[unlabeled_idx]\n",
        "#     x_val, y_val = x_train[val_idx], y_train[val_idx]\n",
        "    \n",
        "#     train_labeled_dataset = SimpleTextDataset(x_labeled,\n",
        "#                                               y_labeled,\n",
        "#                                               transform=preprocessor)\n",
        "    \n",
        "#     train_unlabeled_dataset = SimpleTextDataset(x_unlabeled,\n",
        "#                                                 y_unlabeled,\n",
        "#                                                 transform=preprocessor)\n",
        "    \n",
        "#     self._train_dataset = TwoInOneDataset([train_labeled_dataset,\n",
        "#                                             train_unlabeled_dataset])\n",
        "    \n",
        "#     self._val_dataset = SimpleTextDataset(x_val,\n",
        "#                                           y_val,\n",
        "#                                           transform=preprocessor)\n",
        "    \n",
        "#     self._test_dataset = SimpleTextDataset(x_test,\n",
        "#                                            y_test,\n",
        "#                                            transform=preprocessor)\n",
        "    \n",
        "#     self.total_iterations = len(train_unlabeled_dataset) // self.hparams['batch_size'] \n",
        "\n",
        "\n",
        "#   def train_dataloader(self):\n",
        "#     return DataLoader(\n",
        "#                       self._train_dataset,\n",
        "#                       batch_size=self.hparams['batch_size'],\n",
        "#                       num_workers=8,\n",
        "#                       shuffle=True # without shuffle it want work cause it need to create map index before __get_item__ function\n",
        "#                      )\n",
        "    \n",
        "  \n",
        "#   def val_dataloader(self):\n",
        "#     return DataLoader(\n",
        "#                       self._val_dataset,\n",
        "#                       batch_size=self.hparams['batch_size'],\n",
        "#                       num_workers=8\n",
        "#                      )\n",
        "    \n",
        "  \n",
        "#   def test_dataloader(self):\n",
        "#     return DataLoader(\n",
        "#                       self._test_dataset,\n",
        "#                       batch_size=self.hparams['batch_size'],\n",
        "#                       num_workers=8\n",
        "#                      )\n",
        "    \n",
        "  \n",
        "#   def configure_optimizers(self):\n",
        "\n",
        "#     optimizers = [\n",
        "#                   torch.optim.Adam(self.parameters(), lr=self.lr),\n",
        "#                  ]\n",
        "#     schedulers = [\n",
        "#                   {\n",
        "#                     'scheduler': ReduceLROnPlateau(optimizers[0],'min', verbose=True), \n",
        "#                     'monitor': 'val_loss', # Default: val_loss\n",
        "#                     'interval': 'epoch',\n",
        "#                     'frequency': 1\n",
        "#                   },\n",
        "#                  ]\n",
        "\n",
        "#     return optimizers, schedulers\n",
        "\n",
        "\n",
        "#   def training_step(self, batch, batch_idx):\n",
        "\n",
        "#     l_batch = batch[0]\n",
        "#     l_texts = l_batch['embedding']\n",
        "#     labels = l_batch['label']\n",
        "#     unl_texts = batch[1]['embedding']\n",
        "\n",
        "#     if self.hparams['with_VAT']:\n",
        "#       vat_loss = VATLoss(xi=self.xi,\n",
        "#                          eps=self.eps,\n",
        "#                          ip=self.ip)\n",
        "#       lds = vat_loss(self, unl_texts)\n",
        "\n",
        "#     logits = self.forward(l_texts)\n",
        "#     loss = self.loss_fct(logits, labels)\n",
        "\n",
        "#     if self.hparams['with_VAT']:\n",
        "#       loss += self.alpha * lds \n",
        "\n",
        "#     labels_hat = logits.max(dim=1)[1]\n",
        "\n",
        "#     labels = labels.detach().cpu()\n",
        "#     labels_hat = labels_hat.detach().cpu()\n",
        "    \n",
        "#     accuracy_error = torch.tensor(1 - accuracy_score(labels, labels_hat))\n",
        "#     f1_error = torch.tensor(1 - f1_score(labels, labels_hat, average='micro'))\n",
        "#     recall_error = torch.tensor(1 - recall_score(labels, labels_hat, average='micro'))\n",
        "#     precision_error = torch.tensor(1 - precision_score(labels, labels_hat, average='micro'))\n",
        "\n",
        "#     logs = {'train_loss': loss,\n",
        "#             'train_accuracy_error': accuracy_error,\n",
        "#             'train_f1_error': f1_error,\n",
        "#             'train_recall_error': recall_error,\n",
        "#             'train_precision_error': precision_error,\n",
        "#            }  \n",
        "\n",
        "#     if self.hparams['with_VAT']:\n",
        "#       logs.update({'lds_loss': lds.item()})\n",
        "\n",
        "\n",
        "#     return {'loss': loss,\n",
        "#             'log': logs}\n",
        "\n",
        "\n",
        "#   def validation_step(self, batch, batch_idx):\n",
        "#     texts = batch['embedding']\n",
        "#     labels = batch['label']\n",
        "  \n",
        "#     logits = self.forward(texts)\n",
        "#     loss = self.loss_fct(logits, labels)\n",
        "#     labels_hat = torch.argmax(logits, dim=1)\n",
        "\n",
        "#     labels = labels.cpu()\n",
        "#     labels_hat = labels_hat.cpu()\n",
        "\n",
        "#     accuracy_error = torch.tensor(1 - accuracy_score(labels, labels_hat))\n",
        "#     f1_error = torch.tensor(1 - f1_score(labels, labels_hat, average='micro'))\n",
        "#     recall_error = torch.tensor(1 - recall_score(labels, labels_hat, average='micro'))\n",
        "#     precision_error = torch.tensor(1 - precision_score(labels, labels_hat, average='micro'))\n",
        "  \n",
        "#     output = {\n",
        "#             \"val_loss\": loss,\n",
        "#             'accuracy_error': accuracy_error,\n",
        "#             'f1_error': f1_error,\n",
        "#             'recall_error': recall_error,\n",
        "#             'precision_error': precision_error,\n",
        "#             }\n",
        "  \n",
        "#     return output\n",
        "\n",
        "\n",
        "#   def validation_epoch_end(self, outputs):\n",
        "#     # CHANGE FOR TENSORS!!!!\n",
        "#     val_acc = compute_global_metric(outputs, 'accuracy_error')\n",
        "#     val_f1 = compute_global_metric(outputs, 'f1_error')\n",
        "#     val_recall = compute_global_metric(outputs, 'recall_error')\n",
        "#     val_precision = compute_global_metric(outputs, 'precision_error')\n",
        "#     val_loss = compute_global_metric(outputs, \"val_loss\")\n",
        "\n",
        "#     tqdm_dict = {\n",
        "#                  \"val_loss\": val_loss,\n",
        "#                  \"val_acc\": val_acc,\n",
        "#                  \"val_f1\": val_f1,\n",
        "#                  \"val_recall\": val_recall,\n",
        "#                  \"val_precision\": val_precision,\n",
        "#                 }\n",
        "#     return {\n",
        "#             \"progress_bar\": tqdm_dict,\n",
        "#             \"log\": tqdm_dict,\n",
        "#             \"val_loss\": val_loss,\n",
        "#             'val_acc': val_acc,\n",
        "#             'val_f1': val_f1\n",
        "#            }\n",
        "\n",
        "\n",
        "#   def test_step(self, batch, batch_idx):\n",
        "\n",
        "#     texts = batch[\"embedding\"]\n",
        "#     labels = batch[\"label\"]\n",
        "  \n",
        "#     logits = self.forward(texts)\n",
        "#     loss = self.loss_fct(logits, labels)\n",
        "#     labels_hat = torch.argmax(logits, dim=1)\n",
        "\n",
        "#     labels = labels.cpu()\n",
        "#     labels_hat = labels_hat.cpu()\n",
        "\n",
        "\n",
        "#     accuracy_error = torch.tensor(1 - accuracy_score(labels, labels_hat))\n",
        "#     f1_error = torch.tensor(1 - f1_score(labels, labels_hat, average='micro'))\n",
        "#     recall_error = torch.tensor(1 - recall_score(labels, labels_hat, average='micro'))\n",
        "#     precision_error = torch.tensor(1 - precision_score(labels, labels_hat, average='micro'))\n",
        "  \n",
        "#     return {\n",
        "#             \"test_loss\": loss,\n",
        "#             'accuracy_error': accuracy_error,\n",
        "#             'f1_error': f1_error,\n",
        "#             'recall_error': recall_error,\n",
        "#             'precision_error': precision_error,\n",
        "#            }\n",
        "\n",
        "\n",
        "#   def test_epoch_end(self, outputs):\n",
        "\n",
        "#     test_acc = compute_global_metric(outputs, 'accuracy_error') \n",
        "#     test_f1 = compute_global_metric(outputs, 'f1_error')\n",
        "#     test_recall = compute_global_metric(outputs, 'recall_error')\n",
        "#     test_precision = compute_global_metric(outputs, 'precision_error')\n",
        "#     test_loss = compute_global_metric(outputs, \"test_loss\")\n",
        "\n",
        "#     tqdm_dict = {\n",
        "#                  \"test_loss\": test_loss,\n",
        "#                  \"test_acc\": test_acc,\n",
        "#                  \"test_f1\": test_f1,\n",
        "#                  \"test_recall\": test_recall,\n",
        "#                  \"test_precision\": test_precision,\n",
        "#                 }\n",
        "#     return {\n",
        "#             \"progress_bar\": tqdm_dict,\n",
        "#             \"log\": tqdm_dict,\n",
        "#             \"test_loss\": test_loss,\n",
        "#             'test_acc': test_acc,\n",
        "#             'test_f1': test_f1\n",
        "#            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8blDj0ji58J4",
        "colab_type": "text"
      },
      "source": [
        "#### Define objective func\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPAMdmP6F-DM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def objective(trial):\n",
        "#   # nluhd_dataset_path = str(Path()/\n",
        "#   #                         'gdrive'/\n",
        "#   #                         'My Drive'/\n",
        "#   #                         'praca_magisterska'/\n",
        "#   #                         'pytorch_lightning'/\n",
        "#   #                         'datasets'/\n",
        "#   #                         'NLU-Data-Home-Domain-preprocessed-without-ner.csv')\n",
        "#   hparams = {\n",
        "#             # model architecture\n",
        "#             'model_type': 'YoonKimConvNN',\n",
        "#             'dropout':'0.2,0.7', \n",
        "#             'kernel_sizes': '3,4,5', # (3,4,5)\n",
        "#             'kernel_num': '60,120', # interval\n",
        "#             'Ci': 1,\n",
        "#             'loss_function':'CrossEntropyLoss',\n",
        "#             # pl trainer params\n",
        "#             'seed': 42,\n",
        "#             'monitor_value': 'val_acc',\n",
        "#             'percent_valid_examples': 0.5, \n",
        "#             'test_run': False,\n",
        "#             'with_VAT': True,\n",
        "#             'max_epochs': 2,\n",
        "#             'min_epochs': 1,\n",
        "#             'val_check_interval': 0.5, \n",
        "#             'patience': 3, # early stopping callback parameter\n",
        "#             'distributed_backend': 'dp',\n",
        "#             # embeddings params\n",
        "#             'embeder_type': \"fastText\",\n",
        "#             'embed_dim': 300,\n",
        "#             'max_sentence_len': 400,\n",
        "#             # dataset params\n",
        "#             'train_test_split': 0.8,\n",
        "#             'batch_size': 32,\n",
        "#             'n_labeled': 1000, # number of labeled samples \n",
        "#             'valid_size_per_class': 1000, # 68 class => n_val_samples = 68 * 10 \n",
        "#             # optimizer params\n",
        "#             'lr': '0.00001, 10',\n",
        "#             # VAT params\n",
        "#             'xi':'6,12',\n",
        "#             'eps':'1,3',\n",
        "#             'ip':'1,3',\n",
        "#             'alpha':'1,3',\n",
        "#             }\n",
        "  \n",
        "#   set_seed(hparams['seed'])\n",
        "  \n",
        "#   hparams.update({'dataset':'IMDB',\n",
        "#                   'num_classes': 2})\n",
        "  \n",
        "  \n",
        "#   # training and evaluating model\n",
        "  \n",
        "          \n",
        "#   metrics_callback = MetricsCallback()\n",
        "  \n",
        "#   checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "#           os.path.join(os.environ['RESULT_PATH'],\n",
        "#                        \"trial_{}\".format(trial.number),\n",
        "#                        \"{epoch}\"), monitor=hparams['monitor_value']\n",
        "#       )\n",
        "  \n",
        "#   trainer = pl.Trainer(\n",
        "#                   gpus=1 if torch.cuda.is_available() else None,\n",
        "#                   logger=False,\n",
        "#                   # val_percent_check=hparams['percent_valid_examples'],\n",
        "#                   checkpoint_callback=checkpoint_callback,\n",
        "#                   max_epochs=hparams['max_epochs'],\n",
        "#                   fast_dev_run=hparams['test_run'],\n",
        "#                   callbacks=[metrics_callback],\n",
        "#                   early_stop_callback=PyTorchLightningPruningCallback(trial, monitor=hparams['monitor_value'])\n",
        "#             )\n",
        "  \n",
        "#   model = LitYKConv_HPO(hparams, trial=trial)\n",
        "  \n",
        "#   trainer.fit(model)\n",
        "#   return metrics_callback.metrics[-1][\"val_acc\"]\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjAj0j4L5vTG",
        "colab_type": "text"
      },
      "source": [
        "#### Run trails"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuNsLhst6BPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pruning = True\n",
        "\n",
        "# pruner = optuna.pruners.MedianPruner() if pruning else optuna.pruners.NopPruner()\n",
        "\n",
        "# study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
        "# study.optimize(objective, n_trials=20, timeout=None)\n",
        "\n",
        "# print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
        "\n",
        "# print(\"Best trial:\")\n",
        "# trial = study.best_trial\n",
        "\n",
        "# print(\"  Value: {}\".format(trial.value))\n",
        "\n",
        "# print(\"  Params: \")\n",
        "# for key, value in trial.params.items():\n",
        "#     print(\"    {}: {}\".format(key, value))\n",
        "# # shutil.rmtree(os.environ['RESULT_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8LrwpD19Y3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optuna.visualization.plot_intermediate_values(study)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y5eSN9y9Xqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optuna.visualization.plot_param_importances(study)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRChtuTLMfxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}